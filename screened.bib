@article{war_vulnerabilities_2025,
	title = {Vulnerabilities in infrastructure as code: what, how many, and who?},
	volume = {30},
	issn = {1573-7616},
	url = {http://dx.doi.org/10.1007/s10664-025-10672-8},
	doi = {10.1007/s10664-025-10672-8},
	number = {5},
	journal = {Empirical Software Engineering},
	author = {War, Aicha and Diallo, Alioune and Habib, Andrew and Klein, Jacques and Bissyandé, Tegawendé F.},
	month = jun,
	year = {2025},
	note = {Publisher: Springer Science and Business Media LLC},
}

@article{bessghaier_towards_2025,
	title = {Towards understanding code review practices for infrastructure-as-code: {An} empirical study on {OpenStack} projects},
	volume = {30},
	issn = {1573-7616},
	url = {http://dx.doi.org/10.1007/s10664-025-10654-w},
	doi = {10.1007/s10664-025-10654-w},
	number = {4},
	journal = {Empirical Software Engineering},
	author = {Bessghaier, Narjes and Ouni, Ali and Sayagh, Mohammed and Chouchen, Moataz and Mkaouer, Mohamed Wiem},
	month = apr,
	year = {2025},
	note = {Publisher: Springer Science and Business Media LLC},
}

@incollection{nasiri_towards_2024,
	title = {Towards a {Taxonomy} of {Infrastructure} as {Code} {Misconfigurations}: {An} {Ansible} {Study}},
	isbn = {978-3-031-72578-4},
	url = {http://dx.doi.org/10.1007/978-3-031-72578-4_5},
	booktitle = {Service-{Oriented} {Computing}},
	publisher = {Springer Nature Switzerland},
	author = {Nasiri, Roya and Kumara, Indika and Tamburri, Damian Andrew and van den Heuvel, Willem-Jan},
	month = oct,
	year = {2024},
	doi = {10.1007/978-3-031-72578-4_5},
	note = {ISSN: 1865-0937},
    abstract = {Infrastructure as Code (IaC) enables the management and provisioning of infrastructure using code instead of manual processes. While the IaC approach can simplify and automate infrastructure management, the configuration errors (i.e., misconfigurations) in the IaC scripts can significantly hinder achieving the benefits of the automation, incur undue costs, and leave the system faulty and insecure. In this paper, we present a taxonomy of IaC misconfigurations to assist practitioners and researchers in building tools for detecting misconfigurations. The user manuals of the IaC frameworks describe configuration parameters and their usage constraints, and provide recommendations on configuring certain parameters correctly. Hence, we systemically collected and analyzed 100 user manuals of the Ansible IaC language to compile a catalog of 25 configuration errors. We also developed a proof-of-concept tool for using the information in the user manuals to generate misconfiguration detection rules.},
	pages = {83--103},
}

@article{shimizu_test-suite-guided_2024,
	title = {Test-suite-guided discovery of least privilege for cloud infrastructure as code},
	volume = {31},
	issn = {1573-7535},
	url = {http://dx.doi.org/10.1007/s10515-024-00420-5},
	doi = {10.1007/s10515-024-00420-5},
	number = {1},
	journal = {Automated Software Engineering},
	author = {Shimizu, Ryo and Nunomura, Yuna and Kanuka, Hideyuki},
	month = mar,
	year = {2024},
	note = {Publisher: Springer Science and Business Media LLC},
}

@article{rahman_as_2020,
	title = {The ‘as code’ activities: development anti-patterns for infrastructure as code},
	volume = {25},
	issn = {1573-7616},
	url = {http://dx.doi.org/10.1007/s10664-020-09841-8},
	doi = {10.1007/s10664-020-09841-8},
	number = {5},
	journal = {Empirical Software Engineering},
	author = {Rahman, Akond and Farhana, Effat and Williams, Laurie},
	month = aug,
	year = {2020},
	note = {Publisher: Springer Science and Business Media LLC},
	pages = {3430--3467},
}

@article{verdet_assessing_2025,
	title = {Assessing the adoption of security policies by developers in terraform across different cloud providers},
	volume = {30},
	issn = {1573-7616},
	url = {http://dx.doi.org/10.1007/s10664-024-10610-0},
	doi = {10.1007/s10664-024-10610-0},
	number = {3},
	journal = {Empirical Software Engineering},
	author = {Verdet, Alexandre and Hamdaqa, Mohammad and Silva, Leuson Da and Khomh, Foutse},
	month = feb,
	year = {2025},
	note = {Publisher: Springer Science and Business Media LLC},
}

@article{eng_patterns_2024,
	title = {Patterns of multi-container composition for service orchestration with {Docker} {Compose}},
	volume = {29},
	issn = {1573-7616},
	url = {http://dx.doi.org/10.1007/s10664-024-10462-8},
	doi = {10.1007/s10664-024-10462-8},
	number = {3},
	journal = {Empirical Software Engineering},
	author = {Eng, Kalvin and Hindle, Abram and Stroulia, Eleni},
	month = may,
	year = {2024},
    abstract = {Software design patterns present general code solutions to common software design problems. Modern software systems rely heavily on containers for running their constituent service components. Yet, despite the prevalence of ready-to-use Docker service images ready to participate in multi-container service compositions of applications, developers do not have much guidance on how to compose their own Docker service orchestrations. Thus in this work, we curate a dataset of successful projects that employ Docker Compose as an orchestration tool to run multiple service containers; then, we engage in qualitative and quantitative analysis of Docker Compose configurations. The collection of data and analysis enables the identification and naming of repeating multi-container composition patterns that are used in numerous successful open-source projects, much like software design patterns. These patterns highlight how software systems are orchestrated in the real-world and can give examples to anybody wishing to compose their own service orchestrations. These contributions also advance empirical research in software engineering patterns as evidence is provided about how Docker Compose is used},
	note = {Publisher: Springer Science and Business Media LLC},
}

@article{10.1007/s10664-023-10432-6,
author = {Rahman, Akond and Bose, Dibyendu Brinto and Zhang, Yue and Pandita, Rahul},
title = {An empirical study of task infections in Ansible scripts},
year = {2023},
issue_date = {Jan 2024},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {29},
number = {1},
issn = {1382-3256},
url = {https://doi.org/10.1007/s10664-023-10432-6},
doi = {10.1007/s10664-023-10432-6},
journal = {Empirical Softw. Engg.},
month = dec,
numpages = {44},
abstract = {Context
Despite being beneficial for managing computing infrastructure at scale, Ansible scripts include security weaknesses, such as hard-coded passwords. Security weaknesses can propagate into tasks, i.e., code constructs used for managing computing infrastructure with Ansible. Propagation of security weaknesses into tasks makes the provisioned infrastructure susceptible to security attacks. A systematic characterization of task infection, i.e., the propagation of security weaknesses into tasks, can aid practitioners and researchers in understanding how security weaknesses propagate into tasks and derive insights for practitioners to develop Ansible scripts securely.
Objective The goal of the paper is to help practitioners and researchers understand how Ansible-managed computing infrastructure is impacted by security weaknesses by conducting an empirical study of task infections in Ansible scripts.
Method We conduct an empirical study where we quantify the frequency of task infections in Ansible scripts. Upon detection of task infections, we apply qualitative analysis to determine task infection categories. We also conduct a survey with 23 practitioners to determine the prevalence and severity of identified task infection categories. With logistic regression analysis, we identify development factors that correlate with presence of task infections.
Results In all, we identify 1,805 task infections in 27,213 scripts. We identify six task infection categories: anti-virus, continuous integration, data storage, message broker, networking, and virtualization. From our survey, we observe tasks used to manage data storage infrastructure perceived to have the most severe consequences. We also find three development factors, namely age, minor contributors, and scatteredness to correlate with the presence of task infections.
Conclusion Our empirical study shows computing infrastructure managed by Ansible scripts to be impacted by security weaknesses. We conclude the paper by discussing the implications of our findings for practitioners and researchers.},
keywords = {Ansible, Configuration script, Devops, Devsecops, Empirical study, Infrastructure as code, Security}
}

@article{SUHAIL2024100706,
title = {TRIPLE: A blockchain-based digital twin framework for cyber–physical systems security},
journal = {Journal of Industrial Information Integration},
volume = {42},
pages = {100706},
year = {2024},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2024.100706},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X24001493},
author = {Sabah Suhail and Mubashar Iqbal and Rasheed Hussain and Saif Ur Rehman Malik and Raja Jurdak},
keywords = {Blockchain, Cyber–physical system (CPS), Digital twin (DT), Threat intelligence (TI), Threat hunting},
abstract = {Cyber–physical systems (CPSs) are being increasingly adopted for industrial applications, yet they involve a dynamic threat landscape that requires CPSs to adapt to emerging threats during their operation. Recently, digital twin (DT) technology (which refers to a virtual representation of a product, process, or environment) has emerged as a suitable candidate to address the security challenges faced by dynamic CPSs. DT has the capability of strengthening the security of CPSs by continuously mapping the physical to twin counterparts to detect inconsistencies. The existing DT-based security solutions are constrained by untrustworthy data dissemination as well as limited data sharing among the involved stakeholders, which, in turn, limit the ability of DTs to run accurate simulations or make valid decisions. To address these challenges, this paper proposes a modular framework called TRusted and Intelligent cyber-PhysicaL systEm (TRIPLE), that leverages blockchain, DTs, and threat intelligence (TI) to secure CPSs. The blockchain-based DT components in the framework provide data integrity, traceability, and availability for trusted DTs. Furthermore, to accurately and comprehensively model system states, the framework envisions fusing process knowledge for modeling DTs from system specification-based and learning-based information and other sources, including infrastructure-as-code (IaC) and knowledge base (KB). The framework also integrates TI for future-proofing against emerging threats, such that threats can be detected either reactively by mapping the behavior of physical and virtual spaces or proactively by TI and threat hunting. We demonstrate the viability of the framework through a proof of concept. Finally, we formally verify the TRIPLE framework to demonstrate its correctness and effectiveness in enhancing CPS security.}
}
@article{ABE20222771,
title = {Neuroscience Cloud Analysis As a Service: An open-source platform for scalable, reproducible data analysis},
journal = {Neuron},
volume = {110},
number = {17},
pages = {2771-2789.e7},
year = {2022},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2022.06.018},
url = {https://www.sciencedirect.com/science/article/pii/S0896627322005876},
author = {Taiga Abe and Ian Kinsella and Shreya Saxena and E. Kelly Buchanan and Joao Couto and John Briggs and Sian Lee Kitt and Ryan Glassman and John Zhou and Liam Paninski and John P. Cunningham},
keywords = {data analysis, open source, cloud compute, infrastructure-as-code, widefield calcium imaging, ensembling, markerless tracking},
abstract = {Summary
A key aspect of neuroscience research is the development of powerful, general-purpose data analyses that process large datasets. Unfortunately, modern data analyses have a hidden dependence upon complex computing infrastructure (e.g., software and hardware), which acts as an unaddressed deterrent to analysis users. Although existing analyses are increasingly shared as open-source software, the infrastructure and knowledge needed to deploy these analyses efficiently still pose significant barriers to use. In this work, we develop Neuroscience Cloud Analysis As a Service (NeuroCAAS): a fully automated open-source analysis platform offering automatic infrastructure reproducibility for any data analysis. We show how NeuroCAAS supports the design of simpler, more powerful data analyses and that many popular data analysis tools offered through NeuroCAAS outperform counterparts on typical infrastructure. Pairing rigorous infrastructure management with cloud resources, NeuroCAAS dramatically accelerates the dissemination and use of new data analyses for neuroscientific discovery.}
}
@article{SCHWANCK2025107626,
title = {A Framework for testing Federated Learning algorithms using an edge-like environment},
journal = {Future Generation Computer Systems},
volume = {166},
pages = {107626},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.107626},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24005909},
author = {Felipe Machado Schwanck and Marcos Tomazzoli Leipnitz and Joel Luís Carbonera and Juliano Araujo Wickboldt},
keywords = {Federated learning, Edge computing, Kubernetes, Microservices, Development framework},
abstract = {Federated Learning (FL) is a machine learning paradigm in which many clients cooperatively train a single centralized model while keeping their data private and decentralized. FL is commonly used in edge computing, which involves placing computer workloads (both hardware and software) as close as possible to the edge, where data are created and where actions are occurring, enabling faster response times, greater data privacy, and reduced data transfer costs. However, due to the heterogeneous data distributions/contents of clients, it is non-trivial to accurately evaluate the contributions of local models in global centralized model aggregation. This is an example of a major challenge in FL, commonly known as data imbalance or class imbalance. In general, testing and evaluating FL algorithms can be a very difficult and complex task due to the distributed nature of the systems. In this work, a framework is proposed and implemented to evaluate FL algorithms in a more easy and scalable way. This framework is evaluated over a distributed edge-like environment managed by a container orchestration platform (i.e. Kubernetes).}
}
@article{ALMUAIRFI202013,
title = {Security controls in infrastructure as code},
journal = {Computer Fraud & Security},
volume = {2020},
number = {10},
pages = {13-19},
year = {2020},
issn = {1361-3723},
doi = {https://doi.org/10.1016/S1361-3723(20)30109-3},
url = {https://www.sciencedirect.com/science/article/pii/S1361372320301093},
author = {Sadiq Almuairfi and Mamdouh Alenezi},
abstract = {The development, deployment and management of software applications have shifted dramatically in the past 10 years. This fundamental shift is what we now know as development operations (DevOps). Infrastructure as Code (IaC) is one of the main tenets of DevOps. Previously, manual configuration via cloud providers’ UI consoles and physical hardware used to take place. But now, with the concept of IaC, the IT infrastructure can be automated by using blueprints that are easily readable by machines.}
}
@article{DALLAPALMA2020110726,
title = {Toward a catalog of software quality metrics for infrastructure code},
journal = {Journal of Systems and Software},
volume = {170},
pages = {110726},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110726},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301618},
author = {Stefano {Dalla Palma} and Dario {Di Nucci} and Fabio Palomba and Damian Andrew Tamburri},
keywords = {Infrastructure as code, Software metrics, Software quality},
abstract = {Infrastructure-as-code (IaC) is a practice to implement continuous deployment by allowing management and provisioning of infrastructure through the definition of machine-readable files and automation around them, rather than physical hardware configuration or interactive configuration tools. On the one hand, although IaC represents an ever-increasing widely adopted practice nowadays, still little is known concerning how to best maintain, speedily evolve, and continuously improve the code behind the IaC practice in a measurable fashion. On the other hand, source code measurements are often computed and analyzed to evaluate the different quality aspects of the software developed. However, unlike general-purpose programming languages (GPLs), IaC scripts use domain-specific languages, and metrics used for GPLs may not be applicable for IaC scripts. This article proposes a catalog consisting of 46 metrics to identify IaC properties focusing on Ansible, one of the most popular IaC language to date, and shows how they can be used to analyze IaC scripts.}
}
@article{DIAZ2024111908,
title = {Harmonizing DevOps taxonomies — A grounded theory study},
journal = {Journal of Systems and Software},
volume = {208},
pages = {111908},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2023.111908},
url = {https://www.sciencedirect.com/science/article/pii/S0164121223003035},
author = {Jessica Díaz and Jorge Pérez and Isaque Alves and Fabio Kon and Leonardo Leite and Paulo Meirelles and Carla Rocha},
keywords = {DevOps team structures, DevOps taxonomies, Grounded theory, Inter-coder agreement},
abstract = {Context:
DevOps responds to the growing need of companies to streamline the software development process and thus has experienced widespread adoption in the past few years. However, the successful adoption of DevOps requires companies to address important cultural and organizational changes. Nevertheless, it is crucial to recognize that various DevOps taxonomies exist, both from academic and practitioner perspectives, which may lead to misleading or failed adoption of DevOps.
Objective:
This paper presents empirical research on the structure of DevOps teams in software-producing organizations. The goal is to better understand the organizational structure and characteristics of teams adopting DevOps by harmonizing the existing knowledge.
Methods:
To achieve this, we employed a grounded theory approach with collaborative coding, involving two research groups. Inter-Coder Agreement (ICA) was utilized to guide the discussion rounds. We conducted a comprehensive analysis of existing studies on DevOps teams and taxonomies to gain a deeper understanding of the subject.
Results:
From the analysis, we built a substantive and analytic theory of DevOps taxonomies. The theory is substantive in that the scope of validity refers to the ten secondary studies processed and analytic in that it analyzes “what is” rather than explaining causality or attempting predictive generalizations. A public repository with all the data related to the products resulting from the analysis and generation of the theory is available.
Conclusions:
We built a theory on DevOps taxonomies and tested whether it harmonizes the existing taxonomies, i.e., whether our theory can instantiate the others. This is the first step to define which taxonomies are best suited to approach DevOps culture and practices according to the companies’ objectives and capabilities. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.}
}
@incollection{POSEY2018153,
title = {6 - Infrastructure for Transportation Cyber-Physical Systems},
editor = {Lipika Deka and Mashrur Chowdhury},
booktitle = {Transportation Cyber-Physical Systems},
publisher = {Elsevier},
pages = {153-171},
year = {2018},
isbn = {978-0-12-814295-0},
doi = {https://doi.org/10.1016/B978-0-12-814295-0.00006-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012814295000006X},
author = {Brandon Posey and Linh Bao Ngo and Mashrur Chowdhury and Amy Apon},
keywords = {Cyber-physical systems, Data collection, Hadoop MapReduce, HDFS, Lambda architecture, RDBMS},
abstract = {In transportation cyber-physical systems (TCPS), data are collected from different transportation modes and from a wide variety of data collection devices. TCPS data have characteristics that can be described using ‘5Vs of big data’: (1) volume, (2) variety, (3) velocity, (4) veracity and (5) value (Demchenko et al., 2013) . Volume represents the raw amount of data to be stored. Velocity represents the rate at which data are being collected and inserted into the data infrastructure and how fast the back end services are expected to process these data streams. The variety aspect arises from the fact that in a data-driven environment, it is inevitable for service providers to collect and combine data from numerous different sources for creating actionable insights. As a result, data will come into the infrastructure under different data formats. With increases in data size, rate of data arrival and number of data sources, the reliability of data contents will certainly decrease. This is the veracity aspect. The final V, value, represents the desired outcome for investing in TCPS data, because all efforts are for nought if usable insights cannot be generated from the data. All of these characteristics make traditional database management systems and conventional data processing and delivery systems inappropriate for many types of transportation data analysis and decision support tasks. An enormous amount of heterogeneous data cannot be processed in real time. This chapter introduces the modern data infrastructures that are needed to support TCPS. The focus is on open-source hardware and software technologies that support data management and delivery systems. The chapter also includes a discussion of infrastructure as code that can leverage emerging commercial cloud facilities.}
}
@article{FEITOSA2024112112,
title = {Mining for cost awareness in the infrastructure as code artifacts of cloud-based applications: An exploratory study},
journal = {Journal of Systems and Software},
volume = {215},
pages = {112112},
year = {2024},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112112},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224001572},
author = {Daniel Feitosa and Matei-Tudor Penca and Massimiliano Berardi and Rares-Dorian Boza and Vasilios Andrikopoulos},
keywords = {Cloud computing, Cost awareness, Mining software repositories, Cloud orchestration},
abstract = {Context:
Cloud computing’s rise as the primary platform for software development and delivery is largely driven by the potential cost savings. However, it is surprising that no empirical evidence has been collected to determine whether cost awareness permeates the development process and how it manifests in practice.
Objective:
This study aims to provide empirical evidence of cost awareness by mining open source repositories of cloud-based applications. The focus is on Infrastructure-as-Code artifacts that automate software (re)deployment on the cloud.
Methods:
A systematic examination of 152735 repositories yielded 2010 relevant hits. We then analyzed 538 relevant commits and 208 relevant issues using inductive and deductive coding and corroborated findings with discussions from Stack Overflow.
Results:
The findings indicate that developers are not only concerned with the cost of their application deployments but also take actions to reduce these costs beyond selecting cheaper cloud services. We also identify research areas for future consideration.
Conclusion:
Although we focus on a particular Infrastructure-as-Code technology (Terraform), the findings can be applicable to cloud-based application development in general. The provided empirical grounding can serve developers seeking to reduce costs through service selection, resource allocation, deployment optimization, and other techniques.}
}
@article{AMARO2025107583,
title = {Mapping DevOps capabilities to the software life cycle: A systematic literature review},
journal = {Information and Software Technology},
volume = {177},
pages = {107583},
year = {2025},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2024.107583},
url = {https://www.sciencedirect.com/science/article/pii/S0950584924001885},
author = {Ricardo Amaro and Rúben Pereira and Miguel Mira {da Silva}},
keywords = {DevOps, Metrics, Performance, Adoption, Software development life cycle, Information system},
abstract = {Context:
Many IT organizations are looking towards DevOps to make their software development and delivery processes faster and more reliable, while DevOps revolutionized the industry by emphasizing collaboration between development and operations teams. Nonetheless, there still exist challenges in harmonizing cultural, technical, measurement and process capabilities for its successful adoption.
Objective:
To research improving DevOps adoption, this study explores DevOps Capabilities relevant to the Life Cycle Processes (LCPs) of the IEEE 2675-2021 DevOps standard. Aiming to provide valuable information on increasing efficiency and outcomes by mapping DevOps Capabilities in each phase of the LCPs. Whereas previous research identified and classified 37 DevOps Capabilities, this study aims to determine which capabilities can enhance each of the 30 phases of the LCPs.
Methods:
Out of 102 documents identified in the Systematic Literature Review (SLR), relations among DevOps Capabilities and LCPs have been synthesized and organized. An in-depth analysis of data was conducted over the connections across various categories. The mapping revealed how they relate in terms of their application and impact.
Results:
The SLR shows technical DevOps Capabilities and technical LCPs strongly correlated. DevOps measurement capabilities have a significant impact on agreement processes. Using an impact scale classification, the study identifies eight capabilities that have exceptional impact on LCPs and eleven capabilities that have a very high impact on the supply process, requirements definition, integration process, and validation process.
Conclusion:
The study demonstrates how DevOps Capabilities together with LCPs can improve software delivery, quality, and reliability. It presents a structured approach for improving processes, as well as evidence of DevOps integration in software development and maintenance. The findings help to assess DevOps Capabilities and LCP relations, which is expected to improve successful adoption. Future research should focus on researching practical cases of DevOps integration into LCPs, while overcoming adoption challenges.}
}
@article{TANZIL2023107244,
title = {A mixed method study of DevOps challenges},
journal = {Information and Software Technology},
volume = {161},
pages = {107244},
year = {2023},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2023.107244},
url = {https://www.sciencedirect.com/science/article/pii/S0950584923000988},
author = {Minaoar Hossain Tanzil and Masud Sarker and Gias Uddin and Anindya Iqbal},
keywords = {DevOps, CI/CD, Jenkins, Infrastructure as code},
abstract = {Context:
DevOps practices combine software development and IT (Information Technology) operations. The continuous needs for rapid but quality software development requires the adoption of high-quality DevOps tools. There is a growing number of DevOps related posts in popular online developer forum Stack Overflow (SO). While previous research analyzed SO posts related to build/release engineering, we are aware of no research that specifically focused on DevOps related discussions.
Objective:
This paper aims to learn the challenges developers face while using the currently available DevOps tools and techniques along with the organizational challenges in DevOps practices.
Method:
We conduct an empirical study by applying topic modeling on 174K SO posts that contain DevOps discussions. We then validate and extend the empirical study findings with a survey of 21 professional DevOps practitioners.
Results:
We find that: (1) There are 23 DevOps topics grouped into four categories: Cloud & CI/CD Tools, Infrastructure as Code, Container & Orchestration, and Quality Assurance. (2) The topic category ‘Cloud & CI/CD Tools’ contains the highest number of topics (10) which cover 48.6% of all questions in our dataset, followed by the category Infrastructure as Code (28.9%). (3) The file management is the most popular topic followed by Jenkins Pipeline, while infrastructural Exception Handling and Jenkins Distributed Architecture are the most difficult topics (with least accepted answers). (4) In the survey, developers mention that it requires hands-on experience before current DevOps tools can be considered easy. They raised the needs for better documentation and learning resources to learn the rapidly changing DevOps tools and techniques. Practitioners also emphasized on the formal training approach by the organizations for DevOps skill development.
Conclusion:
Architects and managers can use the findings of this research to adopt appropriate DevOps technologies, and organizations can design tool or process specific DevOps training programs.}
}
@article{VS2023103490,
title = {Container security: Precaution levels, mitigation strategies, and research perspectives},
journal = {Computers & Security},
volume = {135},
pages = {103490},
year = {2023},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2023.103490},
url = {https://www.sciencedirect.com/science/article/pii/S0167404823004005},
author = {Devi Priya {V S} and Sibi {Chakkaravarthy Sethuraman} and Muhammad Khurram Khan},
keywords = {Microservices, Software development, Container security- root-based and rootless, Threat modeling-attack trees, DREAD},
abstract = {The enterprise technique for application deployment has undergone a major transformation during the past two decades. Using conventional techniques, software developers write code in a particular computing environment, frequently leading to mistakes and defects when moving it to a new computing environment. However, during the past few years, enterprises have begun to use containers & microservices to segregate infrastructure in a particular perspective and develop new models of the technology stack. Software developers could construct and deploy apps more quickly and effectively now, thanks to containerization. Despite the fact that containers have their own namespace, it is still feasible for a containerized image to attack the host system by inserting malicious software into it. This necessitates threat modeling of the container life span. During the investigation, we were able to create the elemental systematic modelling that identifies threats pertaining to container application workflow and its preliminary mitigation techniques, where attack trees are defined alongside the model, which helps academics and enthusiasts better comprehend the significance of container security. We utilize the well-known threat modeling framework, DREAD, to further advance threat modeling across the infrastructure of containers that aids in prioritizing the risks. Additionally, tools for assessing container vulnerabilities and discrete real-world exploits were researched, and approaches for security analysis in container technology were compared to the existing literature. Finally, this study brings to a conclusion by outlining the state-of-the-art survey for future research and identifying potential research topics in server-based and serverless containers.}
}
@article{DALLAPALMA2020100633,
title = {AnsibleMetrics: A Python library for measuring Infrastructure-as-Code blueprints in Ansible},
journal = {SoftwareX},
volume = {12},
pages = {100633},
year = {2020},
issn = {2352-7110},
doi = {https://doi.org/10.1016/j.softx.2020.100633},
url = {https://www.sciencedirect.com/science/article/pii/S2352711020303460},
author = {Stefano {Dalla Palma} and Dario {Di Nucci} and Damian A. Tamburri},
keywords = {Infrastructure as Code, Software metrics, Software quality},
abstract = {Infrastructure-as-Code (IaC) has recently received increasing attention in the research community, mainly due to the paradigm shift it brings in software design, development, and operations management. However, while IaC represents an ever-increasing and widely adopted practice, concerns arise about the need for instruments that help DevOps engineers efficiently maintain, speedily evolve, and continuously improve Infrastructure-as-Code. In this paper, we present AnsibleMetrics, a Python-based static source code measurement tool to characterize Infrastructure-as-Code. Although we focus on Ansible, the most used language for IaC, our tool could be easily extended to support additional formats. AnsibleMetrics represents a step forward towards software quality support for DevOps engineers developing and maintaining infrastructure code.}
}
@article{RAHMAN2019148,
title = {Source code properties of defective infrastructure as code scripts},
journal = {Information and Software Technology},
volume = {112},
pages = {148-163},
year = {2019},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2019.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S0950584919300965},
author = {Akond Rahman and Laurie Williams},
keywords = {Configuration as code, Continuous deployment, Defect prediction, Devops, Empirical study, Infrastructure as code, Puppet},
abstract = {Context
In continuous deployment, software and services are rapidly deployed to end-users using an automated deployment pipeline. Defects in infrastructure as code (IaC) scripts can hinder the reliability of the automated deployment pipeline. We hypothesize that certain properties of IaC source code such as lines of code and hard-coded strings used as configuration values, show correlation with defective IaC scripts.
Objective
The objective of this paper is to help practitioners in increasing the quality of infrastructure as code (IaC) scripts through an empirical study that identifies source code properties of defective IaC scripts.
Methodology
We apply qualitative analysis on defect-related commits mined from open source software repositories to identify source code properties that correlate with defective IaC scripts. Next, we survey practitioners to assess the practitioner’s agreement level with the identified properties. We also construct defect prediction models using the identified properties for 2439 scripts collected from four datasets.
Results
We identify 10 source code properties that correlate with defective IaC scripts. Of the identified 10 properties we observe lines of code and hard-coded string i.e. putting strings as configuration values, to show the strongest correlation with defective IaC scripts. According to our survey analysis, majority of the practitioners show agreement for two properties: include, the property of executing external modules or scripts, and hard-coded string. Using the identified properties, our constructed defect prediction models show a precision of 0.70∼0.78, and a recall of 0.54∼0.67.
Conclusion
Based on our findings, we recommend practitioners to allocate sufficient inspection and testing efforts on IaC scripts that include any of the identified 10 source code properties of IaC scripts.}
}
@incollection{KAVITHA2025,
title = {Agile Software Development: DevOps, SRE, and VSM Practices & Tools},
series = {Advances in Computers},
publisher = {Elsevier},
year = {2025},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2025.06.011},
url = {https://www.sciencedirect.com/science/article/pii/S0065245825001020},
author = {K. Kavitha},
keywords = {DevOps, Site reliability engineering (SRE), Value stream mapping (VSM), Agile software development, Continuous integration and continuous delivery (CI/CD), Infrastructure as code (IaC)},
abstract = {Modern engineering techniques are being used by enterprises to improve agility, reliability and efficiency in quick changing sectors of software development. Devops, or development and operation, encourages cooperation between IT operations and development, facilitates continuous integration for quick software release and pipelines for continuous distribution (CI/CD). To automate procedures, maintain the system reliability, and improve observation, the site reliability engineering (SRE) software integrates engineering concepts and creates on devops. Software delivery pipelines have a structured method price stream mapping (VSM) to detect disabilities, streamline processes and remove bottlenecks. In this chapter, a combination of DevOps, SRE and VSM is examined how it affects playful software development. To improve software quality and user experience, it covers important techniques including codes (IAC), automatic monitoring, issue management and infrastructure in the form of response loops. This value also examines major equipment including stream analytics platform, kubernets, terraforms, and prometheus. In a rapid digital world, companies can increase customer happiness, increase flexibility, and speed up growth cycles using these approaches.}
}
@article{ALGHAWLI2024136,
title = {Resilient cloud cluster with DevSecOps security model, automates a data analysis, vulnerability search and risk calculation},
journal = {Alexandria Engineering Journal},
volume = {107},
pages = {136-149},
year = {2024},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2024.07.036},
url = {https://www.sciencedirect.com/science/article/pii/S1110016824007567},
author = {Abed Saif Ahmed Alghawli and Tamara Radivilova},
keywords = {Digitalization, DevSecOps, Cybersecurity, Risk assessment, FAIR methodology},
abstract = {Automated, secure software development is an important digitalization task, solved with the DevSecOps approach. An important part of the DevSecOps approach is continuous risk assessment, which is necessary to identify and evaluate risk factors. Combining the development cycle with continuous risk assessment creates software development and operation synergies and minimizes vulnerabilities. The article presents the main methods of deploying web applications and ways to increase information security at all stages of product development. It also compares different types of infrastructures and cloud computing providers and analyzes modern tools used to automate processes. The cloud cluster was deployed using Terraform and the Jenkins pipeline, written in the Groovy programming language, which checks program code for vulnerabilities and allows you to fix violations at the earliest stages of developing secure web applications. The developed cluster implements the proposed algorithm for automated risk assessment based on the calculation (modeling) of cloud infrastructure threats and vulnerabilities, which operates in real-time, periodically collecting all information and adjusting the system according to the risk and applied controls. The algorithm for calculating risk and losses is based on statistical data and FAIR information risk assessment methodology. The risk value obtained using the proposed method is quantitative, which allows more efficient forecasting of information security costs in software development.}
}
@article{QUEVAL2025107761,
title = {On the understandability of coupling-related practices in infrastructure-as-code based deployments},
journal = {Information and Software Technology},
volume = {185},
pages = {107761},
year = {2025},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2025.107761},
url = {https://www.sciencedirect.com/science/article/pii/S0950584925001004},
author = {Pierre-Jean Quéval and Nicole Elisabeth Hörner and Evangelos Ntentos and Uwe Zdun},
keywords = {Infrastructure as code, Modeling, Best practices, Controlled experiment, Empirical software engineering, Empirical study},
abstract = {Infrastructure as Code (IaC) empowers software developers and operations teams to automate the deployment and management of IT infrastructure through code. This is particularly valuable for continuously released deployments such as microservices and cloud-based systems. IaC technologies offer flexibility in provisioning and deploying application architectures. However, if the structure is not well-designed, it can lead to severe issues related to coupling aspects. Unfortunately, a lack of comprehensive coupling guidelines for IaC makes ensuring adherence to best practices challenging. Leveraging IaC-based models, metrics, and source code can enhance the comprehension and implementation of coupling measures. Our objective was to investigate how developers understand information derived from system source code and compare it to formal IaC system diagrams and metrics. We conducted a controlled experiment involving a group of participants to evaluate the understandability of IaC system architecture descriptions through source code inspection and formal representations. We hypothesized that providing formal IaC system diagrams and metrics as supplementary materials would improve the understanding of IaC coupling-related practices measured by task correctness. We also expected that these supplementary resources would lead to a significant increase in task duration and that there would be a notable correlation between correctness and duration. The results suggest that including formal IaC system diagrams and metrics as supplementary materials significantly enhances the comprehension of IaC coupling-related practices, as indicated by task correctness. Moreover, providing these formal representations does not significantly prolong task duration, indicating that they do not hinder understanding. A substantial correlation between task correctness and duration is evident when formal IaC system diagrams and metrics are available.}
}
@article{MORRIS2017105,
title = {Use of Docker for deployment and testing of astronomy software},
journal = {Astronomy and Computing},
volume = {20},
pages = {105-119},
year = {2017},
issn = {2213-1337},
doi = {https://doi.org/10.1016/j.ascom.2017.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S2213133717300161},
author = {D. Morris and S. Voutsinas and N.C. Hambly and R.G. Mann},
keywords = {Docker, Survey astronomy, DevOps, Reproducible science, Containerization, Virtualization},
abstract = {We describe preliminary investigations of using Docker for the deployment and testing of astronomy software. Docker is a relatively new containerization technology that is developing rapidly and being adopted across a range of domains. It is based upon virtualization at operating system level, which presents many advantages in comparison to the more traditional hardware virtualization that underpins most cloud computing infrastructure today. A particular strength of Docker is its simple format for describing and managing software containers, which has benefits for software developers, system administrators and end users. We report on our experiences from two projects – a simple activity to demonstrate how Docker works, and a more elaborate set of services that demonstrates more of its capabilities and what they can achieve within an astronomical context – and include an account of how we solved problems through interaction with Docker’s very active open source development community, which is currently the key to the most effective use of this rapidly-changing technology.}
}
@article{RUSSO2020101837,
title = {Building next generation Cyber Ranges with CRACK},
journal = {Computers & Security},
volume = {95},
pages = {101837},
year = {2020},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2020.101837},
url = {https://www.sciencedirect.com/science/article/pii/S0167404820301103},
author = {Enrico Russo and Gabriele Costa and Alessandro Armando},
keywords = {Cyber Range, Cybersecurity, Training, Automated design, Scenario verification},
abstract = {Cyber Ranges are complex infrastructures hosting high quality exercises that simulate cybersecurity scenarios of real-world complexity. Building the computing infrastructure is only the first step towards the successful execution of the cyber exercises. The design, verification and deployment of scenarios are costly and error-prone activities. As a matter of fact, a misconfiguration in the scenario can compromise the exercise and the training goals. This makes the design, development, and deployment of live-fire cyber exercises of real-world complexity so expensive that can be afforded only by a limited number of organizations. In this paper we present CRACK, a framework for the (i) design, (ii) model verification, (iii) generation, and (iv) automated testing of cyber scenarios. We introduce the CRACK SDL, a Scenario Definition Language based on TOSCA, an OASIS standard for the specification and orchestration of virtual infrastructures. CRACK SDL allows for the declarative specification of the scenario elements and their interplay, e.g., a vulnerability affecting a system. Through a formal encoding of the properties of an SDL specification, CRACK also supports the automatic verification of a scenario against its training objectives. After a successful verification, the scenario is automatically deployed in the Cyber Range and automatically tested to check the correspondence between the behavior of the deployed system and its specification. The key functionalities offered by CRACK are presented through a simple, yet representative case study. Experimental results confirm the effectiveness of the proposed approach.}
}
@article{RAHMAN201965,
title = {A systematic mapping study of infrastructure as code research},
journal = {Information and Software Technology},
volume = {108},
pages = {65-77},
year = {2019},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2018.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0950584918302507},
author = {Akond Rahman and Rezvan Mahdavi-Hezaveh and Laurie Williams},
keywords = {Devops, Configuration as code, Configuration script, Continuous deployment, Infrastructure as code, Software engineering, Systematic mapping study},
abstract = {Context: Infrastructure as code (IaC) is the practice to automatically configure system dependencies and to provision local and remote instances. Practitioners consider IaC as a fundamental pillar to implement DevOps practices, which helps them to rapidly deliver software and services to end-users. Information technology (IT) organizations, such as GitHub, Mozilla, Facebook, Google and Netflix have adopted IaC. A systematic mapping study on existing IaC research can help researchers to identify potential research areas related to IaC, for example defects and security flaws that may occur in IaC scripts. Objective: The objective of this paper is to help researchers identify research areas related to infrastructure as code (IaC) by conducting a systematic mapping study of IaC-related research. Method: We conduct our research study by searching five scholar databases. We collect a set of 31,498 publications by using seven search strings. By systematically applying inclusion and exclusion criteria, which includes removing duplicates and removing non-English and non peer-reviewed publications, we identify 32 publications related to IaC. We identify topics addressed in these publications by applying qualitative analysis. Results: We identify four topics studied in IaC-related publications: (i) framework/tool for infrastructure as code; (ii) adoption of infrastructure as code; (iii) empirical study related to infrastructure as code; and (iv) testing in infrastructure as code. According to our analysis, 50.0% of the studied 32 publications propose a framework or tool to implement the practice of IaC or extend the functionality of an existing IaC tool. Conclusion: Our findings suggest that framework or tools is a well-studied topic in IaC research. As defects and security flaws can have serious consequences for the deployment and development environments in DevOps, we observe the need for research studies that will study defects and security flaws for IaC.}
}
@article{OPDEBEECK2021111059,
title = {On the practice of semantic versioning for Ansible galaxy roles: An empirical study and a change classification model},
journal = {Journal of Systems and Software},
volume = {182},
pages = {111059},
year = {2021},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2021.111059},
url = {https://www.sciencedirect.com/science/article/pii/S0164121221001564},
author = {Ruben Opdebeeck and Ahmed Zerouali and Camilo Velázquez-Rodríguez and Coen {De Roover}},
keywords = {Ansible, Infrastructure as code, Semantic versioning, Empirical study, Mining software repositories},
abstract = {Ansible, a popular Infrastructure-as-Code platform, provides reusable collections of tasks called roles. Roles are often contributed by third parties, and like general-purpose libraries, they evolve. Therefore, new releases of roles need to be tagged with version numbers, for which Ansible recommends adhering to the semantic versioning format. However, roles significantly differ from general-purpose libraries, and it is not yet known what constitutes a breaking change or the addition of a feature to a role. Consequently, this can cause confusion for clients of a role and new role contributors. To alleviate this issue, we perform an empirical study on semantic versioning in Ansible roles to uncover the types of changes that trigger certain types of version bumps. Our dataset consists of over 81000 version increments spanning upwards of 8500 Ansible roles. We design a novel structural model for these roles, and implement a domain-specific structural change extraction algorithm to calculate structural difference metrics. Afterwards, we quantitatively investigate the state of semantic versioning in Ansible roles and identify the most commonly changed elements. Then, using the structural difference metrics, we train a Random Forest classifier to predict applicable version bumps for Ansible role releases. Finally, we confirm our empirical findings with a developer survey. Our observations show that although most Ansible role developers follow the semantic versioning format, it appears that they do not always consistently follow the same rules when selecting the version bump to apply. Moreover, we find that the distinction between patch and minor increments is often unclear. Therefore, we use the gained insights to formulate a number of guidelines to apply semantic versioning on Ansible roles. These guidelines can be used by role developers to ensure a clear interpretation of the version increments.}
}
@article{R2024660,
title = {An Empirical Investigation of Docker Sockets for Privilege Escalation and Defensive Strategies},
journal = {Procedia Computer Science},
volume = {233},
pages = {660-669},
year = {2024},
note = {5th International Conference on Innovative Data Communication Technologies and Application (ICIDCA 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.03.255},
url = {https://www.sciencedirect.com/science/article/pii/S187705092400615X},
author = {Rajyashree R and Senthilkumar Mathi and Saravanan G and Sakthivel M},
keywords = {Attack, Containerization, Data heist, Docker, Malware, Virtualization, Vulnerabilities},
abstract = {Cloud-based infrastructures often leverage virtualization, but its implementation can be expensive. Traditional coding methods can lead to issues when transitioning code from one computing environment to another. In response, the container paradigm emerged to offer cost-effective and agile delivery. Containers differ from full machine virtualization by compactly encapsulating the entire software and its dependencies. Leveraging containers, developers can create more secure and efficient applications. Docker, a prominent containerization platform, facilitates the execution of docker images. The Docker Hub serves as a popular repository for various images. Given the importance of application security, especially in the face of threats like malware, ransomware, and data breaches, ensuring robust security is imperative. The paper investigates vulnerabilities within Docker containers and proposes defensive strategies to mitigate potential breaches. In addition, it investigates attacks involving Docker sockets and suggests preventive measures for non-root users.}
}
@article{CASTELLANOSRODRIGUEZ2024256,
title = {Serverless-like platform for container-based YARN clusters},
journal = {Future Generation Computer Systems},
volume = {155},
pages = {256-271},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X2400058X},
author = {Óscar Castellanos-Rodríguez and Roberto R. Expósito and Jonatan Enes and Guillermo L. Taboada and Juan Touriño},
keywords = {Serverless computing, Big Data, Hadoop YARN, Resource scaling, Container cluster, Infrastructure as Code},
abstract = {Serverless computing is an emerging paradigm that has gained a lot of relevance in recent years, as it allows users to consume computing resources without worrying about the underlying infrastructure and pay only for what they actually use. Most current services that implement this paradigm typically rely on the Function-as-a-Service (FaaS) model, which works perfectly for simple applications based on stateless functions triggered by specific events. However, these services are not designed to run more complex applications with intricate interactions, usually presenting a significant degree of configuration difficulty and/or low ability to customise the execution environment. They also tend to be designed for short and simple workloads, with some services even limiting their maximum runtime to just a few minutes. In this paper, we present a platform based on Hadoop YARN oriented to the execution of Big Data workloads in a containerised and serverless way, so that the resources allocated to such containers are automatically and dynamically scaled according to their actual usage. An experimental evaluation has been carried out to compare our serverless-like platform with a standard YARN deployment when executing Big Data workloads concurrently. Our results have shown experimental evidence of enhancing both performance and overall resource efficiency, providing runtime reductions and resource usage improvements of up to 41% and 50%, respectively.}
}
@article{KUMARA2021106593,
title = {The do’s and don’ts of infrastructure code: A systematic gray literature review},
journal = {Information and Software Technology},
volume = {137},
pages = {106593},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106593},
url = {https://www.sciencedirect.com/science/article/pii/S0950584921000720},
author = {Indika Kumara and Martín Garriga and Angel Urbano Romeu and Dario {Di Nucci} and Fabio Palomba and Damian Andrew Tamburri and Willem-Jan {van den Heuvel}},
keywords = {Infrastructure-as-code, DevOps, Gray literature review},
abstract = {Context:
Infrastructure-as-code (IaC) is the DevOps tactic of managing and provisioning software infrastructures through machine-readable definition files, rather than manual hardware configuration or interactive configuration tools.
Objective:
From a maintenance and evolution perspective, the topic has picked the interest of practitioners and academics alike, given the relative scarcity of supporting patterns and practices in the academic literature. At the same time, a considerable amount of gray literature exists on IaC. Thus we aim to characterize IaC and compile a catalog of best and bad practices for widely used IaC languages, all using gray literature materials.
Method:
In this paper, we systematically analyze the industrial gray literature on IaC, such as blog posts, tutorials, white papers using qualitative analysis techniques.
Results:
We proposed a definition for IaC and distilled a broad catalog summarized in a taxonomy consisting of 10 and 4 primary categories for best practices and bad practices, respectively, both language-agnostic and language-specific ones, for three IaC languages, namely Ansible, Puppet, and Chef. The practices reflect implementation issues, design issues, and the violation of/adherence to the essential principles of IaC.
Conclusion:
Our findings reveal critical insights concerning the top languages as well as the best practices adopted by practitioners to address (some of) those challenges. We evidence that the field of development and maintenance IaC is in its infancy and deserves further attention.}
}
@incollection{BROJABASI2025,
title = {Cloud native engineering: A comprehensive review of principles, practices, and challenges},
series = {Advances in Computers},
publisher = {Elsevier},
year = {2025},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2025.06.013},
url = {https://www.sciencedirect.com/science/article/pii/S0065245825001044},
author = {Subhajit Brojabasi and Subrata Paul and Anirban Mitra},
keywords = {Cloud native engineering, Microservices, Container orchestration, DevOps, Observability, Security, Edge computing},
abstract = {The innovative technique known as "cloud native engineering" has revolutionized the art and science of modern software development by redesigning the architecture, development, and deployment of software to maximize the advantages of cloud computing. Based on insights gleaned from published studies, industry practices, and empirical findings, the current review paper provides an inclusive assessment of the fundamental concepts, required methods, and inherent challenges that come with cloud native engineering. We look at popular architectural patterns such as serverless computing, microservices, and service mesh, as well as automation strategies enabled by infrastructure as code (IaC), container orchestration, and continuous integration and deployment (CI/CD). We also go over operational procedures that enhance cloud native environments’ scalability, robustness, and efficiency. Strong solutions are required to handle compliance, threat detection, and system stability as security, monitoring, and observability become crucial factors. The use of AI and machine learning to enhance cloud operations, as well as performance optimization techniques, are also covered in the article. Finally, we discuss future trends including edge computing, multi-cloud methods, and green cloud practices, outlining key areas of research that will shape cloud native engineering in the future.}
}
@article{PETROVIC2020102033,
title = {SMADA-Fog: Semantic model driven approach to deployment and adaptivity in fog computing},
journal = {Simulation Modelling Practice and Theory},
volume = {101},
pages = {102033},
year = {2020},
note = {Modeling and Simulation of Fog Computing},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2019.102033},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X19301649},
author = {Nenad Petrovic and Milorad Tosic},
keywords = {DevOps, Fog Computing, Infrastructure as code, Linear optimization, Model-driven engineering, Semantic technology},
abstract = {The deployment, monitoring and configuration of applications in Fog Computing are becoming quite challenging, due to heterogeneity of mobile and IoT devices involved, data movement constraints imposed by legal regulations as well as frequent changes in the execution environment that may affect quality of service. As a consequence, the system administration procedures are becoming more complex and time-consuming, especially if done manually. In this paper, a Semantic Model driven Approach to Deployment and Adaptivity of container-based applications in Fog Computing (SMADA-Fog) is proposed. Modeling tools, semantic framework, linear optimization model, simulation environment and infrastructure management code generator leveraging the semantic annotations are implemented and presented. According to results of the two experimentally tested scenarios, the proposed approach improves the application performance, while the time required for deployment as well as service adaptation is reduced for at least an order of magnitude.}
}
@article{PANDEY2023102348,
title = {Stochastic modelling of non-stationary environmental loads for reliability analysis under the changing climate},
journal = {Structural Safety},
volume = {103},
pages = {102348},
year = {2023},
issn = {0167-4730},
doi = {https://doi.org/10.1016/j.strusafe.2023.102348},
url = {https://www.sciencedirect.com/science/article/pii/S0167473023000358},
author = {Mahesh D. Pandey and Z. Lounis},
keywords = {Climate change, Non-stationary loads, Non-homogeneous poisson process, Return period, Extreme value distribution, Structural reliability},
abstract = {In recent years, a rapid pace of climate change is becoming evident by a marked increase in the frequency and intensity of weather extremes, and this trend is expected to continue with an increase in global warming for decades to come. The paper presents the non-homogeneous Poisson process as a basis to model an environmental load process induced by non-stationary climate conditions. The distribution of maximum load generated by a non-stationary process is derived, which explicitly accounts for the loading frequency and intensity amplification over time. Using this distribution, structural reliability can be computed for any given time interval in future. The paper shows that traditional measures like the return period, extreme percentiles, and the annual probability of failure, would vary with time under the changing climate. Examples presented in the paper show that a modest amplification of the load magnitude has a drastic negative effect on reliability than that of the frequency of loading. Probabilistic models presented in this paper will be useful in revising currently used “stationary” design codes and ensuring a consistent level of safety in the non-stationary climate.}
}
@article{APEANING2025104342,
title = {Mapping household energy vulnerabilities in the United States: New insights from statistical and machine learning analyses},
journal = {Energy Research & Social Science},
volume = {129},
pages = {104342},
year = {2025},
issn = {2214-6296},
doi = {https://doi.org/10.1016/j.erss.2025.104342},
url = {https://www.sciencedirect.com/science/article/pii/S2214629625004232},
author = {Raphael Apeaning and Musah Labaran and Mohammed Osman},
keywords = {Energy vulnerability, Energy insecurity, Energy justice, Racial disparities, Machine learning, SHAP values},
abstract = {We deploy a two-stage, theory-driven framework to diagnose household energy vulnerability in the United States using the 2020 Residential Energy Consumption Survey. The first step employs a Latent Class Analysis with covariates to extract three capability-based profiles—Secured, Cost-Stressed, and Vulnerable—within a single, coherent likelihood framework. The second step fits a LightGBM model interpreted through SHapley Additive exPlanations (SHAP) to rank the underlying drivers behind each profile. Households earning < $50,000, living in poorly insulated single-family homes, and exposed to high regional energy prices are most likely to fall into the Vulnerable class. The risk intensifies for larger, Black, and female-headed households and for those residing in climates with high heating or cooling degree-day loads. The Cost-Stressed class is driven mainly by large floor area, “other rental” tenure, and moderate incomes ($50,000–$74,999); inadequate insulation and employment insecurity further elevate risk. These findings expose the heterogeneity of U.S. energy hardship and identify distinct leverage points for policy. Embedding such differentiated strategies within federal and state energy-justice initiatives can more equitably reduce household energy burdens and advance capability-based well-being across demographic and regional lines.}
}
@article{ARTICO2022102714,
title = {The future of Artificial Intelligence for the BioTech Big Data landscape},
journal = {Current Opinion in Biotechnology},
volume = {76},
pages = {102714},
year = {2022},
issn = {0958-1669},
doi = {https://doi.org/10.1016/j.copbio.2022.102714},
url = {https://www.sciencedirect.com/science/article/pii/S0958166922000477},
author = {Fausto Artico and Arthur L {Edge III} and Kyle Langham},
abstract = {Recent Industry 4.0 advancements are making available massive amounts of data for the development of innovative BioTech solutions. However, several challenges need to be overcome to correctly use data and novel, non-pharma technologies to greatly speed up discovery, optimization and market delivery of products, and services. In this review, we bring your attention to the important aspects of Big Data and Artificial Intelligence (AI) that have an impact on the future of the field and briefly touch upon how disciplines such as Hyper-Automation, Infrastructure as Code (IaC) and DevOps — a set of practices that combines software development with Information Technology (IT) operations (Ops) — can accelerate Big Data and AI adoption in your Agile Digital Transformation journey.}
}
@article{CHIARI2024102422,
title = {DOML: A new modeling approach to Infrastructure-as-Code},
journal = {Information Systems},
volume = {125},
pages = {102422},
year = {2024},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2024.102422},
url = {https://www.sciencedirect.com/science/article/pii/S0306437924000802},
author = {Michele Chiari and Bin Xiang and Sergio Canzoneri and Galia Novakova Nedeltcheva and Elisabetta {Di Nitto} and Lorenzo Blasi and Debora Benedetto and Laurentiu Niculut and Igor Škof},
keywords = {DOML, Infrastructure-as-Code, DevOps, IaC Modeling languages, Multi-layer modeling approach, Evaluation},
abstract = {One of the main DevOps practices is the automation of resource provisioning and deployment of complex software. This automation is enabled by the explicit definition of Infrastructure-as-Code (IaC), i.e., a set of scripts, often written in different modeling languages, which defines the infrastructure to be provisioned and applications to be deployed. We introduce the DevOps Modeling Language (DOML), a new Cloud modeling language for infrastructure deployments. DOML is a modeling approach that can be mapped into multiple IaC languages, addressing infrastructure provisioning, application deployment and configuration. The idea behind DOML is to use a single modeling paradigm which can help to reduce the need of deep technical expertise in using different specialized IaC languages. We present the DOML’s principles and discuss the related work on IaC languages. Furthermore, the advantages of the DOML for the end-user are demonstrated in comparison with some state-of-the-art IaC languages such as Ansible, Terraform, and Cloudify, and an evaluation of its effectiveness through several examples and a case study is provided.}
}
@article{MATSCHINSKE2023,
title = {The FeatureCloud Platform for Federated Learning in Biomedicine: Unified Approach},
journal = {Journal of Medical Internet Research},
volume = {25},
year = {2023},
issn = {1438-8871},
doi = {https://doi.org/10.2196/42621},
url = {https://www.sciencedirect.com/science/article/pii/S1438887123005241},
author = {Julian Matschinske and Julian Späth and Mohammad Bakhtiari and Niklas Probul and Mohammad Mahdi {Kazemi Majdabadi} and Reza Nasirigerdeh and Reihaneh Torkzadehmahani and Anne Hartebrodt and Balazs-Attila Orban and Sándor-József Fejér and Olga Zolotareva and Supratim Das and Linda Baumbach and Josch K Pauling and Olivera Tomašević and Béla Bihari and Marcus Bloice and Nina C Donner and Walid Fdhila and Tobias Frisch and Anne-Christin Hauschild and Dominik Heider and Andreas Holzinger and Walter Hötzendorfer and Jan Hospes and Tim Kacprowski and Markus Kastelitz and Markus List and Rudolf Mayer and Mónika Moga and Heimo Müller and Anastasia Pustozerova and Richard Röttger and Christina C Saak and Anna Saranti and Harald H H W Schmidt and Christof Tschohl and Nina K Wenke and Jan Baumbach},
keywords = {privacy-preserving machine learning, federated learning, interactive platform, artificial intelligence, AI store, privacy-enhancing technologies, additive secret sharing},
abstract = {Background
Machine learning and artificial intelligence have shown promising results in many areas and are driven by the increasing amount of available data. However, these data are often distributed across different institutions and cannot be easily shared owing to strict privacy regulations. Federated learning (FL) allows the training of distributed machine learning models without sharing sensitive data. In addition, the implementation is time-consuming and requires advanced programming skills and complex technical infrastructures.
Objective
Various tools and frameworks have been developed to simplify the development of FL algorithms and provide the necessary technical infrastructure. Although there are many high-quality frameworks, most focus only on a single application case or method. To our knowledge, there are no generic frameworks, meaning that the existing solutions are restricted to a particular type of algorithm or application field. Furthermore, most of these frameworks provide an application programming interface that needs programming knowledge. There is no collection of ready-to-use FL algorithms that are extendable and allow users (eg, researchers) without programming knowledge to apply FL. A central FL platform for both FL algorithm developers and users does not exist. This study aimed to address this gap and make FL available to everyone by developing FeatureCloud, an all-in-one platform for FL in biomedicine and beyond.
Methods
The FeatureCloud platform consists of 3 main components: a global frontend, a global backend, and a local controller. Our platform uses a Docker to separate the local acting components of the platform from the sensitive data systems. We evaluated our platform using 4 different algorithms on 5 data sets for both accuracy and runtime.
Results
FeatureCloud removes the complexity of distributed systems for developers and end users by providing a comprehensive platform for executing multi-institutional FL analyses and implementing FL algorithms. Through its integrated artificial intelligence store, federated algorithms can easily be published and reused by the community. To secure sensitive raw data, FeatureCloud supports privacy-enhancing technologies to secure the shared local models and assures high standards in data privacy to comply with the strict General Data Protection Regulation. Our evaluation shows that applications developed in FeatureCloud can produce highly similar results compared with centralized approaches and scale well for an increasing number of participating sites.
Conclusions
FeatureCloud provides a ready-to-use platform that integrates the development and execution of FL algorithms while reducing the complexity to a minimum and removing the hurdles of federated infrastructure. Thus, we believe that it has the potential to greatly increase the accessibility of privacy-preserving and distributed data analyses in biomedicine and beyond.}
}
@article{BALASUBRAMANIAN2025100545,
title = {A cognitive platform for collecting cyber threat intelligence and real-time detection using cloud computing},
journal = {Decision Analytics Journal},
volume = {14},
pages = {100545},
year = {2025},
issn = {2772-6622},
doi = {https://doi.org/10.1016/j.dajour.2025.100545},
url = {https://www.sciencedirect.com/science/article/pii/S2772662225000013},
author = {Prasasthy Balasubramanian and Sadaf Nazari and Danial Khosh Kholgh and Alireza Mahmoodi and Justin Seby and Panos Kostakos},
keywords = {Cyber threat intelligence, Machine learning operations, Classification, Indicators of compromise, Bidirectional encoder representations from transformers (BERT), Longformer},
abstract = {The extraction of cyber threat intelligence (CTI) from open sources is a rapidly expanding defensive strategy that enhances the resilience of both Information Technology (IT) and Operational Technology (OT) environments against large-scale cyber-attacks. However, for most organizations, collecting actionable CTI remains both a technical bottleneck and a black box. While previous research has focused on improving individual components of the extraction process, the community lacks open-source platforms for deploying streaming CTI data pipelines in the wild. This study proposes an efficient platform capable of processing compute-intensive data pipelines, based on cloud computing, for real-time detection, collection, and sharing of CTI from various online sources. We developed a prototype platform (TSTEM) with a containerized microservice architecture that uses Tweepy, Scrapy, Terraform, Elasticsearch, Logstash, and Kibana (ELK), Kafka, and Machine Learning Operations (MLOps) to autonomously search, extract, and index indicators of compromise (IOCs) in the wild. Moreover, the provisioning, monitoring, and management of the platform are achieved through infrastructure as code (IaC). Custom focus-crawlers collect web content, processed by a first-level classifier to identify potential IOCs. Relevant content advances to a second level for further examination. State-of-the-art natural language processing (NLP) models are used for classification and entity extraction, enhancing the IOC extraction methodology. Our results indicate these models exhibit high accuracy (exceeding 98%) in classification and extraction tasks, achieving this performance within less than a minute. The system’s effectiveness is due to a finely-tuned IOC extraction method that operates at multiple stages, ensuring precise identification with low false positives.}
}
@article{OKONKWO2025929,
title = {Solar PV systems under weather extremes: Case studies, classification, vulnerability assessment, and adaptation pathways},
journal = {Energy Reports},
volume = {13},
pages = {929-959},
year = {2025},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2024.12.067},
url = {https://www.sciencedirect.com/science/article/pii/S2352484724008813},
author = {Paul C. Okonkwo and Samuel Chukwujindu Nwokolo and Sunday O. Udo and Anthony Umunnakwe Obiwulu and Usang Nkanu Onnoghen and Saad S. Alarifi and Ahmed M. Eldosouky and Stephen E. Ekwok and Peter Andráš and Anthony E. Akpan},
keywords = {Solar PV modules, Extreme weather events, Hurricanes, Floods, Heatwaves, Snowstorms},
abstract = {This study examines the significant challenges presented by the rising frequency and severity of climate change-induced extreme weather events—such as hurricanes, floods, heatwaves, and snowstorms—on the reliability and efficacy of solar photovoltaic (PV) systems. Utilizing case studies from various global places, it underscores the susceptibilities of photovoltaic systems to environmental harm, encompassing structural failure, efficiency decline, and operational interruptions. The study presents a novel, resilience-oriented paradigm that incorporates sophisticated design principles, operational techniques, and policy innovations to alleviate these risks. Principal findings underscore the significance of site-specific risk evaluations, modular and adaptable system architectures, and cohesive resilience planning in photovoltaic system engineering. Proactive operational techniques, such as regular maintenance, emergency reaction plans, and intelligent system monitoring, are deemed essential for sustaining performance in extreme weather conditions. Innovative technological solutions, including resilient materials, sophisticated coatings, durable mounting methods, and thermal management technologies, are emphasized for their capacity to endure intense environmental stressors. The study delineates future research goals, encompassing the creation of innovative materials with superior durability, scalable energy storage integration, structural advances, and greater grid interconnectivity via smart grid technology. It emphasizes the significance of cybersecurity protocols to safeguard photovoltaic infrastructure and promotes legislative and regulatory enhancements to facilitate resilience implementation. Collaboration among researchers, industry executives, and policymakers is considered crucial for addressing the increasing difficulties presented by climate change. This paper establishes a framework for integrating resilience into all facets of solar PV system design and operation, thereby ensuring the long-term sustainability, efficiency, and efficacy of solar energy systems in a swiftly changing climate environment. This comprehensive strategy is essential for ensuring the future of renewable energy amid global environmental difficulties.}
}
@article{MANSOURI2020102740,
title = {An automated implementation of hybrid cloud for performance evaluation of distributed databases},
journal = {Journal of Network and Computer Applications},
volume = {167},
pages = {102740},
year = {2020},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2020.102740},
url = {https://www.sciencedirect.com/science/article/pii/S1084804520302149},
author = {Yaser Mansouri and Victor Prokhorenko and M. Ali Babar},
keywords = {Hybrid cloud, Cloud bursting, Distributed databases, WireGuard VPN, Throughput, Read and write latency},
abstract = {A Hybrid cloud is an integration of resources between private and public clouds. It enables users to horizontally scale their on-premises infrastructure up to public clouds in order to improve performance and cut up-front investment cost. This model of applications deployment is called cloud bursting that allows data-intensive applications especially distributed database systems to have the benefit of both private and public clouds. In this work, we present an automated implementation of a hybrid cloud using (i) a robust and zero-cost Linux-based VPN to make a secure connection between private and public clouds, and (ii) Terraform as a software tool to deploy infrastructure resources based on the requirements of hybrid cloud. We also explore performance evaluation of cloud bursting for six modern and distributed database systems on the hybrid cloud spanning over local OpenStack and Microsoft Azure. Our results reveal that MongoDB and MySQL Cluster work efficient in terms of throughput and operations latency if they burst into a public cloud to supply their resources. In contrast, the performance of Cassandra, Riak, Redis, and Couchdb reduces if they significantly leverage their required resources via cloud bursting.}
}
@article{CAMMOCK202110,
title = {Opportunities for a civil engineering climate action strategy},
journal = {Proceedings of the Institution of Civil Engineers - Civil Engineering},
volume = {174},
number = {5},
pages = {10-15},
year = {2021},
issn = {0965-089X},
doi = {https://doi.org/10.1680/jcien.20.00043},
url = {https://www.sciencedirect.com/science/article/pii/S0965089X21000148},
author = {Reece Cammock},
keywords = {climate change, codes of practice & standards, failure},
abstract = {This paper outlines the technical and anecdotal findings of a horizon scanning exercise into the ability of civil engineers to deliver impactful climate action. Examples of interaction between extreme weather and built environment assets are broken down via systems thinking. The concept of unconscious bias is addressed in how infrastructure climate risk is diagnosed; beyond the effects of flooding, drought, and heatwaves. Differentiations between climate mitigation, resilience and adaptation are made. Opportunities to address each throughout the infrastructure lifecycle are discussed, including how to balance conflicts of interest between them.}
}
@article{RISCO2024457,
title = {Rescheduling serverless workloads across the cloud-to-edge continuum},
journal = {Future Generation Computer Systems},
volume = {153},
pages = {457-466},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2023.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X23004764},
author = {Sebastián Risco and Caterina Alarcón and Sergio Langarita and Miguel Caballer and Germán Moltó},
keywords = {Cloud computing, Cloud-to-edge continuum, Containers, FaaS, Kubernetes, Serverless computing},
abstract = {Serverless computing was a breakthrough in Cloud computing due to its high elasticity capabilities and fine-grained pay-per-use model offered by the main public Cloud providers. Meanwhile, open-source serverless platforms supporting the FaaS (Function as a Service) model allow users to take advantage of many of their benefits while operating on the on-premises platforms of organizations. This opens the possibility to deploy and exploit them on the different layers of the cloud-to-edge continuum, either on IoT (Internet of Things) devices located at the Edge (i.e. next to data acquisition devices), in on-premises clusters closer to the data sources (i.e. Fog computing) or directly on the Cloud. This paper presents two strategies to mitigate the overload that disparate data ingestion rates may cause in low-powered devices at the Edge or Fog layers. To this end, it is proposed to delegate and reschedule serverless jobs between the different layers of the cloud-to-edge continuum using an open-source platform for event-driven file processing. To demonstrate the performance of these strategies, a use case for fire detection is proposed that includes processing in the Fog via minified Kubernetes clusters located near the Edge, in the private Cloud via on-premises elastic clusters and, finally, in the public Cloud by using the AWS (Amazon Web Services) Lambda FaaS service. The results indicate that these strategies can mitigate overloads in use cases involving processing across the cloud-to-edge continuum by coordinating several layers of computing resources.}
}
@article{YANG2018407,
title = {Towards sustainable and resilient high density cities through better integration of infrastructure networks},
journal = {Sustainable Cities and Society},
volume = {42},
pages = {407-422},
year = {2018},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2018.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S2210670718300210},
author = {Yifan Yang and S. Thomas Ng and Frank J. Xu and Martin Skitmore},
keywords = {High density cities, Sustainability, Resilience, Infrastructure system, Asset management},
abstract = {Many developed high density cities around the world are facing unprecedented challenges as their infrastructure facilities are aging while citizen demands are ever surging. The concerted efforts of different infrastructure stakeholders are indispensable to elevate the quality, reliability, and capacity of infrastructure systems to make high-density cities more sustainable and resilient against increasing climate change and manmade threats. To address these challenges, this paper proposes an integrated framework for multisector infrastructure asset management. For deriving the framework, case studies are conducted first on the best infrastructure asset management (IAM) practices of different countries in such diverse aspects as core process integration, contingency management, climate change response and adaptation, program coordination and orchestration, social value creation and sharing, risk management, resilience and sustainability. By using the criteria and a list of questions obtained from the case studies, interviews with different stakeholders in selected infrastructure sectors in Hong Kong are subsequently carried out to identify the barriers and possible solutions to enhancing the integrated management of multisector infrastructure assets in high-density cities. To facilitate such municipalities in managing their infrastructure assets effectively and efficiently, the proposed multisector integrated IAM framework is established from the holistic perspectives of information integration, process integration, collective decision, and harmonization between interdependent infrastructure systems.}
}
@article{FILINIS202472,
title = {Intent-driven orchestration of serverless applications in the computing continuum},
journal = {Future Generation Computer Systems},
volume = {154},
pages = {72-86},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2023.12.032},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X23004910},
author = {Nikos Filinis and Ioannis Tzanettis and Dimitrios Spatharakis and Eleni Fotopoulou and Ioannis Dimolitsas and Anastasios Zafeiropoulos and Constantinos Vassilakis and Symeon Papavassiliou},
keywords = {Serverless computing, Computing continuum, Intent-driven orchestration, Reinforcement Learning, Service Level Objective, Multi-cluster scheduling},
abstract = {Following the emergence of Internet of Things (IoT) and edge computing technologies and the development of distributed applications with strict Quality of Service (QoS) requirements, a transition is underway from centralized computing models to distributed computing continuum systems. The latter provide abstractions of the available resources, while they lead to the development of orchestration mechanisms with increased distributed intelligence and autonomy characteristics. These characteristics make the computing continuum suitable for managing serverless computing applications, considering their loose coupling with the resources and the need for reactiveness and efficiency to serve dynamic workloads in the edge and cloud part of the infrastructure. This paper presents an intent-based approach for the orchestration of a function chain over an edge and cloud infrastructure. We propose a Reinforcement Learning (RL) based autoscaling method that incorporates a reward function that aims to provide optimal utilization of resources and timely autoscaling of the functions, taking advantage of methods for workload prediction. Based on a high-level intent, the proposed optimization problem dictates the scheduling of the functions, minimizing the communication overhead and transformation cost while also considering the energy efficiency of the infrastructure. The proposed solution is evaluated with other state-of-the-art techniques for autoscaling and scheduling of serverless functions in a small edge infrastructure. Our solution provides 1.52% QoS violations with a slight increase in the deployed resources, while also significantly reducing the total cost and power consumption for the deployment of the function chain.}
}
@incollection{SAEZDECAMARA2025309,
title = {Chapter 12 - Practical approaches towards IoT dataset generation for security experiments},
editor = {Dinh Thai Hoang and Nguyen Quang Hieu and Diep N. Nguyen and Ekram Hossain},
booktitle = {Advanced Machine Learning for Cyber-Attack Detection in IoT Networks},
publisher = {Academic Press},
pages = {309-373},
year = {2025},
isbn = {978-0-443-29032-9},
doi = {https://doi.org/10.1016/B978-0-44-329032-9.00017-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443290329000178},
author = {Xabier Sáez-de-Cámara and Jose Luis Flores and Cristóbal Arellano and Aitor Urbieta and Iñaki Garitano and Urko Zurutuza},
keywords = {Botnet, Emulation, Internet of Things, Machine learning, Network security, Testbed},
abstract = {The cybersecurity field has been steadily adopting rapid advances in artificial intelligence (AI) and machine learning (ML) techniques for various purposes, such as threat detection and response, with promising results. Obtaining high-quality data for model training is fundamental to creating robust solutions; however, the scarcity of IoT security datasets remains a limiting factor in developing ML-based security systems for IoT scenarios. Broadly, there are two methods for generating datasets: using physical IoT hardware on operational networks and employing virtualization-based systems. The former provides accurate and representative data but can be costly, time-consuming, difficult to adapt, and potentially risky. On the other hand, the latter offers a safer, more flexible, and cost-effective approach for various research purposes, despite not replicating exact hardware conditions. This chapter will delve into the practical process of dataset generation from the point of view of these two approaches. First, regarding the virtualized approach, we will leverage the recently published Gotham testbed, a reproducible, flexible, and extendable security testbed based on emulated nodes that mixes containerization and virtual machine technologies. This testbed can be used to generate various datasets of network traces, including activities from real malware emulated in the platform or real attack activities from the internet interacting with the testbed. Then, based on the VARIoT project, we will explore the platform and methodology to create datasets of IoT traffic under realistic conditions, including both legitimate and malicious traces, using a laboratory set of physical IoT hardware devices.}
}
@article{BADALYAN2022101126,
title = {Ansible execution control in Python and Golang for cloud orchestration},
journal = {SoftwareX},
volume = {19},
pages = {101126},
year = {2022},
issn = {2352-7110},
doi = {https://doi.org/10.1016/j.softx.2022.101126},
url = {https://www.sciencedirect.com/science/article/pii/S2352711022000826},
author = {David Badalyan and Oleg Borisenko},
keywords = {Ansible, Cloud orchestration, Function hooking, Golang, Python},
abstract = {The Ansible configuration manager is currently one of the most popular systems for software deployment. However, Ansible is difficult to debug when working with large scenarios and is difficult to embed into other systems. We propose the cotea (Python) and gocotea (Golang) tools that allow users to control Ansible execution programmatically, by iterating over the tasks and collecting progress information. We additionally propose gopython — a solution for embedding arbitrary Python code into a Golang application. The approach used was generalized up to the abstract architecture of the software tool, which allows for the control of an arbitrary Python program execution.}
}
@article{KAFKA2021114212,
title = {What is the role of firearms in nonfatal intimate partner violence? Findings from civil protective order case data},
journal = {Social Science & Medicine},
volume = {283},
pages = {114212},
year = {2021},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2021.114212},
url = {https://www.sciencedirect.com/science/article/pii/S027795362100544X},
author = {Julie M. Kafka and Kathryn E. Moracco and Deanna S. Williams and Claire G. Hoffman},
keywords = {Firearm violence, Intimate partner violence, Domestic violence, Protective order, Firearm access, United States},
abstract = {Background
Perpetrators of intimate partner violence (IPV) use firearms to injure, scare, and manipulate their partners. Abusers who have a firearm in their homes are more likely to threaten and/or kill their partner. To date, however, limited research documents the nature of IPV perpetrator firearm access or the prevalence of nonfatal firearm abuse behaviors.
Methods
Federal law restricts firearm access for IPV perpetrators in qualifying domestic violence protective order (DVPO) cases and information about firearms should be disclosed during the DVPO process. We used secondary data from civil DVPO cases (n = 406) in North Carolina that were collected using a representative sampling strategy. Data were from DVPO case files and structured DVPO hearing observations. We conducted a content analysis to record IPV perpetrator access to guns and reported firearm abuse behaviors. We used a linear regression analysis to determine whether IPV perpetrator gun access was associated with higher levels of reported abuse. We also examined factors associated with perpetration of nonfatal firearm abuse.
Results
We found evidence of perpetrator firearm access in nearly half of all cases (46%, n = 108). Controlling for covariates, gun access was significantly associated with higher levels of reported IPV (b = 0.5, p < .001). Firearm abuse was reported in nearly one out of four cases (23.1%, n = 101), and often entailed spoken threats, displaying a gun, or holding a partner at gun point. The only factors associated with firearm abuse in the multivariate models were related to English language speaking/fluency.
Conclusions
Gun access should be considered an indicator for severe IPV. We must ensure that existing legal mechanisms to identify and restrict abuser access to firearms are fully implemented and enforced. Firearm abuse often manifests as non-physical coercive control which is traumatic and has the potential to escalate to homicide, even in the absence of past physical violence.}
}
@article{KUMAR2024109419,
title = {Optimizing resource allocation using proactive scaling with predictive models and custom resources},
journal = {Computers and Electrical Engineering},
volume = {118},
pages = {109419},
year = {2024},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2024.109419},
url = {https://www.sciencedirect.com/science/article/pii/S0045790624003471},
author = {Bablu Kumar and Anshul Verma and Pradeepika Verma},
keywords = {Custom resource definition, Cloud computing, Docker, Kubernetes, Operator reconciliation process, Proactive auto-scaling, Resource allocation},
abstract = {Kubernetes-based containerized applications heavily rely on distributing network workloads among cluster applications, primarily because of the frequent resource requests and limited set of pods and containers. Kubernetes scaling manages many containerized services using either reactive or proactive autoscaling. Reactive autoscaling cannot foresee future workload and thus cannot compete with proactive autoscaling. In addition to this, reactive autoscaling has several quality of service issues such as high latency, inability to manage workload fluctuations frequently, and insufficient service resource usage. To address these issues, the custom resource utilizes a predictive artificial intelligence scaling method, including Autoregressive Integrated Moving Average (ARIMA), Long Short-Term Memory (LSTM), Bidirectional Long Short-Term Memory (Bi-LSTM), and Transformer models. This custom resource is integrated with the operator reconciliation process and the model control system, utilizing coroutines to asynchronously manage workloads and allocate resources as pods within clusters. To evaluate effectiveness, the NASA-HTTP dataset is utilized to scale containerization as an application of resources and assess the accuracy of under-provisioning and over-provisioning as well in resource management. According to the model control system, the Transformer result predictive model ranks among the top min-heap models, exhibiting the lowest performance metric values compared to other predictive models. Specifically, its mean squared error is 77.3363, its root mean squared error is 8.7941, and its mean absolute error is 6.5930. Finally, facilitated through Docker-based resource management, integrated with Kubernetes, this service significantly manages workload and enhances resource utilization, efficiency, and performance using the proposed model. Incorporating Explainable artificial intelligence into the system improves clarity and comprehension of the decision-making process of predictive models, especially in model control and operator reconciliation.}
}
@article{MUSIC2024619,
title = {Digital transformation with a lightweight on-premise PaaS},
journal = {Future Generation Computer Systems},
volume = {160},
pages = {619-629},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.06.026},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24003261},
author = {Din Mušić and Jernej Hribar and Carolina Fortuna},
keywords = {Digital transformation, Cloud computing, Edge computing, Platform as a service, Kubitect},
abstract = {The rise of cloud computing has been enabled by advances in virtualization and containerization technology. Over the past decade, the use of cloud computing has grown rapidly and has had a significant impact on digital transformation with many enterprises migrating to public clouds. While convenient and cost efficient, such approaches are prone to certain data privacy, compliance and security risks. The ongoing democratization of cloud technologies represented by the increasing number of open source projects, has enabled certain enterprises to easily develop their on-premise cloud infrastructure. However, these open source projects are largely enterprise level and still too complex for small and micro enterprises and academic environments. To further decrease the on-premise infrastructure deployment and management barrier, we first provide an analysis of the existing on-premises PaaS workflows and solutions, along with the complexity of their deployment models, and identify the requirements for simple PaaS solutions for small environments with limited resources. We then introduce Kubitect as an enabler of on-premises PaaS democratization and expedite digital transformation. Kubitect is a lightweight single file declarative infrastructure configuration solution for on-premises cluster definition, instantiation and update. Our qualitative and quantitative evaluation shows the advantage of Kubitect for small environments where simplicity is more important than deploy time, assuming the latter is relatively comparable with alternative solutions.}
}
@article{FU2024e37001,
title = {Combating urban heat: Systematic review of urban resilience and adaptation strategies},
journal = {Heliyon},
volume = {10},
number = {17},
pages = {e37001},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e37001},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024130320},
author = {Qingchen Fu and Zhouhua Zheng and Md Nazirul Islam Sarker and Yang Lv},
keywords = {Climate adaptation, Heatwave mitigation, Land use, Policy innovation, Urban vulnerability, Community resilience},
abstract = {Urban areas are currently facing the increasingly pressing issue of urban heat worldwide, which is being worsened by climate change and rising urbanization. As a result, there is a growing need for new approaches to enhance urban resilience and adapt to these challenges. The escalating occurrence and severity of urban heat events provide notable hazards, particularly to susceptible groups, necessitating proactive efforts to alleviate detrimental consequences. Therefore, this research addresses the inquiry, “What strategic approaches can be effectively employed to mitigate vulnerability and strengthen urban resilience in response to urban heat?” Thus, this study ascertains and examines approaches to enhance urban resilience, mitigate susceptibility, and implement adaptation strategies to combat urban heat. Utilizing the content analysis method, a comprehensive assortment of documents encompassing academic publications, policy documents, and reports was subjected to a systematic analysis employing the MAXQDA software. Databases searched included Web of Science, Scopus, and Google Scholar, and a total of 72 studies were included in the final analysis. The research reveals a wide range of novel ideas and practical measures that can be implemented to improve urban resilience and mitigate vulnerability to urban heat. Urban greening strategies, heatwave early warning sys-tems, and community involvement projects have exhibited differing effectiveness, application, and adaptation levels in many urban landscapes and socio-economic circumstances. Additionally, this research emphasizes the value of using multidimensional, context-specific strategies to address the unique challenges and needs of diverse urban regions and marginalized communities. Furthermore, structural changes, legislative reforms, and community-based solutions may be necessary to manage complex issues posed by urban heat. Therefore, effectively implementing adaptation strategies is vital to effectively combating challenges caused by urban heat in urban areas.}
}
@article{GOLDENITS2025110724,
title = {Taxonomy of cybersecurity considerations in agriculture},
journal = {Computers and Electronics in Agriculture},
volume = {237},
pages = {110724},
year = {2025},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2025.110724},
url = {https://www.sciencedirect.com/science/article/pii/S0168169925008300},
author = {Georg Goldenits and Thomas Neubauer},
keywords = {Cybersecurity, Agriculture, Cyberthreat, Internet of Things, Agri-food supply chain},
abstract = {Agriculture is at the heart of our food production, which we all rely on. Increasing ambitions to digitalise the sector bear the risk of exposing it to various disruptions. This paper gives the main definition of dependability and security, including attributes such as reliability, availability, safety, integrity, maintainability, etc., in the context of agriculture. By first introducing the topics of cybersecurity and Agriculture 4.0, with its corresponding technological considerations, we aim to build a common understanding for various stakeholders dealing with the agri-food sector. Furthermore, we support these stakeholders by building upon these concepts and combining them in a taxonomy to navigate the complexities of cybersecurity in agriculture. This paper addresses the most significant threats to dependability and security when digitising farming operations. We list various types of cybersecurity relevant to digital and novel technologies in agriculture, potential pitfalls regarding cybersecurity issues that come with using these technologies and present the most relevant faults that agricultural systems might encounter. For our taxonomy, we combine these by linking them to the most significant technologies in Agriculture 4.0. In addition to focusing on the cybersecurity threats, we present technological and non-technology-based countermeasures and legislative frameworks to prevent, detect and mitigate security breaches. Since this paper aims to lay a foundation for cybersecurity in agriculture, we also describe the roles of various stakeholders along the agri-food supply chain and how they participate in ensuring a secure and dependable system.}
}
@article{SAURABH2020107,
title = {Expelliarmus: Semantic-centric virtual machine image management in IaaS Clouds},
journal = {Journal of Parallel and Distributed Computing},
volume = {146},
pages = {107-121},
year = {2020},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2020.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0743731520303415},
author = {Nishant Saurabh and Shajulin Benedict and Jorge G. Barbosa and Radu Prodan},
keywords = {Virtual machine image management, Semantic similarity, Storage optimization, Virtual machine image publishing, Virtual machine image retrieval},
abstract = {Infrastructure-as-a-service (IaaS) Clouds concurrently accommodate diverse sets of user requests, requiring an efficient strategy for storing and retrieving virtual machine images (VMIs) at a large scale. The VMI storage management requires dealing with multiple VMIs, typically in the magnitude of gigabytes, which entails VMI sprawl issues hindering the elastic resource management and provisioning. Unfortunately, existing techniques to facilitate VMI management overlook VMI semantics (i.e at the level of base image and software packages), with either restricted possibility to identify and extract reusable functionalities or with higher VMI publishing and retrieval overheads. In this paper, we propose Expelliarmus, a novel VMI management system that helps to minimize VMI storage, publishing and retrieval overheads. To achieve this goal, Expelliarmus incorporates three complementary features. First, it models VMIs as semantic graphs to facilitate their similarity computation. Second, it provides a semantically-aware VMI decomposition and base image selection to extract and store non-redundant base image and software packages. Third, it assembles VMIs based on the required software packages upon user request. We evaluate Expelliarmus through a representative set of synthetic Cloud VMIs on a real test-bed. Experimental results show that our semantic-centric approach is able to optimize the repository size by 2.3−22 times compared to state-of-the-art systems (e.g. IBM’s Mirage and Hemera) with significant VMI publishing and slight retrieval performance improvement.}
}
@article{SHAPKIN2022785,
title = {Automation of Configuration, Initialization and Deployment of Applications Based on an Algebraic Approach},
journal = {Procedia Computer Science},
volume = {213},
pages = {785-792},
year = {2022},
note = {2022 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence: The 13th Annual Meeting of the BICA Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.11.135},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922018348},
author = {Pavel Shapkin},
keywords = {applicative computing systems, containerization, orchestration},
abstract = {Thanks to the development of cloud platforms and containerization technologies, the spectrum of opportunities for deploying complex multi-component systems is extremely wide. On the one hand, the available tools unify the solution of complex problems. But on the other hand they do not have sufficient means for automatic synthesis and analysis. The article presents an approach that allows unifying and automating the task of building deployment and initialization code for of multi-component software systems. The proposed solution is based on the use of applicative computing systems and abstract algebraic structures that are interpreted in various ways to generate various parts of the software system.}
}
@article{ARVIDSSON2021107741,
title = {Critical infrastructure, geographical information science and risk governance: A systematic cross-field review},
journal = {Reliability Engineering & System Safety},
volume = {213},
pages = {107741},
year = {2021},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2021.107741},
url = {https://www.sciencedirect.com/science/article/pii/S0951832021002738},
author = {Björn Arvidsson and Jonas Johansson and Nicklas Guldåker},
keywords = {Review, Critical infrastructure, Resilience, Risk, Giscience, GIS, Risk governance, Scoping study},
abstract = {Two key challenges for governing and managing critical infrastructure risk and resilience are interdependencies between infrastructures and the multi-actor setting in which they operate. This paper looks beyond the Critical Infrastructure (CI) field of research to identify and discuss cross-disciplinary approaches to address these challenges. It explores two related and slightly overlapping research fields: Geographical Information Science (GIScience) and Risk Governance (RG). The purpose is to systematically explore how concepts and approaches from these two fields can help develop the CI field further. The overall methodology follows the scoping study framework, which is strengthened by presenting a novel method for article keyword analysis of 14 170 articles guiding a content analysis of 51 articles. The results reveal that research areas intersecting CI and GIScience are natural hazard modelling, network analysis, data management, and geovisualisation and for CI and RG the inclusion of socio-cultural dimensions. These areas constitute good opportunities for further research. Challenges for cross-disciplinary research and practical applications include harmonisation of concepts, management of confidential data, and addressing less-technical CI sectors. In conclusion, the CI field is young and growing, and in need of further cross- and interdisciplinary research endeavours to tackle the complex issues at hand.}
}
@article{ALIC2019243,
title = {BIGSEA: A Big Data analytics platform for public transportation information},
journal = {Future Generation Computer Systems},
volume = {96},
pages = {243-269},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.02.011},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X18304448},
author = {Andy S. Alic and Jussara Almeida and Giovanni Aloisio and Nazareno Andrade and Nuno Antunes and Danilo Ardagna and Rosa M. Badia and Tania Basso and Ignacio Blanquer and Tarciso Braz and Andrey Brito and Donatello Elia and Sandro Fiore and Dorgival Guedes and Marco Lattuada and Daniele Lezzi and Matheus Maciel and Wagner Meira and Demetrio Mestre and Regina Moraes and Fabio Morais and Carlos Eduardo Pires and Nádia P. Kozievitch and Walter dos Santos and Paulo Silva and Marco Vieira},
abstract = {Analysis of public transportation data in large cities is a challenging problem. Managing data ingestion, data storage, data quality enhancement, modelling and analysis requires intensive computing and a non-trivial amount of resources. In EUBra-BIGSEA (Europe–Brazil Collaboration of Big Data Scientific Research Through Cloud-Centric Applications) we address such problems in a comprehensive and integrated way. EUBra-BIGSEA provides a platform for building up data analytic workflows on top of elastic cloud services without requiring skills related to either programming or cloud services. The approach combines cloud orchestration, Quality of Service and automatic parallelisation on a platform that includes a toolbox for implementing privacy guarantees and data quality enhancement as well as advanced services for sentiment analysis, traffic jam estimation and trip recommendation based on estimated crowdedness. All developments are available under Open Source licenses (http://github.org/eubr-bigsea, https://hub.docker.com/u/eubrabigsea/).}
}
@article{BATCHELOR2023100160,
title = {The Multidisciplinary Heart Team in Cardiovascular Medicine: Current Role and Future Challenges},
journal = {JACC: Advances},
volume = {2},
number = {1},
pages = {100160},
year = {2023},
issn = {2772-963X},
doi = {https://doi.org/10.1016/j.jacadv.2022.100160},
url = {https://www.sciencedirect.com/science/article/pii/S2772963X22002381},
author = {Wayne B. Batchelor and Saif Anwaruddin and Dee Dee Wang and Elizabeth M. Perpetua and Ashok Krishnaswami and Poonam Velagapudi and Janet F. Wyman and David Fullerton and Patricia Keegan and Alistair Phillips and Laura Ross and Brij Maini and Gwen Bernacki and Gurusher S. Panjrath and James Lee and Jeffrey B. Geske and Fred Welt and Prashanth D. Thakker and Anita Deswal and Ki Park and Michael J. Mack and Martin Leon and Sandra Lewis and David Holmes},
keywords = {multidisciplinary heart team, structural heart disease, team-based care},
abstract = {Cardiovascular multidisciplinary heart teams (MDHTs) have evolved significantly over the past decade. These teams play a central role in the treatment of a wide array of cardiovascular diseases affecting interventional cardiology, cardiac surgery, interventional imaging, advanced heart failure, adult congenital heart disease, cardio-oncology, and cardio-obstetrics. To meet the specific needs of both patients and heart programs, the composition and function of cardiovascular MDHTs have had to adapt and evolve. Although lessons have been learned from multidisciplinary cancer care, best practices for the operation of cardiovascular MDHTs have yet to be defined, and the evidence base supporting their effectiveness is limited. This expert panel review discusses the history and evolution of cardiovascular MDHTs, their composition and role in treating patients across a broad spectrum of disciplines, basic tenets for successful operation, and the future challenges facing them.}
}
@article{MELLOT2025114725,
title = {Electrification, flexibility or both? Emerging trends in European energy policy},
journal = {Energy Policy},
volume = {206},
pages = {114725},
year = {2025},
issn = {0301-4215},
doi = {https://doi.org/10.1016/j.enpol.2025.114725},
url = {https://www.sciencedirect.com/science/article/pii/S0301421525002320},
author = {Adrien Mellot and Christian Moretti and Alejandro Nuñez-Jimenez and Jan Linder and Niccolò Moro and Siobhan Powell and Jochen Markard and Christian Winzer and Anthony Patt},
keywords = {Policy, Flexibility, Sector coupling, Sustainability transitions, Electrification},
abstract = {In Europe, low-carbon electrification is emerging as an overarching policy strategy to reduce greenhouse gas emissions. However, increasing shares of variable renewables and the rising electricity demand from sector coupling technologies such as electric vehicles or heat pumps make balancing electricity supply and demand more difficult. Demand-side flexibility could address this challenge, but several regulatory barriers and policy shortcomings remain. As technologies diffuse, open questions remain about whether and how policy support for low-carbon electrification addresses these technologies’ flexible operation in addition to their deployment. In this context, we examine policies that support the diffusion of novel technologies and those that, separately or in combination, support demand-side flexibility. Over a timespan of 9 years (2016–2024), our analysis covers four technologies across six jurisdictions: electric vehicles, heat pumps, hydrogen, and new industrial loads in Austria, France, Germany, Italy, Switzerland, and the European Union. We find that technology diffusion policies are increasingly combined with flexibility policies. At the same time, policy objectives and the number and types of policies vary significantly across countries. This points to different transition pathways depending, for example, on national electricity system characteristics and flexibility needs, and to different challenges in coordinating policies across sectors and technologies.}
}
@article{CHOUDHURY2025,
title = {Advancing Privacy-Preserving Health Care Analytics and Implementation of the Personal Health Train: Federated Deep Learning Study},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/60847},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000055},
author = {Ananya Choudhury and Leroy Volmer and Frank Martin and Rianne Fijten and Leonard Wee and Andre Dekker and Johan van Soest},
keywords = {gross tumor volume segmentation, federated learning infrastructure, privacy-preserving technology, cancer, deep learning, artificial intelligence, lung cancer, oncology, radiotherapy, imaging, data protection, data privacy},
abstract = {Background
The rapid advancement of deep learning in health care presents significant opportunities for automating complex medical tasks and improving clinical workflows. However, widespread adoption is impeded by data privacy concerns and the necessity for large, diverse datasets across multiple institutions. Federated learning (FL) has emerged as a viable solution, enabling collaborative artificial intelligence model development without sharing individual patient data. To effectively implement FL in health care, robust and secure infrastructures are essential. Developing such federated deep learning frameworks is crucial to harnessing the full potential of artificial intelligence while ensuring patient data privacy and regulatory compliance.
Objective
The objective is to introduce an innovative FL infrastructure called the Personal Health Train (PHT) that includes the procedural, technical, and governance components needed to implement FL on real-world health care data, including training deep learning neural networks. The study aims to apply this federated deep learning infrastructure to the use case of gross tumor volume segmentation on chest computed tomography images of patients with lung cancer and present the results from a proof-of-concept experiment.
Methods
The PHT framework addresses the challenges of data privacy when sharing data, by keeping data close to the source and instead bringing the analysis to the data. Technologically, PHT requires 3 interdependent components: “tracks” (protected communication channels), “trains” (containerized software apps), and “stations” (institutional data repositories), which are supported by the open source “Vantage6” software. The study applies this federated deep learning infrastructure to the use case of gross tumor volume segmentation on chest computed tomography images of patients with lung cancer, with the introduction of an additional component called the secure aggregation server, where the model averaging is done in a trusted and inaccessible environment.
Results
We demonstrated the feasibility of executing deep learning algorithms in a federated manner using PHT and presented the results from a proof-of-concept study. The infrastructure linked 12 hospitals across 8 nations, covering 4 continents, demonstrating the scalability and global reach of the proposed approach. During the execution and training of the deep learning algorithm, no data were shared outside the hospital.
Conclusions
The findings of the proof-of-concept study, as well as the implications and limitations of the infrastructure and the results, are discussed. The application of federated deep learning to unstructured medical imaging data, facilitated by the PHT framework and Vantage6 platform, represents a significant advancement in the field. The proposed infrastructure addresses the challenges of data privacy and enables collaborative model development, paving the way for the widespread adoption of deep learning–based tools in the medical domain and beyond. The introduction of the secure aggregation server implied that data leakage problems in FL can be prevented by careful design decisions of the infrastructure.
Trial Registration
ClinicalTrials.gov NCT05775068; https://clinicaltrials.gov/study/NCT05775068}
}
@article{AHMAD2025112274,
title = {Anomaly detection in offshore open radio access network using long short-term memory models on a novel artificial intelligence-driven cloud-native data platform},
journal = {Engineering Applications of Artificial Intelligence},
volume = {161},
pages = {112274},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.112274},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625022821},
author = {Abdelrahim Ahmad and Peizheng Li and Robert Piechocki and Rui Inacio},
keywords = {Open radio access network, Anomaly detection, Long short-term memory models, Artificial intelligence, Big data platform, Telecommunications, Machine learning operations, Data engineering, Development operations, Cloud-native private networks},
abstract = {The Radio Access Network (RAN) is a critical component of modern telecommunications infrastructure, currently evolving towards disaggregated and open architectures. These advancements are pivotal for integrating intelligent, data-driven applications aimed at enhancing network reliability and operational autonomy through the introduction of cognitive capabilities, as exemplified by the emerging Open Radio Access Network (O-RAN) standards. Despite its potential, the nascent nature of O-RAN technology presents challenges, primarily due to the absence of mature operational standards. This complicates the management of data and intelligent applications, particularly when integrating with traditional network management and operational support systems. Divergent vendor-specific design approaches further hinder migration and limit solution reusability. These challenges are compounded by a skills gap in telecommunications business-oriented engineering, which remains a key barrier to effective O-RAN deployment and intelligent application development. To address these challenges, Boldyn Networks developed a novel cloud-native data analytics platform, specifically designed to support scalable Artificial Intelligence (AI) integration within O-RAN deployments. This platform underwent rigorous testing in real-world scenarios, and applied advanced AI techniques to improve operational efficiency and customer experience. Implementation involved adopting Development Operations (DevOps) practices, leveraging data lakehouse architectures tailored for AI applications, and employing sophisticated data engineering strategies. The platform successfully addresses connectivity challenges inherent in real-world offshore wind farm deployments using Long Short-Term Memory (LSTM) models for anomaly detection in network connectivity. After integrating the LSTM models into the network control, more than 90 percent of connectivity issues were reduced in runtime. This marks a step toward autonomous, self-organizing, and self-healing networks.}
}
@article{WANG2021102687,
title = {Perceptions of urban heat island mitigation and implementation strategies: survey and gap analysis},
journal = {Sustainable Cities and Society},
volume = {66},
pages = {102687},
year = {2021},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2020.102687},
url = {https://www.sciencedirect.com/science/article/pii/S2210670720309021},
author = {Chenghao Wang and Zhi-Hua Wang and Kamil E. Kaloush and Joseph Shacat},
keywords = {Urban heat island, mitigation strategies, questionnaire, survey analysis, public education, information sharing},
abstract = {Sustainable development of cities and communities under climate change calls for effective and pragmatic strategies to mitigate urban heat island (UHI) during hot seasons. Meanwhile, the effectiveness of UHI mitigation measures can be affected by public perceptions during planning and implementation processes. However, the general perceptions of UHI mitigation and implementation strategies have not received adequate attention in urban climate research. This study leverages the results of a carefully designed survey to fill this research gap. The perceptions of professional respondents are largely affected by the geographic areas they work in and partially affected by how familiar respondents are with the UHI-related building codes and regulations. In addition, academic literature and government reports are the two major sources for most respondents to obtain UHI mitigation information. We also identify four knowledge and implementation gaps: the lack of public education on UHI mitigation and implementation measures, the lack of effective communications between researchers and code writers, the lack of implementing UHI mitigation strategies in some countries, and the lack of trustworthy information shared on social media. Bridging these gaps are of key importance to fostering public engagement and improving the effectiveness of UHI mitigation measures.}
}
@article{JEONG2025100791,
title = {Autoscaling techniques in cloud-native computing: A comprehensive survey},
journal = {Computer Science Review},
volume = {58},
pages = {100791},
year = {2025},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2025.100791},
url = {https://www.sciencedirect.com/science/article/pii/S157401372500067X},
author = {Byeonghui Jeong and Young-Sik Jeong},
keywords = {Cloud-native computing, Autoscaling, Resource management, Security},
abstract = {Autoscaling, the core technology of cloud-native computing, dynamically adjusts computing resources as per application load fluctuations in order to improve scalability, cost efficiency, and performance continuity. By doing so, autoscaling enables widespread adoption of cloud-native computing across various industries; consequently, autoscaling techniques are critical for supporting the cloud-native paradigm. This study aims to provide a comprehensive survey of cloud-native autoscaling techniques, offering a unified understanding of current approaches and identifying unresolved issues. First, autoscaling algorithms and mechanisms are each classified into three types. Through this classification framework, a wide range of scaling algorithms, from threshold-based reactive policies to artificial intelligence (AI)-based proactive policies, are examined, and their respective advantages and limitations are analyzed. Next, the study comprehensively investigates and summarizes the experimental environments, datasets, and performance metrics used for evaluating autoscaling techniques. Furthermore, it systematically discusses key considerations for optimizing autoscaling techniques across the lifecycle of cloud-native applications by dividing the process into three distinct stages. In addition, this study provides a comprehensive review of cyberattacks that exploit autoscaling and the corresponding mitigation strategies. Finally, it discusses open issues, future directions, and research opportunities related to autoscaling in cloud-native computing.}
}
@article{JUNG2021102305,
title = {Containers and orchestration of numerical ocean model for computational reproducibility and portability in public and private clouds: Application of ROMS 3.6},
journal = {Simulation Modelling Practice and Theory},
volume = {109},
pages = {102305},
year = {2021},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2021.102305},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X21000290},
author = {Kwangwoog Jung and Yang-Ki Cho and Yong-Jin Tak},
keywords = {Numerical ocean model, Computational reproducibility, High-performance computing, Cloud computing, Infra abstraction, Containerization, Docker, Regional Ocean-modeling System, Kubernetes, Public and Private Cloud},
abstract = {Various numerical models have been used to understand and predict ocean dynamics. For this reason, many information technology (IT) resources are required for high-resolution global ocean modeling. The development of cloud-computing technologies has enabled earth scientists to easily use numerical ocean models that require high-performance computing (HPC) and message-passing interface (MPI) software in private and public clouds. Although it is easier today to use computing resources than it was in the past, computational reproducibility and portability in diverse IT environments remain crucial issues. This study proposes a model execution architecture for computational reproducibility, portability, and agility based on container-based virtualization and orchestration technologies. We implement a containerized regional ocean-modeling system (ROMS), an MPI-based numerical ocean model that exists in various public or private cloud environments (e.g., personal computers and multiple-node servers). The preparation time for model setup is greatly reduced using our container-based HPC architecture. Containerization of ROMS is tested for its support of the portability of numerical modeling in a wide range of public-cloud environments. When leveraging an abstraction layer of complex and diverse infrastructure environments, we can run the ocean model more easily while obtaining computational reproducibility using a shareable deployment code. This advancement can be used to guide the containerization of various numerical models and to run them in parallel in public and private cloud-computing environments.}
}
@inproceedings{10.1145/3713081.3731735,
author = {Saavedra, Nuno and Ferreira, Jo\~{a}o F. and Mendes, Alexandra},
title = {InfraFix: Technology-Agnostic Repair of Infrastructure as Code},
year = {2025},
isbn = {9798400714740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713081.3731735},
doi = {10.1145/3713081.3731735},
abstract = {Infrastructure as Code (IaC) enables scalable and automated IT infrastructure management but is prone to errors that can lead to security vulnerabilities, outages, and data loss. While prior research has focused on detecting IaC issues, Automated Program Repair (APR) remains underexplored, largely due to the lack of suitable specifications. In this work, we propose InfraFix, the first technology-agnostic framework for repairing IaC scripts. Unlike prior approaches, InfraFix allows APR techniques to be guided by diverse information sources. Additionally, we introduce a novel approach for generating repair scenarios, enabling large-scale evaluation of APR techniques for IaC. We implement and evaluate InfraFix using an SMT-based repair module and a state inference module that uses system calls, demonstrating its effectiveness across 254,288 repair scenarios with a success rate of 95.7%. Our work provides a foundation for advancing APR in IaC by enabling researchers to experiment with new state inference and repair techniques using InfraFix and to evaluate their approaches at scale with our repair scenario generation method.},
booktitle = {Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {41–45},
numpages = {5},
keywords = {infrastructure as code, automated program repair, DevOps},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {ISSTA Companion '25}
}

@inproceedings{10.1145/3713081.3731721,
author = {Coppa, Emilio and Sokolowski, Daniel and Salvaneschi, Guido},
title = {Hybrid Fuzzing of Infrastructure as Code Programs (Short Paper)},
year = {2025},
isbn = {9798400714740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713081.3731721},
doi = {10.1145/3713081.3731721},
abstract = {Infrastructure as Code (IaC) has become a cornerstone of modern cloud and system deployment, enabling automated and repeatable infrastructure provisioning. However, ensuring the correctness of IaC programs remains challenging due to their complexity and dynamic nature. In particular, IaC programs can exhibit different behaviors depending on the state of the resources they manage. Since these resources are deployed on external providers, accounting for their possible states is difficult, making the testing phase particularly challenging. This paper presents HIT, a novel unit-testing framework for IaC programs that effectively tests IaC code using relevant resource states. HIT combines fuzzing and concolic execution, two effective yet previously unexplored techniques for IaC code. Our experiments confirm that HIT achieves better code coverage than state-of-the-art approaches.},
booktitle = {Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {92–97},
numpages = {6},
keywords = {fuzzing, infrastructure as code, symbolic execution, DevOps},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {ISSTA Companion '25}
}

@article{10.1145/3660790,
author = {Hassan, Md Mahadi and Salvador, John and Santu, Shubhra Kanti Karmaker and Rahman, Akond},
title = {State Reconciliation Defects in Infrastructure as Code},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660790},
doi = {10.1145/3660790},
abstract = {In infrastructure as code (IaC), state reconciliation is the process of querying and comparing the infrastructure state prior to changing the infrastructure. As state reconciliation is pivotal to manage IaC-based computing infrastructure at scale, defects related to state reconciliation can create large-scale consequences. A categorization of state reconciliation defects, i.e., defects related to state reconciliation, can aid in understanding the nature of state reconciliation defects. We conduct an empirical study with 5,110 state reconciliation defects where we apply qualitative analysis to categorize state reconciliation defects. From the identified defect categories, we derive heuristics to design prompts for a large language model (LLM), which in turn are used for validation of state reconciliation.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 From our empirical study, we identify 8 categories of state reconciliation defects, amongst which 3 have not been reported for previously-studied software systems. The most frequently occurring defect category is inventory, i.e., the category of defects that occur when managing infrastructure inventory. Using an LLM with heuristics-based paragraph style prompts, we identify 9 previously unknown state reconciliation defects of which 7 have been accepted as valid defects, and 4 have already been fixed. Based on our findings, we conclude the paper by providing a set of recommendations for researchers and practitioners.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {83},
numpages = {24},
keywords = {defect, devops, empirical study, infrastructure as code, state reconciliation}
}

@inproceedings{10.1145/3618305.3623607,
author = {Spielmann, David and Sokolowski, Daniel and Salvaneschi, Guido},
title = {Extensible Testing for Infrastructure as Code},
year = {2023},
isbn = {9798400703843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3618305.3623607},
doi = {10.1145/3618305.3623607},
abstract = {Developers automate deployments with   Programming Languages Infrastructure as Code (PL-IaC)   by implementing IaC programs in popular languages   like TypeScript and Python.   Yet, systematic testing---well established for high-velocity software development---is rarely applied to IaC programs   because IaC testing techniques   are either slow or require extensive development effort.   To solve this dilemma,   we develop ProTI, a novel IaC unit testing approach,   and implement it for Pulumi TypeScript.   Our preliminary experiments   with simple type-based test case generators and oracles show   that ProTI can find bugs reliably in a short time,   often without writing any additional testing code.   ProTI's extensible plugin architecture allows   combining, adopting, and experimenting with new approaches,   opening the discussion about novel generators and oracles   for efficient IaC testing.},
booktitle = {Companion Proceedings of the 2023 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity},
pages = {58–60},
numpages = {3},
keywords = {DevOps, Fuzzing, Infrastructure as Code, Testing},
location = {Cascais, Portugal},
series = {SPLASH 2023}
}

@inproceedings{10.1145/3694715.3695974,
author = {Qiu, Yiming and Kon, Patrick Tser Jern and Beckett, Ryan and Chen, Ang},
title = {Unearthing Semantic Checks for Cloud Infrastructure-as-Code Programs},
year = {2024},
isbn = {9798400712517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3694715.3695974},
doi = {10.1145/3694715.3695974},
abstract = {Cloud infrastructures are increasingly managed by Infrastructure-as-Code (IaC) frameworks (e.g., Terraform). IaC frameworks enable cloud users to configure their resources in a declarative manner, without having to directly work with low-level cloud API calls. However, with today's IaC tooling, IaC programs that pass the compilation phase may still incur errors at deployment time, resulting in significant disruption. We observe that this stems from a fundamental semantic gap between IaC-level programs and cloud-level requirements---even a syntactically-correct IaC program may violate cloud-level expectations. To bridge this gap, we develop Zodiac, a tool that can unearth IaC-level semantic checks on cloud-level requirements. It provides an automated pipeline to mine these checks from online IaC repositories and validate them using deployment-based testing. We have applied Zodiac to Terraform resources offered by Microsoft Azure---a leading IaC framework and a leading cloud vendor---where it found 500+ semantic checks where violation would produce deployment failures. With these checks, we have identified 200+ buggy Terraform projects and helped fix errors within official Azure provider usage examples.},
booktitle = {Proceedings of the ACM SIGOPS 30th Symposium on Operating Systems Principles},
pages = {574–589},
numpages = {16},
keywords = {infrastructure as code, cloud management, program analysis, configuration mining},
location = {Austin, TX, USA},
series = {SOSP '24}
}

@inproceedings{10.1145/3643991.3644888,
author = {Sokolowski, Daniel and Spielmann, David and Salvaneschi, Guido},
title = {The PIPr Dataset of Public Infrastructure as Code Programs},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644888},
doi = {10.1145/3643991.3644888},
abstract = {With Programming Languages Infrastructure as Code (PL-IaC), developers implement IaC programs in popular imperative programming languages like Python and Typescript. Such programs generate the declarative target state of the deployment, i.e., they describe what to set up, not how to set it up. Despite the popularity of PL-IaC, which has grown more than ten times from 2020 to 2023, we know little about how developers apply it and how IaC programs differ from other software. Such knowledge is essential to effectively use existing software engineering techniques and develop new ones for PL-IaC. To shed light on PL-IaC in practice, we present PIPr, the first systematic PL-IaC dataset. PIPr is based on 37 712 public IaC programs on GitHub from August 2022 and includes initial analyses, assessing the programming languages, testing techniques, and licenses of the IaC programs. Beyond the metadata and analysis results of all IaC programs, PIPr contains the code of all 15 504 IaC programs whose licenses permit redistribution. PIPr sets the ground for future in-depth investigations on PL-IaC in practice.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {498–503},
numpages = {6},
keywords = {infrastructure as code, Pulumi, AWS CDK, CDKTF, testing},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3639478.3643078,
author = {Sokolowski, Daniel and Spielmann, David and Salvaneschi, Guido},
title = {Unleashing the Giants: Enabling Advanced Testing for Infrastructure as Code},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3643078},
doi = {10.1145/3639478.3643078},
abstract = {Infrastructure as Code (IaC) programs are written in imperative programming languages like Python or TypeScript while declaratively defining the target state of software deployments, which the IaC solution then sets up, e.g., Pulumi and AWS CDK. Through a repository mining study and analysis, we noticed that testing IaC programs poses a dilemma: current techniques are either slow and expensive or require prohibitively high development effort. To solve this issue, we introduce Automated Configuration Testing (ACT), enabling efficient testing with low development effort. ACT automates the tedious aspects of unit testing IaC programs and is extensible through a plugin system for test generators and oracles. ACT is already effective with simple type-based plugins, and leveraging existing giants, i.e., advanced test generation and oracle techniques, in new plugins will further boost its effectiveness.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {300–301},
numpages = {2},
keywords = {property-based testing, fuzzing, infrastructure as code, DevOps},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@article{10.1145/3689799,
author = {Drosos, Georgios-Petros and Sotiropoulos, Thodoris and Alexopoulos, Georgios and Mitropoulos, Dimitris and Su, Zhendong},
title = {When Your Infrastructure Is a Buggy Program: Understanding Faults in Infrastructure as Code Ecosystems},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3689799},
doi = {10.1145/3689799},
abstract = {Modern applications have become increasingly complex and their manual installation and configuration is  no longer practical. Instead, IT organizations heavily rely on Infrastructure as Code (IaC) technologies, to automate the provisioning, configuration, and maintenance of computing infrastructures and systems. IaC systems typically offer declarative, domain-specific languages (DSLs) that allow system administrators and developers to write high-level programs that specify the desired state of their infrastructure in a reliable, predictable, and documented fashion. Just like traditional programs, IaC software is not immune to faults, with issues ranging from deployment failures to critical misconfigurations that often impact production systems used by millions of end users. Surprisingly, despite its crucial role in global infrastructure management, the tooling and techniques for ensuring IaC reliability still have room for improvement.     In this work, we conduct a comprehensive analysis of 360 bugs identified in IaC software within prominent IaC ecosystems including Ansible, Puppet, and Chef. Our work is the first in-depth exploration of bug characteristics in these widely-used IaC environments. Through our analysis we aim to understand: (1) how these bugs manifest, (2) their underlying root causes, (3) their reproduction requirements in terms of system state (e.g., operating system versions) or input characteristics, and (4) how these bugs are fixed. Based on our findings, we evaluate the state-of-the-art techniques for IaC reliability, identify their limitations, and provide a set of recommendations for future research. We believe that our study helps researchers to (1) better understand the complexity and peculiarities of IaC software, and (2) develop advanced tooling for more reliable and robust system configurations.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {359},
numpages = {31},
keywords = {Ansible, Chef, IaC, Puppet, bug, deployment, infrastructure as code, testing}
}

@inproceedings{10.1145/3714393.3726494,
author = {Tran, Anh-Duy and Sion, Laurens and Yskout, Koen and Joosen, Wouter},
title = {TerrARA: Automated Security Threat Modeling for Infrastructure as Code},
year = {2025},
isbn = {9798400714764},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3714393.3726494},
doi = {10.1145/3714393.3726494},
abstract = {The emergence of DevOps is accompanied by an increased use of Infrastructure as Code (IaC) to specify and manage deployment configurations, infrastructure, and associated resources. Terraform is one such IaC solution. However, improper configurations can lead to serious security threats. This paper introduces an approach, implemented as TerrARA, that provides a systematic and structured way for automatically eliciting security threats based on Terraform configuration files. Specifically, TerrARA: (1) automates the construction of an abstract model-an enriched Data Flow Diagram (DFD)-from Terraform configuration files for Amazon Web Services (AWS), and it can be extended to other resources and cloud providers via profiles; (2) encodes cloud computing threat patterns, which are utilized by the SPARTA threat modeling engine to automatically identify security threats; and (3) demonstrates its capability in accurately extracting DFDs from Terraform projects and eliciting relevant cloud computing security threats, achieving high accuracy and reasonable performance compared to existing tools and approaches like StartLeft and GPT-4o. By integrating it into CI/CD pipelines, the automated reconstruction and analysis enable continuous security assessments that systematically incorporate cloud infrastructure artifacts into the threat modeling process.},
booktitle = {Proceedings of the Fifteenth ACM Conference on Data and Application Security and Privacy},
pages = {269–280},
numpages = {12},
keywords = {data flow diagram, infrastructure as code, security by design, terraform, threat modeling},
location = {Pittsburgh, PA, USA},
series = {CODASPY '25}
}

@inproceedings{10.1145/3540250.3558912,
author = {Sokolowski, Daniel},
title = {Infrastructure as code for dynamic deployments},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3558912},
doi = {10.1145/3540250.3558912},
abstract = {Modern DevOps organizations require a high degree of automation to achieve software stability at frequent changes. Further, there is a need for flexible, timely reconfiguration of the infrastructure, e.g., to use pay-per-use infrastructure efficiently based on application load. Infrastructure as Code (IaC) is the DevOps tool to automate infrastructure. However, modern static IaC solutions only support infrastructures that are deployed and do not change afterward. To implement infrastructures that change dynamically over time, static IaC programs have to be (updated and) re-run, e.g., in a CI/CD pipeline, or configure an external orchestrator that implements the dynamic behavior, e.g., an autoscaler or Kubernetes operator. Both do not capture the dynamic behavior in the IaC program and prevent analyzing and testing the infrastructure configuration jointly with its dynamic behavior. To fill this gap, we envision dynamic IaC, which augments static IaC with the ability to define dynamic behavior within the IaC program. In contrast to static IaC programs, dynamic IaC programs run continuously. They re-evaluate program parts that depend on external signals when these change and automatically adjust the infrastructure accordingly. We implement DIaC as the first dynamic IaC solution and demonstrate it in two realistic use cases of broader relevance. With dynamic IaC, ensuring the program’s correctness is even harder than for static IaC because programs may define many target configurations in contrast to only a few. However, for this reason, it is also more critical. To solve this issue, we propose automated, specialized property-based testing for IaC programs and implement it in ProTI.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1775–1779},
numpages = {5},
keywords = {Cloud, DevOps, Infrastructure as Code, Software Evolution, Testing},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1109/ASE56229.2023.00162,
author = {Saavedra, Nuno and Gon\c{c}alves, Jo\~{a}o and Henriques, Miguel and Ferreira, Jo\~{a}o F. and Mendes, Alexandra},
title = {Polyglot Code Smell Detection for Infrastructure as Code with GLITCH},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00162},
doi = {10.1109/ASE56229.2023.00162},
abstract = {This paper presents GLITCH, a new technology-agnostic framework that enables automated polyglot code smell detection for Infrastructure as Code scripts. GLITCH uses an intermediate representation on which different code smell detectors can be defined. It currently supports the detection of nine security smells and nine design &amp; implementation smells in scripts written in Ansible, Chef, Docker, Puppet, or Terraform. Studies conducted with GLITCH not only show that GLITCH can reduce the effort of writing code smell analyses for multiple IaC technologies, but also that it has higher precision and recall than current state-of-the-art tools. A video describing and demonstrating GLITCH is available at: https://youtu.be/E4RhCcZjWbk.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2042–2045},
numpages = {4},
keywords = {devops, infrastructure as code, code smells, security smells, design smells, implementation smells, ansible, chef, docker, puppet, terraform, intermediate model, static analysis},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3643991.3644934,
author = {Begoug, Mahi and Chouchen, Moataz and Ouni, Ali and Abdullah Alomar, Eman and Mkaouer, Mohamed Wiem},
title = {Fine-Grained Just-In-Time Defect Prediction at the Block Level in Infrastructure-as-Code (IaC)},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644934},
doi = {10.1145/3643991.3644934},
abstract = {Infrastructure-as-Code (IaC) is an emerging software engineering practice that leverages source code to facilitate automated configuration of software systems' infrastructure. IaC files are typically complex, containing hundreds of lines of code and dependencies, making them prone to defects, which can result in breaking online services at scale. To help developers early identify and fix IaC defects, research efforts have introduced IaC defect prediction models at the file level. However, the granularity of the proposed approaches remains coarse-grained, requiring developers to inspect hundreds of lines of code in a file, while only a small fragment of code is defective. To alleviate this issue, we introduce a machine-learning-based approach to predict IaC defects at a fine-grained level, focusing on IaC blocks, i.e., small code units that encapsulate specific behaviours within an IaC file. We trained various machine learning algorithms based on a mixture of code, process, and change-level metrics. We evaluated our approach on 19 open-source projects that use Terraform, a widely used IaC tool. The results indicated that there is no single algorithm that consistently outperforms the others in 19 projects. Overall, among the six algorithms, we observed that the LightGBM model achieved a higher average of 0.21 in terms of MCC and 0.71 in terms of AUC. Models analysis reveals that the developer's experience and the relative number of added lines tend to be the most important features. Additionally, we found that blocks belonging to the most frequent types are more prone to defects. Our defect prediction models have also shown sensitivity to concept drift, indicating that IaC practitioners should regularly retrain their models.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {100–112},
numpages = {13},
keywords = {defect prediction, infrastructure-as-code, IaC, terraform},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@article{10.1145/3691630,
author = {Ntentos, Evangelos and Lueger, Nicole Elisabeth and Simhandl, Georg and Zdun, Uwe and Schneider, Simon and Scandariato, Riccardo and D\'{\i}az Ferreyra, Nicol\'{a}s E.},
title = {On the Understandability of Design-Level Security Practices in Infrastructure-as-Code Scripts and Deployment Architectures},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3691630},
doi = {10.1145/3691630},
abstract = {Infrastructure as Code (IaC) automates IT infrastructure deployment, which is particularly beneficial for continuous releases, for instance, in the context of microservices and cloud systems. Despite its flexibility in application architecture, neglecting security can lead to vulnerabilities. The lack of comprehensive architectural security guidelines for IaC poses challenges in adhering to best practices. We studied how developers interpret IaC scripts (source code) in two IaC technologies, Ansible and Terraform, compared to semi-formal IaC deployment architecture models and metrics regarding design-level security understanding. In a controlled experiment involving ninety-four participants, we assessed the understandability of IaC-based deployment architectures through source code inspection compared to semi-formal representations in models and metrics.We hypothesized that providing semi-formal IaC deployment architecture models and metrics as supplementary material would significantly improve the comprehension of IaC security-related practices, as measured by task correctness. Our findings suggest that semi-formal IaC deployment architecture models and metrics as supplementary material enhance the understandability of IaC security-related practices without significantly increasing duration. We also observed a significant correlation between task correctness and duration when models and metrics were provided.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {6},
numpages = {37},
keywords = {Infrastructure as code, modeling, best practices, controlled experiment, empirical software engineering}
}

@inproceedings{10.1145/3643916.3644439,
author = {Begoug, Mahi and Chouchen, Moataz and Ouni, Ali},
title = {TerraMetrics: An Open Source Tool for Infrastructure-as-Code (IaC) Quality Metrics in Terraform},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644439},
doi = {10.1145/3643916.3644439},
abstract = {Infrastructure-as-Code (IaC) constitutes a pivotal DevOps methodology, leading edge of software deployment onto cloud platforms. IaC relies on source code files rather than manual configuration to manage the infrastructure of a software system. Terraform, an IaC tool and its declarative configuration language named HCL, has recently garnered considerable attention among IaC practitioners. Like other software artefacts, Terraform files could be affected by misconfigurations, faults, and smells. Therefore, DevOps practitioners might benefit from a quality assurance tool to help them perform quality assurance activities on Terrafrom artefacts. This paper introduces TerraMetrics, an open-source tool designed to characterize the quality of Terraform artefacts by providing a catalogue of 40 quality metrics. TerraMetrics leverages the Terraform Abstract Syntax Tree (AST) to extract the metric list, offering a potentially enduring solution compared to conventional regular expressions. This tool comprises three main components: (i) a parser transforming HCL code into an AST, (ii) visitors that traverse the AST nodes to extract the metrics, and (iii) collectors for storing the collected metrics in JSON format. The TerraMetrics tool is publicly available as an Open Source tool, with a demo video, at: https://github.com/stilab-ets/terametrics.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {450–454},
numpages = {5},
keywords = {infrastructure-as-code, terraform, HCL, quality metrics, AST},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@article{10.1145/3748268,
author = {G\"{o}bel, Thomas and Baier, Harald},
title = {From IaC to IoC – Using Infrastructure as Code (IaC) to Generate Synthetic Datasets of Compromised (IoC) Linux Systems for Use in Digital Forensics},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3748268},
doi = {10.1145/3748268},
abstract = {Due to the increasing number of cyber attacks, there is a growing need for incident responders who are able to reconstruct events and assess the actual damage caused by an incident using digital forensics (DF). For this reason, DF datasets are crucial for education, training and tool testing. Currently, such datasets are available either as statically prepared images via one of the publicly available dataset repositories. Alternatively, a dataset generation framework can be used to synthesise individually configurable datasets. In this paper, we use the second approach and extend an established framework for our purposes. Our extension applies to both the target operating system and the framework traces induced by the data generation framework. More specifically, we take the existing data synthesis framework ForTrace as a baseline and integrate our concept of a Linux module that can perform (semi-)automatic attacks on Linux systems in order to create appropriate Indicators of Compromise (IoC) within the generated image. In doing so, we evaluate the suitability of Infrastructure as Code (IaC) for configuring vulnerable target systems and assess the effectiveness of our approach to avoiding undesirable artefacts caused by the data generation framework. To evaluate our framework extension, we generate synthetic datasets from two types of compromised systems as proof of concept using our new approach and then compare the actual traces generated with the expected traces based on the respective scenario.},
note = {Just Accepted},
journal = {Digital Threats},
month = sep,
keywords = {Digital Forensic Datasets, Digital Corpora, Digital Forensic Education and Training, Data Synthesis, Synthetic Data, Data Synthesis Framework, ForTrace, Infrastructure as Code, Indicators of Compromise, Linux Forensics}
}

@inproceedings{10.1145/3551349.3556945,
author = {Saavedra, Nuno and Ferreira, Jo\~{a}o F.},
title = {GLITCH: Automated Polyglot Security Smell Detection in Infrastructure as Code},
year = {2023},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551349.3556945},
doi = {10.1145/3551349.3556945},
abstract = {Infrastructure as Code (IaC) is the process of managing IT infrastructure via programmable configuration files (also called IaC scripts). Like other software artifacts, IaC scripts may contain security smells, which are coding patterns that can result in security weaknesses. Automated analysis tools to detect security smells in IaC scripts exist, but they focus on specific technologies such as Puppet, Ansible, or Chef. This means that when the detection of a new smell is implemented in one of the tools, it is not immediately available for the technologies supported by the other tools&nbsp;—&nbsp;the only option is to duplicate the effort. This paper presents an approach that enables consistent security smell detection across different IaC technologies. We conduct a large-scale empirical study that analyzes security smells on three large datasets containing 196,755 IaC scripts and 12,281,251 LOC. We show that all categories of security smells are identified across all datasets and we identify some smells that might affect many IaC projects. To conduct this study, we developed GLITCH, a new technology-agnostic framework that enables automated polyglot smell detection by transforming IaC scripts into an intermediate representation, on which different security smell detectors can be defined. GLITCH currently supports the detection of nine different security smells in scripts written in Ansible, Chef, or Puppet. We compare GLITCH with state-of-the-art security smell detectors. The results obtained not only show that GLITCH can reduce the effort of writing security smell analyses for multiple IaC technologies, but also that it has higher precision and recall than the current state-of-the-art tools.},
booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
articleno = {47},
numpages = {12},
keywords = {Ansible, Chef, Puppet, devops, infrastructure as code, intermediate model, security smells, static analysis},
location = {Rochester, MI, USA},
series = {ASE '22}
}

@inproceedings{10.1145/3416504.3424334,
author = {Hasan, Mohammed Mehedi and Bhuiyan, Farzana Ahamed and Rahman, Akond},
title = {Testing practices for infrastructure as code},
year = {2020},
isbn = {9781450381239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416504.3424334},
doi = {10.1145/3416504.3424334},
abstract = {Infrastructure as code (IaC) helps practitioners to rapidly deploy software services to end-users. Despite reported benefits, IaC scripts are susceptible to defects. Defects in IaC scripts can cause serious consequences, for example, creating large-scale outages similar to the Amazon Web Services (AWS) incident in 2017. The prevalence of defects in IaC scripts necessitates practitioners to implement IaC testing and be aware of IaC testing practices. A synthesis of IaC testing practices can enable practitioners in early mitigation of IaC defects and also help researchers to identify potential research avenues. The goal of this paper is to help practitioners improve the quality of infrastructure as code (IaC) scripts by identifying a set of testing practices for IaC scripts. We apply open coding on 50 Internet artifacts, such as blog posts to derive IaC testing practices. We identify six testing practices that include behavior-focused test coverage, the practice of measuring coverage of IaC test cases in terms of expected behavior. We conclude our paper by discussing how practitioners and researchers can leverage our derived list of testing practices for IaC.},
booktitle = {Proceedings of the 1st ACM SIGSOFT International Workshop on Languages and Tools for Next-Generation Testing},
pages = {7–12},
numpages = {6},
keywords = {configuration as code, devops, empirical study, infrastructure as code, practices, qualitative analysis, testing},
location = {Virtual, USA},
series = {LANGETI 2020}
}

@inproceedings{10.1145/3617733.3617777,
author = {Osaba, Eneko and Diaz-De-Arcaya, Josu and Alonso, Juncal and Lobo, Jesus L. and Benguria, Gorka and Etxaniz, I\~{n}aki},
title = {Multiobjective Optimization Analysis for Finding Infrastructure-as-Code Deployment Configurations},
year = {2023},
isbn = {9798400707735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617733.3617777},
doi = {10.1145/3617733.3617777},
abstract = {Multiobjective optimization is a hot topic in the artificial intelligence and operations research communities. The design and development of multiobjective methods is a frequent task for researchers and practitioners. As a result of this vibrant activity, a myriad of techniques have been proposed in the literature to date, demonstrating a significant effectiveness for dealing with situations coming from a wide range of real-world areas. This paper is focused on a multiobjective problem related to optimizing Infrastructure-as-Code deployment configurations. The system implemented for solving this problem has been coined as IaC Optimizer Platform (IOP). Despite the fact that a prototypical version of the IOP has been introduced in the literature before, a deeper analysis focused on the resolution of the problem is needed, in order to determine which is the most appropriate multiobjective method for embedding in the IOP. The main motivation behind the analysis conducted in this work is to enhance the IOP performance as much as possible. This is a crucial aspect of this system, deeming that it will be deployed in a real environment, as it is being developed as part of a H2020 European project. Going deeper, we resort in this paper to nine different evolutionary computation-based multiobjective algorithms. For assessing the quality of the considered solvers, 12 different problem instances have been generated based on real-world settings. Results obtained by each method after 10 independent runs have been compared using Friedman's non-parametric tests. Findings reached from the tests carried out lad to the creation of a multi-algorithm system, capable of applying different techniques according to the user's needs.},
booktitle = {Proceedings of the 2023 11th International Conference on Computer and Communications Management},
pages = {26–31},
numpages = {6},
location = {Nagoya, Japan},
series = {ICCCM '23}
}

@inproceedings{10.1145/3502717.3532125,
author = {Rahman, Akond and Shamim, Shazibul Islam and Shahriar, Hossain and Wu, Fan},
title = {Can We use Authentic Learning to Educate Students about Secure Infrastructure as Code Development?},
year = {2022},
isbn = {9781450392006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3502717.3532125},
doi = {10.1145/3502717.3532125},
abstract = {Despite yielding benefits for organizations, infrastructure as code (IaC) scripts are susceptible to security weaknesses, such as hard-coded passwords. Existence of such security weaknesses necessitate integration of education materials related to secure development of IaC scripts. In this preliminary work, we describe our experiences of how application of authentic learning helped students learn about secure development of IaC scripts. Our paper shows education materials based on authentic learning to help students learn about secure IaC development.},
booktitle = {Proceedings of the 27th ACM Conference on on Innovation and Technology in Computer Science Education Vol. 2},
pages = {631},
numpages = {1},
keywords = {devops, devsecops, infrastructure as code},
location = {Dublin, Ireland},
series = {ITiCSE '22}
}

@inproceedings{10.1145/3465481.3470030,
author = {Espinha Gasiba, Tiago and Andrei-Cristian, Iosif and Lechner, Ulrike and Pinto-Albuquerque, Maria},
title = {Raising Security Awareness of Cloud Deployments using Infrastructure as Code through CyberSecurity Challenges},
year = {2021},
isbn = {9781450390514},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3465481.3470030},
doi = {10.1145/3465481.3470030},
abstract = {Improper deployment of software can have serious consequences, ranging from simple downtime to permanent data loss and data breaches. Infrastructure as Code tools serve to streamline delivery by promising consistency and speed, by abstracting away from the underlying actions. However, this simplicity may distract from architectural or configuration faults, potentially compromising the secure development lifecycle. One way to address this issue involves awareness training. Sifu is a platform that provides education on security through serious games, developed in the industry, for the industry. The presented work extends the Sifu platform with challenges addressing Terraform-aided cloud deployment on Amazon Web Services. This paper proposes an evaluation pipeline behind the challenges, and provides details of the vulnerability detection and feedback mechanisms, as well as a novel technique for detecting undesired differences between a given architecture and a target result. Furthermore, this paper quantifies the challenges’ perceived usefulness and impact, by evaluating the challenges among a total of twelve participants. Our preliminary results show that the challenges are suitable for education and the industry, with potential usage in internal training. A key finding is that, although the participants understand the importance of secure coding, their answers indicate that universities leave them unprepared in this area. Finally, our results are compared with related industry works, to extract and provide good practices and advice for practitioners.},
booktitle = {Proceedings of the 16th International Conference on Availability, Reliability and Security},
articleno = {63},
numpages = {8},
keywords = {Awareness, CyberSecurity Challenges, DevSecOps, Infrastructure as Code, Secure Coding, Serious Games, Training},
location = {Vienna, Austria},
series = {ARES '21}
}

@inproceedings{10.1145/3417113.3422154,
author = {Bhuiyan, Farzana Ahamed and Rahman, Akond},
title = {Characterizing co-located insecure coding patterns in infrastructure as code scripts},
year = {2021},
isbn = {9781450381284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417113.3422154},
doi = {10.1145/3417113.3422154},
abstract = {Context: Insecure coding patterns (ICPs), such as hard-coded passwords can be inadvertently introduced in infrastructure as code (IaC) scripts, providing malicious users the opportunity to attack provisioned computing infrastructure. As performing code reviews is resource-intensive, a characterization of co-located ICPs, i.e., ICPs that occur together in a script can help practitioners to prioritize their review efforts and mitigate ICPs in IaC scripts. Objective: The goal of this paper is to help practitioners in prioritizing code review efforts for infrastructure as code (IaC) scripts by conducting an empirical study of co-located insecure coding patterns in IaC scripts. Methodology: We conduct an empirical study with 1613, 2764 and 2845 Puppet scripts respectively collected from three organizations namely, Mozilla, Openstack, and Wikimedia. We apply association rule mining to identify co-located ICPs in IaC scripts. Results: We observe 17.9%, 32.9%, and 26.7% of the scripts to include co-located ICPs respectively, for Mozilla, Openstack, and Wikimedia. The most frequent co-located ICP category is hard-coded secret and suspicious comment. Conclusion: Practitioners can prioritize code review efforts for IaC scripts by reviewing scripts that include co-located ICPs.},
booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
pages = {27–32},
numpages = {6},
keywords = {co-location, configuration script, devops, devsecops, empirical study, infrastructure as code, insecure coding pattern, puppet, security},
location = {Virtual Event, Australia},
series = {ASE '20}
}


@inproceedings{10.1145/3183440.3195034,
author = {Rahman, Akond and Stallings, Jonathan and Williams, Laurie},
title = {Defect prediction metrics for infrastructure as code scripts in DevOps},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3195034},
doi = {10.1145/3183440.3195034},
abstract = {Use of infrastructure as code (IaC) scripts helps software teams manage their configuration and infrastructure automatically. Information technology (IT) organizations use IaC scripts to create and manage automated deployment pipelines to deliver services rapidly. IaC scripts can be defective, resulting in dire consequences, such as creating wide-scale service outages for end-users. Prediction of defective IaC scripts can help teams to mitigate defects in these scripts by prioritizing their inspection efforts. The goal of this paper is to help software practitioners in prioritizing their inspection efforts for infrastructure as code (IaC) scripts by proposing defect prediction model-related metrics. IaC scripts use domain specific languages (DSL) that are fundamentally different from object-oriented programming (OOP) languages. Hence, the OOP-based metrics that researchers used in defect prediction might not be applicable for IaC scripts. We apply Constructivist Grounded Theory (CGT) on defect-related commits mined from version control systems to identify metrics suitable for IaC scripts. By applying CGT, we identify 18 metrics. Of these metrics, 13 are related to IaC, for example, count of string occurrences in a script. Four of the identified metrics are related to churn, and one metric is lines of code.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {414–415},
numpages = {2},
keywords = {DevOps, continuous deployment, infrastructure as code, metrics},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/3416505.3423563,
author = {Palma, Stefano Dalla and Mohammadi, Majid and Di Nucci, Dario and Tamburri, Damian A.},
title = {Singling the odd ones out: a novelty detection approach to find defects in infrastructure-as-code},
year = {2020},
isbn = {9781450381246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416505.3423563},
doi = {10.1145/3416505.3423563},
abstract = {Infrastructure-as-Code (IaC) is increasingly adopted. However, little is known about how to best maintain and evolve it. Previous studies focused on defining Machine-Learning models to predict defect-prone blueprints using supervised binary classification. This class of techniques uses both defective and non-defective instances in the training phase. Furthermore, the high imbalance between defective and non-defective samples makes the training more difficult and leads to unreliable classifiers. In this work, we tackle the defect-prediction problem from a different perspective using novelty detection and evaluate the performance of three techniques, namely OneClassSVM, LocalOutlierFactor, and IsolationForest, and compare their performance with a baseline RandomForest binary classifier. Such models are trained using only non-defective samples: defective data points are treated as novelty because the number of defective samples is too little compared to defective ones. We conduct an empirical study on an extremely-imbalanced dataset consisting of 85 real-world Ansible projects containing only small amounts of defective instances. We found that novelty detection techniques can recognize defects with a high level of precision and recall, an AUC-PR up to 0.86, and an MCC up to 0.31. We deem our results can influence the current trends in defect detection and put forward a new research path toward dealing with this problem.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation},
pages = {31–36},
numpages = {6},
keywords = {Defect Prediction, Infrastructure-as-Code, Novelty Detection},
location = {Virtual, USA},
series = {MaLTeSQuE 2020}
}

@inproceedings{10.1145/3416505.3423564,
author = {Borovits, Nemania and Kumara, Indika and Krishnan, Parvathy and Palma, Stefano Dalla and Di Nucci, Dario and Palomba, Fabio and Tamburri, Damian A. and van den Heuvel, Willem-Jan},
title = {DeepIaC: deep learning-based linguistic anti-pattern detection in IaC},
year = {2020},
isbn = {9781450381246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3416505.3423564},
doi = {10.1145/3416505.3423564},
abstract = {Linguistic anti-patterns are recurring poor practices concerning inconsistencies among the naming, documentation, and implementation of an entity. They impede readability, understandability, and maintainability of source code. This paper attempts to detect linguistic anti-patterns in infrastructure as code (IaC) scripts used to provision and manage computing environments. In particular, we consider inconsistencies between the logic/body of IaC code units and their names. To this end, we propose a novel automated approach that employs word embeddings and deep learning techniques. We build and use the abstract syntax tree of IaC code units to create their code embedments. Our experiments with a dataset systematically extracted from open source repositories show that our approach yields an accuracy between 0.785 and 0.915 in detecting inconsistencies.},
booktitle = {Proceedings of the 4th ACM SIGSOFT International Workshop on Machine-Learning Techniques for Software-Quality Evaluation},
pages = {7–12},
numpages = {6},
keywords = {Code Embedding, Deep Learning, Defects, IaC, Infrastructure Code, Linguistic Anti-patterns, Word2Vec},
location = {Virtual, USA},
series = {MaLTeSQuE 2020}
}


@inproceedings{10.1145/3603166.3632135,
author = {Falazi, Ghareeb and Harzenetter, Lukas and K\'{e}pes, K\'{a}lm\'{a}n and Leymann, Frank and Breitenb\"{u}cher, Uwe and Ntentos, Evangelos and Zdun, Uwe and Becker, Martin and Heldwein, Elena},
title = {Compliance Management of IaC-Based Cloud Deployments During Runtime},
year = {2024},
isbn = {9798400702341},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603166.3632135},
doi = {10.1145/3603166.3632135},
abstract = {Modern cloud applications increasingly depend on Infrastructure-as-Code (IaC) practices for infrastructure automation to help manage the complexity of deploying large-scale architectures. Additionally, the deployment of cloud applications is commonly subject to compliance rules. Moreover, designing compliant IaC-based cloud deployments is not enough since runtime changes to the infrastructure or the configuration of individual components may introduce compliance violations. Often, the process of checking and fixing such violations is done manually, which is time-consuming and error-prone. Therefore, this work aims to define and implement a method for runtime IaC compliance management that reduces the complexity, effort, and uncertainty of checking and enforcing compliance rules against IaC-based cloud deployments at runtime. To this end, we follow the design-science research methodology to design and implement (i) the Runtime IaC Compliance Management (RICMa) method and (ii) the IaC Compliance Management Framework (IaCMF) that supports the execution of the RICMa method. We prototypically implement IaCMF and evaluate it using a qualitative interview study with industry experts.},
booktitle = {Proceedings of the IEEE/ACM 16th International Conference on Utility and Cloud Computing},
articleno = {10},
numpages = {11},
keywords = {infrastructure-as-code, IaC, IT compliance, cloud compliance, compliance management},
location = {Taormina (Messina), Italy},
series = {UCC '23}
}

@inproceedings{10.1145/3663530.3665019,
author = {Mendis, Pemsith and Reeves, Wilson and Babar, Muhammad Ali and Zhang, Yue and Rahman, Akond},
title = {Evaluating the Quality of Open Source Ansible Playbooks: An Executability Perspective},
year = {2024},
isbn = {9798400706721},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663530.3665019},
doi = {10.1145/3663530.3665019},
abstract = {Infrastructure as code (IaC) is the practice of automatically managing computing platforms, such as Internet of Things (IoT) platforms. IaC has gained popularity in recent years, yielding a plethora of software artifacts, such as Ansible playbooks that are available on social coding platforms. Despite the availability of open source software (OSS) Ansible playbooks, there is a lack of empirical research on the quality of these playbooks, which can hinder the progress of IaC-related research. To that end, we conduct an empirical study with 2,952 OSS Ansible playbooks where we evaluate the quality of OSS playbooks from the perspective of executability, i.e., if publicly available OSS Ansible playbooks can be executed without failures. From our empirical study, we observe 71.5% of the mined 2,952 Ansible playbooks cannot be executed as is because of four categories of failures.},
booktitle = {Proceedings of the 4th International Workshop on Software Engineering and AI for Data Quality in Cyber-Physical Systems/Internet of Things},
pages = {2–5},
numpages = {4},
keywords = {Ansible, data quality, devops, executability, infrastructure as code},
location = {Porto de Galinhas, Brazil},
series = {SEA4DQ 2024}
}

@inproceedings{10.1145/3664476.3670929,
author = {Billoir, Eddie and Laborde, Romain and Wazan, Ahmad Samer and Rutschle, Yves and Benzekri, Abdelmalek},
title = {Enhancing Secure Deployment with Ansible: A Focus on Least Privilege and Automation for Linux},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3670929},
doi = {10.1145/3664476.3670929},
abstract = {As organisations increasingly adopt Infrastructure as Code (IaC), ensuring secure deployment practices becomes paramount. Ansible is a well-known open-source and modular tool for automating IT management tasks. However, Ansible is subject to supply-chain attacks that can compromise all managed hosts. This article presents a semi-automated process that improves Ansible-based deployments to have fine-grained control on administrative privileges granted to Ansible tasks. We describe the integration of the RootAsRole framework to Ansible. Finally, we analyse the limit of the current implementation.},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {56},
numpages = {7},
keywords = {Ansible, Infrastructure as Code, Principle of Least privilege, Security},
location = {Vienna, Austria},
series = {ARES '24}
}

@inproceedings{10.1145/2740908.2742833,
author = {Scheuner, Joel and Cito, J\"{u}rgen and Leitner, Philipp and Gall, Harald},
title = {Cloud WorkBench: Benchmarking IaaS Providers based on Infrastructure-as-Code},
year = {2015},
isbn = {9781450334730},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2740908.2742833},
doi = {10.1145/2740908.2742833},
abstract = {Optimizing the deployment of applications in Infrastructure-as-a-Service clouds requires to evaluate the costs and performance of different combinations of cloud configurations which is unfortunately a cumbersome and error-prone process. In this paper, we present Cloud WorkBench (CWB), a concrete implementation of a cloud benchmarking Web service, which fosters the definition of reusable and representative benchmarks. We demonstrate the complete cycle of benchmarking an IaaS service with the sample benchmark SysBench. In distinction to existing work, our system is based on the notion of Infrastructure-as-Code, which is a state of the art concept to define IT infrastructure in a reproducible, well-defined, and testable way.},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
pages = {239–242},
numpages = {4},
keywords = {benchmarking, cloud computing, devops, iaas, iac},
location = {Florence, Italy},
series = {WWW '15 Companion}
}

@inproceedings{10.1145/3708035.3736065,
author = {Canales Bigio, Paola and Durbin, Mark},
title = {Cloud Based Data Pipeline supporting the Florida Zero Suicide Initiative Reporting},
year = {2025},
isbn = {9798400713989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708035.3736065},
doi = {10.1145/3708035.3736065},
abstract = {Data extract, transform, and load (ETL) pipelines facilitate repeatable and reliable processing of research data. This work presents a low-cost cloud ETL pipeline that uses Amazon Web services (AWS) to retrieve survey responses from Qualtrics, perform statistical computations, and host JSON-formatted output that is used to generate visualizations of the survey results for distribution and analysis. A reproducible infrastructure as code template was developed for the Florida LEADS (Launch Engage Activate Departments and Systems for Zero Suicide) project. This template can be used for projects that require the consumption of Qualtrics data for their research.},
booktitle = {Practice and Experience in Advanced Research Computing 2025: The Power of Collaboration},
articleno = {24},
numpages = {3},
keywords = {AWS, Data Pipeline, ETL pipeline, Infrastructure as Code, Qualtrics, Research data collection, Research data workflow},
location = {
},
series = {PEARC '25}
}

@inproceedings{10.1145/3626111.3628206,
author = {Qiu, Yiming and Kon, Patrick Tser Jern and Xing, Jiarong and Huang, Yibo and Liu, Hongyi and Wang, Xinyu and Huang, Peng and Chowdhury, Mosharaf and Chen, Ang},
title = {Simplifying Cloud Management with Cloudless Computing},
year = {2023},
isbn = {9798400704154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626111.3628206},
doi = {10.1145/3626111.3628206},
abstract = {Cloud computing has transformed the IT industry, but managing cloud infrastructures remains a difficult task. We make a case for putting today's management practices, known as "Infrastructure-as-Code," on a firmer ground via a principled design. We call this end goal Cloudless Computing: it aims to simplify cloud infrastructure management tasks by supporting them "as-a-service," analogous to serverless computing that relieves users of the burden of managing server instances. By assisting tenants with these tasks, cloud resources will be presented to their users more readily without the undue burden of complex control. We describe the research problems by examining the typical lifecycle of today's cloud infrastructure management, and identify places where a cloudless approach will advance the state of the art.},
booktitle = {Proceedings of the 22nd ACM Workshop on Hot Topics in Networks},
pages = {95–101},
numpages = {7},
keywords = {Infrastructure as code, cloud management},
location = {Cambridge, MA, USA},
series = {HotNets '23}
}

@inproceedings{10.1145/3641554.3701870,
author = {Saligrama, Aditya and Ho, Cody and Tripp, Benjamin and Abbott, Michael and Kozyrakis, Christos},
title = {Teaching Cloud Infrastructure and Scalable Application Deployment in an Undergraduate Computer Science Program},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701870},
doi = {10.1145/3641554.3701870},
abstract = {Making successful use of cloud computing requires nuanced approaches to both system design and deployment methodology, involving reasoning about the elasticity, cost, and security models of cloud services. Building cloud-native applications without a firm understanding of the fundamentals of cloud engineering can leave students susceptible to cost and security pitfalls. Yet, cloud computing is not commonly taught at the undergraduate level. To address this gap, we designed an undergraduate-level course that frames cloud infrastructure deployment as a software engineering practice. Our course featured a number of hands-on assignments that gave students experience with modern, best-practice concepts and tools including infrastructure-as-code (IaC). We describe the design of the course, our experience teaching its initial offering, and provide our reflections on what worked well and potential areas for improvement. Our course material is available at https://infracourse.cloud.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1015–1021},
numpages = {7},
keywords = {application deployment, computing, computing education, infrastructure-as-code, scalability},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3569951.3597555,
author = {Skidmore, Edwin and Cosi, Michele and Swetnam, Tyson and Merchant, Nirav and Xu, Zhouyun and Choi, Illyoung and Davey, Sean and Frady, Jeremy and Wall, Mariah and Yung, Michelle},
title = {Cloud Computing for Research and Education Gets a Sweet Upgrade with CACAO},
year = {2023},
isbn = {9781450399852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569951.3597555},
doi = {10.1145/3569951.3597555},
abstract = {We introduce Cloud Automation and Continuous Analysis Orchestration&nbsp;(CACAO), an open source web platform designed to facilitate access and availability of cloud resources for education and research. By leveraging open source Infrastructure-as-Code&nbsp;(IaC) technologies such as Terraform and Ansible, CACAO empowers users to create customized cloud resources and complex software stacks through an intuitive web interface. CACAO integrates with CyVerse, another prominent open source cyberinfrastructure, and is a featured interface for Jetstream2, a public education and research cloud. CACAO effectively manages multi-cloud deployments in OpenStack and commercial service providers. In 2022 bioinformatics and machine learning workshops worldwide used CACAO during its alpha release. CACAO adheres to open science standards and the FAIR data principles, broadening access to cloud platforms and reducing the complexity of deploying the resources necessary for teaching advanced data informatics skills required in today’s workforce.},
booktitle = {Practice and Experience in Advanced Research Computing 2023: Computing for the Common Good},
pages = {251–254},
numpages = {4},
keywords = {cloud computing, containers, cyberinfrastructure, infrastructure as code, multicloud, open science, orchestration},
location = {Portland, OR, USA},
series = {PEARC '23}
}

@inproceedings{10.1145/3468264.3473101,
author = {Sokolowski, Daniel},
title = {Deployment coordination for cross-functional DevOps teams},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3473101},
doi = {10.1145/3468264.3473101},
abstract = {Software stability and reliability are the core concerns of DevOps. They are improved by tightening the collaboration between developers and operators in cross-functional teams on the one hand and by automating operations through continuous integration (CI) and infrastructure as code (IaC) on the other hand. Ideally, teams in DevOps are fully independent. Still, their applications often depend on each other in practice, requiring them to coordinate their deployment through centralization or manual coordination. With this work, we propose and implement the novel IaC solution µs ([mju:z] ”muse”), which automates deployment coordination in a decentralized fashion. µs is the first approach that is compatible with the DevOps goals as it enables truly independent operations of the DevOps teams. We define our research problem through a questionnaire survey with IT professionals and evaluate the solution by comparing it to other modern IaC approaches, assessing its performance, and applying it to existing IaC programs.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1630–1634},
numpages = {5},
keywords = {Cloud, DevOps, Infrastructure as Code, Resource Orchestration},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}


@article{10.1145/3408897,
author = {Rahman, Akond and Rahman, Md Rayhanur and Parnin, Chris and Williams, Laurie},
title = {Security Smells in Ansible and Chef Scripts: A Replication Study},
year = {2021},
issue_date = {January 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3408897},
doi = {10.1145/3408897},
abstract = {Context: Security smells are recurring coding patterns that are indicative of security weakness and require further inspection. As infrastructure as code (IaC) scripts, such as Ansible and Chef scripts, are used to provision cloud-based servers and systems at scale, security smells in IaC scripts could be used to enable malicious users to exploit vulnerabilities in the provisioned systems. Goal: The goal of this article is to help practitioners avoid insecure coding practices while developing infrastructure as code scripts through an empirical study of security smells in Ansible and Chef scripts. Methodology: We conduct a replication study where we apply qualitative analysis with 1,956 IaC scripts to identify security smells for IaC scripts written in two languages: Ansible and Chef. We construct a static analysis tool called Security Linter for Ansible and Chef scripts (SLAC) to automatically identify security smells in 50,323 scripts collected from 813 open source software repositories. We also submit bug reports for 1,000 randomly selected smell occurrences. Results: We identify two security smells not reported in prior work: missing default in case statement and no integrity check. By applying SLAC we identify 46,600 occurrences of security smells that include 7,849 hard-coded passwords. We observe agreement for 65 of the responded 94 bug reports, which suggests the relevance of security smells for Ansible and Chef scripts amongst practitioners. Conclusion: We observe security smells to be prevalent in Ansible and Chef scripts, similarly to that of the Puppet scripts. We recommend practitioners to rigorously inspect the presence of the identified security smells in Ansible and Chef scripts using (i) code review, and (ii) static analysis tools.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
articleno = {3},
numpages = {31},
keywords = {Ansible, chef, configuration as code, configuration scripts, devops, devsecops, empirical study, infrastructure as code, insecure coding, security, smell, static analysis}
}

@inproceedings{10.1145/3616131.3616142,
author = {Millward, Douglas J. and Reed, Martin J. and Olaniyi, Nkaepe},
title = {CACLE - Automated Mitigation for Misconfiguration Vulnerabilities in Cloud Systems},
year = {2023},
isbn = {9798400707339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616131.3616142},
doi = {10.1145/3616131.3616142},
abstract = {Recent studies have highlighted the increasing risk to Cloud Systems of User Misconfiguration Errors. This paper provides an evolutionary approach to identifying and mitigating such errors, known as the Configuration and Checking Logic Engine. We demonstrate its effectiveness utilizing test files from publicly available GitHub repositories. The results show that not only is it as effective as other solutions that check IaC templates, but it is also an order of magnitude faster than existing approaches.},
booktitle = {Proceedings of the 2023 7th International Conference on Cloud and Big Data Computing},
pages = {74–80},
numpages = {7},
keywords = {Additional Key Words and Phrases: cloud security, automated vulnerability mitigation, infrastructure as code, user misconfiguration errors},
location = {Manchester, United Kingdom},
series = {ICCBDC '23}
}

@inproceedings{10.1145/3624486.3624507,
author = {Villanueva, Eliseo and Torres, Ismael and Osaba, Eneko and Canzoneri, Sergio and Franchini, Andrea and Blasi, Lorenzo},
title = {PIACERE Integrated Development Environment},
year = {2023},
isbn = {9798400708350},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624486.3624507},
doi = {10.1145/3624486.3624507},
abstract = {This article presents a model-driven engineering (MDE) integrated development environment (IDE) to assist the DevSecOps (Development Security and Operations) process. This tool has been developed within the PIACERE H2020 project, which proposes a framework composed of a set of tools developed to support all phases of the DevSecOps life cycle including modeling, test/validation, build/generate, deployment, operate and modeling. PIACERE IDE is an Eclipse based tool, that acts as the front-end for this framework, and plays a key role in integrating other PIACERE tools. The IDE allows developers to access the different tools in a simple and unified way.},
booktitle = {Proceedings of the 3rd Eclipse Security, AI, Architecture and Modelling Conference on Cloud to Edge Continuum},
pages = {62–66},
numpages = {5},
keywords = {DevSecOps, Eclipse, IDE (integrated development environment), IaC (Infrastructure as Code)},
location = {Ludwigsburg, Germany},
series = {eSAAM '23}
}

@inproceedings{10.1145/3468264.3468575,
author = {Sokolowski, Daniel and Weisenburger, Pascal and Salvaneschi, Guido},
title = {Automating serverless deployments for DevOps organizations},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468575},
doi = {10.1145/3468264.3468575},
abstract = {DevOps unifies software development and operations in cross-functional teams to improve software delivery and operations (SDO) performance. Ideally, cross-functional DevOps teams independently deploy their services, but the correct operation of a service often demands other services, requiring coordination to ensure the correct deployment order. This issue is currently solved either with a central deployment or manual out-of-band communication across teams, e.g., via phone, chat, or email. Unfortunately, both contradict the independence of teams, hindering SDO performance—the reason why DevOps is adopted in the first place. In this work, we conduct a study on 73 IT professionals, showing that, in practice, they resort to manual coordination for correct deployments even if they expect better SDO performance with fully automated approaches. To address this issue, we propose µs ([mju:z] “muse”), a novel IaC system automating deployment coordination in a fully decentralized fashion, still retaining compatibility with DevOps practice—in contrast to today’s solutions. We implement µs, demonstrate that it effectively enables automated coordination, introduces negligible definition overhead, has no performance overhead, and is broadly applicable, as shown by the migration of 64 third-party IaC projects.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {57–69},
numpages = {13},
keywords = {Cloud, DevOps, Infrastructure as Code, Serverless Computing},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@article{10.5555/3729857.3729869,
author = {Szakonyi, Annamaria},
title = {The Impact of Course Modality and Size on Learning Outcomes: Applying IaC Principles in IS/Cyber Graduate Course Design},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {6},
issn = {1937-4771},
abstract = {This study explores the impact of class size and course modality on student learning outcomes, using Infrastructure as Code (IaC) principles to design Information Systems and Cybersecurity graduate courses. To address challenges like larger class sizes, diverse formats, and AI reliance, IaC principles such as scalability, modularity, and repeatability were applied to course design. Tools like LMS blueprints and modular templates ensured consistency across online and in-person formats. Analysis of student feedback and grades showed that smaller classes and individual assignments improved outcomes, while group work fostered collaboration. The findings suggest that IaC-inspired strategies can improve scalability and quality in graduate education.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {111–120},
numpages = {10}
}

@article{10.1145/3607186,
author = {Bessghaier, Narjes and Sayagh, Mohammed and Ouni, Ali and Mkaouer, Mohamed Wiem},
title = {What Constitutes the Deployment and Runtime Configuration System? An Empirical Study on OpenStack Projects},
year = {2023},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3607186},
doi = {10.1145/3607186},
abstract = {Modern software systems are designed to be deployed in different configured environments (e.g., permissions, virtual resources, network connections) and adapted at runtime to different situations (e.g., memory limits, enabling/disabling features, database credentials). Such a configuration during the deployment and runtime of a software system is implemented via a set of configuration files, which together constitute what we refer to as a “configuration system.” Recent research efforts investigated the evolution and maintenance of configuration files. However, they merely focused on a limited part of the configuration system (e.g., specific infrastructure configuration files or Dockerfiles), and their results do not generalize to the whole configuration system. To cope with such a limitation, we aim to better capture and understand what files constitute a configuration system. To do so, we leverage an open card sort technique to qualitatively study 1,756 configuration files from OpenStack, a large and widely studied open source software ecosystem. Our investigation reveals the existence of nine types of configuration files, which cover the creation of the infrastructure on top of which OpenStack will be deployed, along with other types of configuration files used to customize OpenStack after its deployment. These configuration files are interconnected while being used at different deployment stages. For instance, we observe specific configuration files used during the deployment stage to create other configuration files that are used in the runtime stage. We also observe that identifying and classifying these types of files is not straightforward, as five out of the nine types can be written in similar programming languages (e.g., Python and Bash) as regular source code files. We also found that the same file extensions (e.g., Yaml) can be used for different configuration types, making it difficult to identify and classify configuration files. Thus, we first leverage a machine learning model to identify configuration from non-configuration files, which achieved a median area under the curve (AUC) of 0.91, a median Brier score of 0.12, a median precision of 0.86, and a median recall of 0.83. Thereafter, we leverage a multi-class classification model to classify configuration files based on the nine configuration types. Our multi-class classification model achieved a median weighted AUC of 0.92, a median Brier score of 0.04, a median weighted precision of 0.84, and a median weighted recall of 0.82. Our analysis also shows that with only 100 labeled configuration and non-configuration files, our model reached a median AUC higher than 0.69. Furthermore, our configuration model requires a minimum of 100 configuration files to reach a median weighted AUC higher than 0.75.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
articleno = {5},
numpages = {37},
keywords = {Configuration files, infrastructure-as-code, files classification, machine learning models, OpenStack}
}

@inproceedings{10.1145/3578245.3584943,
author = {Cankar, Matija and Petrovic, Nenad and Pita Costa, Joao and Cernivec, Ales and Antic, Jan and Martincic, Tomaz and Stepec, Dejan},
title = {Security in DevSecOps: Applying Tools and Machine Learning to Verification and Monitoring Steps},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3584943},
doi = {10.1145/3578245.3584943},
abstract = {Security represents one of the crucial concerns when it comes to DevOps methodology-empowered software development and service delivery process. Considering the adoption of Infrastructure as Code (IaC), even minor flaws could potentially cause fatal consequences, especially in sensitive domains such as healthcare and maritime applications. However, most of the existing solutions tackle either Static Application Security Testing (SAST) or run-time behavior analysis distinctly. In this paper, we propose a) IaC Scan Runner, an open-source solution developed in Python for inspecting a variety of state-of-the-art IaC languages in application design time and b) the run time anomaly detection tool called LOMOS. Both tools work in synergy and provide a valuable contribution to a DevSecOps tool set. The proposed approach is demonstrated and their results will be demonstrated on various case studies showcasing the capabilities of static analysis tool IaC Scan Runner combined with LOMOS - log analysis artificial intelligence-enabled framework.},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {201–205},
numpages = {5},
keywords = {DAST, DevOps, DevSecOps, IaC, SAST, machine learning, natural language processing, self-supervised learning},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1145/3638209.3638223,
author = {Osaba, Eneko and Benguria, Gorka and Lobo, Jesus L. and Diaz-De-Arcaya, Josu and Alonso, Juncal and Etxaniz, I\~{n}aki},
title = {Optimizing IaC Configurations: a Case Study Using Nature-inspired Computing},
year = {2024},
isbn = {9798400709067},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638209.3638223},
doi = {10.1145/3638209.3638223},
abstract = {In the last years, one of the fields of artificial intelligence that has been investigated the most is nature-inspired computing. The research done on this specific topic showcases the interest that sparks in researchers and practitioners, who put their focus on this paradigm because of the adaptability and ability of nature-inspired algorithms to reach high-quality outcomes on a wide range of problems. In fact, this kind of methods has been successfully applied to solve real-world problems in heterogeneous fields such as medicine, transportation, industry, or software engineering. Our main objective with this paper is to describe a tool based on nature-inspired computing for solving a specific software engineering problem. The problem faced consists of optimizing Infrastructure as Code deployment configurations. For this reason, the name of the system is IaC Optimizer Platform. A prototypical version of the IOP was described in previous works, in which the functionality of this platform was introduced. With this paper, we take a step forward by describing the final release of the IOP, highlighting its main contribution regarding the current state-of-the-art, and justifying the decisions made on its implementation. Also, we contextualize the IOP within the complete platform in which it is embedded, describing how a user can benefit from its use. To do that, we also present and solve a real-world use case.},
booktitle = {Proceedings of the 2023 6th International Conference on Computational Intelligence and Intelligent Systems},
pages = {85–90},
numpages = {6},
keywords = {Combinatorial Optimization, Multi-objective Optimization, Nature-inspired Computing, PIACERE},
location = {Tokyo, Japan},
series = {CIIS '23}
}

@inproceedings{10.1145/3419111.3421303,
author = {Dai, Ting and Karve, Alexei and Koper, Grzegorz and Zeng, Sai},
title = {Automatically detecting risky scripts in infrastructure code},
year = {2020},
isbn = {9781450381376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3419111.3421303},
doi = {10.1145/3419111.3421303},
abstract = {Infrastructure code supports embedded scripting languages such as Shell and PowerShell to manage the infrastructure resources and conduct life-cycle operations. Risky patterns in the embedded scripts have widespread of negative impacts across the whole infrastructure, causing disastrous consequences. In this paper, we propose an analysis framework, which can automatically extract and compose the embedded scripts from infrastructure code before detecting their risky code patterns with correlated severity levels and negative impacts. We implement SecureCode based on the proposed framework to check infrastructure code supported by Ansible, i.e., Ansible playbooks. We integrate SecureCode with the DevOp pipeline deployed in IBM cloud and test Secure-Code on 45 IBM Services community repositories. Our evaluation shows that SecureCode can efficiently and effectively identify 3419 true issues with 116 false positives in minutes. Among the 3419 true issues, 1691 have high severity levels.},
booktitle = {Proceedings of the 11th ACM Symposium on Cloud Computing},
pages = {358–371},
numpages = {14},
keywords = {ansible, availability, infrastructure-as-code, performance, powershell, reliability, security, shell, static analysis},
location = {Virtual Event, USA},
series = {SoCC '20}
}

@inproceedings{10.1145/3492323.3495624,
author = {Ceesay, Sheriffo and Lin, Yuhui and Barker, Adam},
title = {Adaptive brokerage framework for the cloud with functional testing},
year = {2022},
isbn = {9781450391634},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3492323.3495624},
doi = {10.1145/3492323.3495624},
abstract = {In this paper, we present an Adaptive Brokerage for the Cloud (ABC) that can be used to simplify application deployment, monitoring and management processes in the cloud. The broker uses modern cloud infrastructure automation tools to test, deploy, monitor and optimise cloud resources. We used an e-commerce application to evaluate the entire functionality of the broker, we found out that different deployment options such as single-tier vs two-tier lead to interesting hardware and application performance insights. These insights are used to make effective infrastructure optimisation decisions.},
booktitle = {Proceedings of the 14th IEEE/ACM International Conference on Utility and Cloud Computing Companion},
articleno = {14},
numpages = {6},
keywords = {IaC, automated provisioning, cloud computing, functional testing, software engineering},
location = {Leicester, United Kingdom},
series = {UCC '21}
}

@inproceedings{10.1145/3687997.3695643,
author = {Simhandl, Georg and Zdun, Uwe},
title = {Cloud Programming Languages and Infrastructure from Code: An Empirical Study},
year = {2024},
isbn = {9798400711800},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687997.3695643},
doi = {10.1145/3687997.3695643},
abstract = {Infrastructure-from-Code (IfC) is a new approach to DevOps and an advancement of Infrastructure-as-Code (IaC).     One of its key concepts is to provide a higher level of abstraction facilitated by new programming languages or software development kits, which automatically generate the necessary code and configurations to provision the infrastructure, deploy the application, and manage the cloud services. IfC approaches promise higher developer productivity by reducing DevOps-specific tasks and the expert knowledge required. However, empirical studies on developers' performance, perceived ease of use, and usability related to IfC are missing. We conducted a controlled experiment (n=40) to assess the usability of the cloud programming languages (PL) and software development kits (SDK). Both approaches involve similar effectiveness. We found that the PL-based approach was moderately less efficient but increased correctness with time spent on programming. Tracing generated infrastructure configurations from code was more challenging with the SDK-based approach. Applying thematic analysis, 19 themes emerged related to usability barriers, supporting factors, security, cloud cost, and enhancement areas. We conclude with five findings and future directions.},
booktitle = {Proceedings of the 17th ACM SIGPLAN International Conference on Software Language Engineering},
pages = {143–156},
numpages = {14},
keywords = {Cloud, Empirical Study, Experiment, Infrastructure From Code, Programming Language},
location = {Pasadena, CA, USA},
series = {SLE '24}
}

@inproceedings{10.1145/3053600.3053629,
author = {Miglierina, Marco and Tamburri, Damian A.},
title = {Towards Omnia: A Monitoring Factory for Quality-Aware DevOps},
year = {2017},
isbn = {9781450348997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3053600.3053629},
doi = {10.1145/3053600.3053629},
abstract = {Modern DevOps pipelines entail extreme automation and speed as paramount assets for continuous application improvement. Likewise, monitoring is required to assess the quality of service and user-experience such that applications can continuously evolve towards use-centric excellence. In this scenario however, it is increasingly difficult to pull up and maintain efficient monitoring infrastructures which are frictionless, i.e., they do not introduce any slowdown neither in the DevOps pipeline nor in the DevOps organizational and social structure comprising multiple roles and responsibilities. Using an experimental prototype, this paper elaborates Omnia an approach for structured monitoring configuration and rollout based around a monitoring factory, i.e., a re-interpretation of the factory design-pattern for building and managing ad-hoc monitoring platforms. Comparing with practitioner surveys and the state of the art, we observed that Omnia shows the promise of delivering an effective solution that tackles the steep learning curve and entry costs needed to embrace cloud monitoring and monitoring-based DevOps continuous improvement.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
pages = {145–150},
numpages = {6},
keywords = {monitoring, monitoring configuration as code, monitoring factory, monitoring infrastructure as code, monitoring interface, monitoring management},
location = {L'Aquila, Italy},
series = {ICPE '17 Companion}
}

@inproceedings{10.1145/3274694.3274713,
author = {Rahman, Md Lutfor and Neupane, Ajaya and Song, Chengyu},
title = {IAC: On the Feasibility of Utilizing Neural Signals for Access Control},
year = {2018},
isbn = {9781450365697},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3274694.3274713},
doi = {10.1145/3274694.3274713},
abstract = {Access control is the core security mechanism of an operating system (OS). Ideally, the access control system should enforce context integrity, i.e., an application can only access security and privacy sensitive resources expected by users. Unfortunately, existing access control systems, including the permission systems in modern OS like iOS and Android, all fail to enforce context integrity thus allow apps to abuse their permissions. A naive approach to enforce context integrity is to prompt users every time a sensitive resource is accessed, but this will quickly lead to habituation. The state-of-art solutions include (1) user-driven access control, which binds a predefined context to protected GUI elements and (2) predicting users' authorization decision based on their previous behaviors and privacy preferences. However, previous studies have shown that the first approach is vulnerable to attacks (e.g., clickjacking) and the second approach i challenging to implement as it is difficult to infer the context. In this work, we explore the feasibility of a novel approach to enforce the context integrity---by inferring what task users want to do under the given context from their neural signals; then automatically authorizes access to a predefined set of sensitive resources that are necessary for that task. We conducted a comprehensive user study including 41 participants where we collected their neural signals when they were performing tasks that required access to sensitive resources. After preprocessing and features extraction, we trained machine learning classifier to infer what kind of tasks a user wants to perform. The experiment results show that the classifier was able to infer the high-level intents like take a photo with a weighted average precision of 88%.},
booktitle = {Proceedings of the 34th Annual Computer Security Applications Conference},
pages = {641–652},
numpages = {12},
keywords = {brain-computer interface, intent-driven access control, machine learning},
location = {San Juan, PR, USA},
series = {ACSAC '18}
}

@inproceedings{10.1145/3551349.3560419,
author = {Reis, Sofia and Abreu, Rui and d'Amorim, Marcelo and Fortunato, Daniel},
title = {Leveraging Practitioners’ Feedback to Improve a Security Linter},
year = {2023},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551349.3560419},
doi = {10.1145/3551349.3560419},
abstract = {Infrastructure-as-Code (IaC) is a technology that enables the management and distribution of infrastructure through code instead of manual processes. In 2020, Palo Alto Network’s Unit 42 announced the discovery of over 199K vulnerable IaC templates through their “Cloud Threat” Report. This report highlights the importance of tools to prevent vulnerabilities from reaching production. Unfortunately, we observed through a comprehensive study that a security linter for IaC scripts is not reliable yet—high false positive rates. Our approach to tackling this problem was to leverage community expertise to improve the precision of this tool. More precisely, we interviewed professional developers to collect their feedback on the root causes of imprecision of the state-of-the-art security linter for Puppet. From that feedback, we developed a linter adjusting 7 rules of an existing linter ruleset and adding 3 new rules. We conducted a new study with 131 practitioners, which helped us improve the tool’s precision significantly and achieve a final precision of . An important takeaway from this paper is that obtaining professional feedback is fundamental to improving the rules’ precision and extending the rulesets, which is critical for the usefulness and adoption of lightweight tools, such as IaC security linters.},
booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
articleno = {66},
numpages = {12},
keywords = {Infrastructure, Linter, Security},
location = {Rochester, MI, USA},
series = {ASE '22}
}

@inproceedings{10.1145/2541614.2541632,
author = {Hummer, Waldemar and Rosenberg, Florian and Oliveira, F\'{a}bio and Eilam, Tamar},
title = {Automated testing of chef automation scripts},
year = {2013},
isbn = {9781450325493},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2541614.2541632},
doi = {10.1145/2541614.2541632},
abstract = {Infrastructure as Code (IaC) is a novel approach for deployment of middleware and applications. IaC typically builds on automation scripts to put the system into a specific state. The series of steps in an automation should be idempotent to guarantee repeatability and convergence. These are key factors if automations are run periodically to override out-of-band changes and prevent drifts from the desired state. Rigorous testing must ensure that the system reliably converges from arbitrary initial/intermediate states to a desired state.We tackle this issue and demonstrate our tool for automated testing of automation scripts. Our tool is tailored to Opscode's Chef, one of the most popular IaC frameworks to date. Various testing parameters can be configured, and the Web-based user interface allows to inspect the system state changes during execution. Detailed test reports are created at the end of a test suite, which facilitate tracking down the root cause of failures and issues of non-idempotence.},
booktitle = {Proceedings Demo &amp; Poster Track of ACM/IFIP/USENIX International Middleware Conference},
articleno = {4},
numpages = {2},
location = {Beijing, China},
series = {MiddlewareDPT '13}
}

@inproceedings{10.1145/3701625.3701690,
author = {Marques, Denis and Rocha, Richard and Santos, Bruna and Pacheco, Felipe and Rodrigues, Cleyton Mario de Oliveira and Santos, Wylliams Barbosa},
title = {Industry Academia and Government Collaboration to Reduce Gaps in Software Engineering: Applications for Students and Professionals in Career Transition},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701690},
doi = {10.1145/3701625.3701690},
abstract = {The development of skills in Software Engineering disciplines often faces challenges when applied to real projects in the software industry. An effective practice to overcome these difficulties is collaboration between industry and academia. This collaboration aims to strengthen the exchange of knowledge between the two contexts, promoting the advancement of industry through Research and Development (R&amp;D), and in academia, applying knowledge in real contexts and even funding research. This study explores application development and the perceptions of undergraduate, master’s and doctoral students in Computer Engineering, as well as professionals in career transition (with Now and Low Code profiles), about projects with real clients and collaboration policies between industry and academia.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {657–664},
numpages = {8},
keywords = {Software Engineering, Career Transition, IAC, Software Quality},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3578245.3584932,
author = {Ardagna, Danilo and Di Nitto, Elisabetta and Blasi, Lorenzo and Lordan, Francesc},
title = {ICPE'23 Fast Continuum Workshop Chairs' Welcome},
year = {2023},
isbn = {9798400700729},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578245.3584932},
doi = {10.1145/3578245.3584932},
abstract = {It is our great pleasure to welcome you to the first FastContinuum Workshop held on April 16th 2023. The goal of the workshop is to foster discussion and collaboration among researchers from cloud/edge/fog computing and performance analysis communities, to share the relevant topics and results of the current approaches proposed by industry and academia. FastContinuum solicited full papers as well as demo and short papers including reports about research activities not mature enough for a full paper as well as new ideas and vision papers.The final program includes four full papers and three short ones. They cover some of the most interesting areas of computing continua, from FaaS development and acceleration to the management of heterogeneous datasets to the development of Infrastructure as Code and the automation of deployment through the computing continuum. DevSecOps is also brought to the attendees' attention as one of the crucial ingredients for proper management of the continuum.The workshop keynote, given by Samuel Kunev, investigates further the area of serverless computing properly positioning the multiple aspects and approaches developed in this area and highlighting the main challenges related to the performance of these approaches. The keynote is held in collaboration with the eleventh International Workshop on Load Testing and Benchmarking of Software Systems (LTB 2023).},
booktitle = {Companion of the 2023 ACM/SPEC International Conference on Performance Engineering},
pages = {155},
numpages = {1},
keywords = {cloud, computing continuum, edge, fog computing},
location = {Coimbra, Portugal},
series = {ICPE '23 Companion}
}

@inproceedings{10.1145/3494322.3494328,
author = {Mizutani, Iori and Ramanathan, Ganesh and Mayer, Simon},
title = {Integrating Multi-Disciplinary Offline and Online Engineering in Industrial Cyber-Physical Systems through DevOps},
year = {2022},
isbn = {9781450385664},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3494322.3494328},
doi = {10.1145/3494322.3494328},
abstract = {Industry 4.0 is transforming industrial automation systems into increasingly complex cyber-physical systems (CPS). In particular, there is a need to integrate systems across horizontal and vertical layers across industrial and disciplinary domains. The development of industrial CPS requires not only high-level configuration and control at the execution system level, but also offline and online engineering (OOE) work, including mechanical and electrical engineering of the devices, their installation, networking, and documentation. Using DevOps, a collection of modern software lifecycle management tactics, we propose to build an integrated platform to manage the OOE tasks. Continuous Integration/Continuous Delivery (CI/CD) pipelines and Infrastructure as Code, which are key aspects of DevOps, coordinate the building, testing, and deployment of software services. To bring the corresponding benefits of pure software systems to industrial CPS, we integrate engineering tasks using distributed version control and the W3C Web of Things. As a proof of concept, we implemented the concept for a mock system that includes the OOE tasks in a process automation scenario. The DevOps platform provides a structured transfer and exchange of engineering knowledge among stakeholders involved in industrial CPS.},
booktitle = {Proceedings of the 11th International Conference on the Internet of Things},
pages = {40–47},
numpages = {8},
keywords = {CI/CD, Cyber-Physical Systems, DevOps, Industrial Automation, Web of Things},
location = {St.Gallen, Switzerland},
series = {IoT '21}
}

@inproceedings{10.1145/3417990.3420194,
author = {Piedade, Bruno and Dias, Jo\~{a}o Pedro and Correia, Filipe F.},
title = {An empirical study on visual programming docker compose configurations},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3420194},
doi = {10.1145/3417990.3420194},
abstract = {Infrastructure-as-Code tools, such as Docker and Docker Compose, play a crucial role in the development and orchestration of cloud-native and at-scale software. However, as IaC relies mostly on the development of text-only specifications, these are prone to misconfigurations and hard to debug. Several works suggest the use of models as a way to abstract their complexity, and some point to the use of visual metaphors. Yet, few empirical studies exist in this domain. We propose a visual programming notation and environment for specifying Docker Compose configurations and proceed to empirically validate its merits when compared with the standard text-only specification. The goal of this work is to produce evidence of the impact that visual approaches may have on the development of IaC. We observe that the use of our solution reduced the development time and error proneness, primarily for configurations definition activities. We also observed a preference for the approach in terms of ease of use, a positive sentiment of its usefulness and intention to use.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {60},
numpages = {10},
keywords = {docker, docker compose, orchestration, visual programming},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/3465481.3469181,
author = {Lesueur, Fran\c{c}ois and No\^{u}s, Camille},
title = {MI-LXC: A Small-Scale Internet-Like Environment for Network Security Teaching},
year = {2021},
isbn = {9781450390514},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3465481.3469181},
doi = {10.1145/3465481.3469181},
abstract = {MI-LXC is a framework to simulate an internet-like infrastructure on top of LXC to practice cybersecurity on a realistic environment. MI-LXC follows the infrastructure-as-code paradigm to program the topology of the system and the provisioning of the different hosts. This construction is highly customizable, allowing to create hosts ranging from webservers to graphical desktops. Provisioning of similar subsets of features on different hosts is attained through a template mechanism. MI-LXC currently provides 28 hosts in 11 AS, allowing to simulate BGP routing, DNS, SMTP, HTTP, Certification authorities as well as attacks against these protocols. In this article, we present the MI-LXC framework, the generated infrastructure and some labs on top of it. MI-LXC is a free software (AGPL).},
booktitle = {Proceedings of the 16th International Conference on Availability, Reliability and Security},
articleno = {145},
numpages = {6},
keywords = {Cyberrange, Cybersecurity, Internet simulator, Training platform},
location = {Vienna, Austria},
series = {ARES '21}
}

@article{10.1145/3236386.3237207,
author = {Limoncelli, Thomas A.},
title = {GitOps: A Path to More Self-service IT: IaC + PR = GitOps},
year = {2018},
issue_date = {May-June 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {3},
issn = {1542-7730},
url = {https://doi.org/10.1145/3236386.3237207},
doi = {10.1145/3236386.3237207},
abstract = {GitOps lowers the bar for creating self-service versions of common IT processes, making it easier to meet the return in the ROI calculation. GitOps not only achieves this, but also encourages desired behaviors in IT systems: better testing, reduction of bus factor, reduced wait time, more infrastructure logic being handled programmatically with IaC, and directing time away from manual toil toward creating and maintaining automation.},
journal = {Queue},
month = jun,
pages = {13–26},
numpages = {14}
}

@inproceedings{10.1145/3463274.3463786,
author = {Zhou, Peng and Ali Khan, Arif Ali and Liang, Peng and Badshah, Sher},
title = {System and Software Processes in Practice: Insights from Chinese Industry},
year = {2021},
isbn = {9781450390538},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3463274.3463786},
doi = {10.1145/3463274.3463786},
abstract = {Software development processes play a key role in the software and system development life cycle. Processes are becoming complex and evolve rapidly due to the modern-day continuous software engineering (CSE) concepts, which are mainly based on continuous integration, continuous delivery, infrastructure-as-code, automation and more. The fast growing Chinese software development industry adopts various processes to achieve potential benefits offered in the international market. This study is conducted with the aim to investigate the trends of processes in practice in the Chinese industry. The survey questionnaire data is collected from 34 practitioners working in software development firms across the China and the results highlight that iterative and agile processes are extensively used in industrial setting. Furthermore, agile and traditional approaches are combined to develop the hybrid processes. Most of the participants are satisfied using the current development processes, however, they show interest to continuously improve the existing process models and methods. Finally, we noticed that majority of the software development organizations used the ISO 9001 standard for process assessment and improvement activities. The given results provide preliminary overview of processes deployed in the Chinese industry.},
booktitle = {Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering},
pages = {394–401},
numpages = {8},
keywords = {Chinese industry, Process Improvement Standards, Software processes, Survey},
location = {Trondheim, Norway},
series = {EASE '21}
}

@inproceedings{10.1145/3084226.3084264,
author = {Garousi, Vahid and Felderer, Michael and Kuhrmann, Marco and Herkilo\u{g}lu, Kadir},
title = {What industry wants from academia in software testing? Hearing practitioners' opinions},
year = {2017},
isbn = {9781450348041},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3084226.3084264},
doi = {10.1145/3084226.3084264},
abstract = {The level of industry-academia collaboration (IAC) in software engineering in general and in software testing in particular is quite low. Many researchers and practitioners are not collaborating with the "other side" to solve industrial problems. To shed light on the above issue and to characterize precisely what industry wants from academia in software testing, we solicited practitioners' opinions on their challenges in different testing activities and also the particularly relevant topics that they want the research community to work on. This short paper aims to draw the community's attention to the important issue of strengthening IAC with the hope of more IAC in software testing in the areas of most importance to the industry.},
booktitle = {Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering},
pages = {65–69},
numpages = {5},
keywords = {Software testing, industrial challenges, industrial needs, industry-academia collaborations, opinion survey},
location = {Karlskrona, Sweden},
series = {EASE '17}
}

@inproceedings{10.5555/2820518.2820527,
author = {Jiang, Yujuan and Adams, Bram},
title = {Co-evolution of infrastructure and source code: an empirical study},
year = {2015},
isbn = {9780769555942},
publisher = {IEEE Press},
abstract = {Infrastructure-as-code automates the process of configuring and setting up the environment (e.g., servers, VMs and databases) in which a software system will be tested and/or deployed, through textual specification files in a language like Puppet or Chef. Since the environment is instantiated automatically by the infrastructure languages' tools, no manual intervention is necessary apart from maintaining the infrastructure specification files. The amount of work involved with such maintenance, as well as the size and complexity of infrastructure specification files, have not yet been studied empirically. Through an empirical study of the version control system of 265 OpenStack projects, we find that infrastructure files are large and churn frequently, which could indicate a potential of introducing bugs. Furthermore, we found that the infrastructure code files are coupled tightly with the other files in a project, especially test files, which implies that testers often need to change infrastructure specifications when making changes to the test framework and tests.},
booktitle = {Proceedings of the 12th Working Conference on Mining Software Repositories},
pages = {45–55},
numpages = {11},
location = {Florence, Italy},
series = {MSR '15}
}

@inproceedings{10.1145/3616131.3616136,
author = {Rall, Dennis and Bauer, Bernhard and Fraunholz, Thomas},
title = {Towards Democratizing AI: A Comparative Analysis of AI as a Service Platforms and the Open Space for Machine Learning Approach},
year = {2023},
isbn = {9798400707339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616131.3616136},
doi = {10.1145/3616131.3616136},
abstract = {Recent AI research has significantly reduced the barriers to apply AI, but the process of setting up the necessary tools and frameworks can still be a challenge. While AI-as-a-Service platforms have emerged to simplify the training and deployment of AI models, they still fall short of achieving true democratization of AI. In this paper, we aim to address this gap by comparing several popular AI-as-a-Service platforms and identifying the key requirements for a platform that can achieve true democratization of AI. Our analysis highlights the need for self-hosting options, high scalability, and openness. To address these requirements, we propose our approach: the "Open Space for Machine Learning" platform. Our platform is built on cutting-edge technologies such as Kubernetes, Kubeflow Pipelines, and Ludwig, enabling us to overcome the challenges of democratizing AI. We argue that our approach is more comprehensive and effective in meeting the requirements of democratizing AI than existing AI-as-a-Service platforms.},
booktitle = {Proceedings of the 2023 7th International Conference on Cloud and Big Data Computing},
pages = {34–39},
numpages = {6},
keywords = {AI-as-a-Service, Artificial Intelligence, Cloud Computing, Platform},
location = {Manchester, United Kingdom},
series = {ICCBDC '23}
}

@inproceedings{10.1145/3275219.3275220,
author = {Yin, Kang and Zhou, Jiahong and Chen, Wei and Wu, Guoquan and Zhu, Jiaxin and Wei, Jun},
title = {D-Tagger: A Tag Recommendation Approach for Docker Repositories},
year = {2018},
isbn = {9781450365901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3275219.3275220},
doi = {10.1145/3275219.3275220},
abstract = {Docker repositories usually contain Docker images and Dockerfiles, where Docker images are a kind of off-the-shelf artifact and Dockerfiles specify how to automatically build Docker images following the notion of Infrastructure-as-Code. Given a huge number of Docker repositories, tag recommendation is essential to ensure that relevant ones can be easily retrieved, because tagging is practical in describing, bookmarking, navigating and searching software objects. However, in Docker Hub, tags are not well supported to semantically describing the repositories, and manually tagging is still an exhausting and time-consuming task.Dockerfile specifies Docker repository in a rigorous and compact way. Thus, based on Dockerfile analysis, this paper proposes D-Tagger, a tag recommendation approach to addressing the problem of multi-labeling Docker repositories. When taking Dockerfile as specific description, D-Tagger models a repository with its labeled tags and the terms extracted from its Dockerfile, and employs Labeled Latent Dirichlet Allocation algorithm to make tag recommendation. When regarding Dockerfile as configuration code, D-Tagger constructs a feature model based on key instructions that identify the Dockerfile, and then recommends tags with a similarity-based ranking method. D-Tagger finally makes a combination by considering both of the two perspectives. We evaluate D-Tagger on over 100,000 repositories of Docker Hub (accessed until Aug. 15, 2017). The experimental results show that the accuracy of D-Tagger, in terms of Recall@5 and Recall@10, achieve 0.675 and 0.712 respectively. In addition, D-Tagger outperforms the state-of-the-art approach when tagging repositories without description documents.},
booktitle = {Proceedings of the 10th Asia-Pacific Symposium on Internetware},
articleno = {3},
numpages = {10},
keywords = {Docker, Docker repository, Dockerfile, tag recommendation},
location = {Beijing, China},
series = {Internetware '18}
}

@inproceedings{10.1145/3236024.3275528,
author = {Debroy, Vidroha and Miller, Senecca and Brimble, Lance},
title = {Building lean continuous integration and delivery pipelines by applying DevOps principles: a case study at Varidesk},
year = {2018},
isbn = {9781450355735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3236024.3275528},
doi = {10.1145/3236024.3275528},
abstract = {Continuous Integration (CI) and Continuous Delivery (CD) are widely considered to be best practices in software development. Studies have shown however, that adopting these practices can be challenging and there are many barriers that engineers may face, such as – overly long build times, lack of support for desired workflows, issues with configuration, etc. At Varidesk, we recently began shifting our primary web application (from a monolithic) to a micro-services-based architecture and also adapted our software development practices to aim for more effective CI/CD. In doing so, we also ran into some of the same afore-mentioned barriers. In this paper we focus on two specific challenges that we faced – long wait times for builds/releases to be queued and completed, and the lack of support for tooling, especially from a cross-cloud perspective. We then present the solutions that we came up with, which involved re-thinking DevOps as it applied to us, and re-building our own CI/CD pipelines based on DevOps-supporting approaches such as containerization, infrastructure-as-code, and orchestration. Our re-designed pipelines have led us to see speed increases, in terms of total build/release time, in the range of 330x-1110x and have enabled us to seamlessly move from a single-cloud to a multi- cloud environment, with no architectural changes to any apps.},
booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {851–856},
numpages = {6},
keywords = {Continuous Delivery, Continuous Deployment, Continuous Integration, DevOps, Software Build, Software Release},
location = {Lake Buena Vista, FL, USA},
series = {ESEC/FSE 2018}
}

@inproceedings{10.1145/3721889.3721924,
author = {Kapetanidou, Ioanna Angeliki and Nizamis, Alexandros and Votis, Konstantinos},
title = {An evaluation of commonly used Kubernetes security scanning tools},
year = {2025},
isbn = {9798400715600},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721889.3721924},
doi = {10.1145/3721889.3721924},
abstract = {With the advent of the edge-cloud continuum, Kubernetes (K8s) has emerged as the prominent solution for service orchestration. In this context, ensuring deployment security is essential. To identify vulnerabilities and misconfigurations in a timely and efficient manner, security scanning tools are employed. In this work, we evaluate six widely used security tools for workload and static code analysis. We consider several factors, including scan time, the number of detected threats, and resource usage. This evaluation seeks not only to demonstrate the performance trade-offs of these tools but also to contribute additional insights into their practical capabilities.},
booktitle = {Proceedings of the 2nd International Workshop on MetaOS for the Cloud-Edge-IoT Continuum},
pages = {20–25},
numpages = {6},
keywords = {Edge-cloud Continuum, Kubernetes, Risk Analysis, Security},
location = {Rotterdam, Netherlands},
series = {MECC '25}
}

@article{10.1145/3567837,
author = {Akdur, Deniz},
title = {Analysis of Software Engineering Skills Gap in the Industry},
year = {2022},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {1},
url = {https://doi.org/10.1145/3567837},
doi = {10.1145/3567837},
abstract = {Many practitioners might struggle with becoming productive in different software engineering (SE) roles due to misalignment of the skills learnt during the university time with what is expected in the industry. Companies spend significant resources to train the personnel, whose academic backgrounds are not only based on “computing disciplines”. Hiring properly trained practitioners allows employers to spend less time while incorporating them more efficiently into the workforce; for employees, knowing the most important skillset is helpful to increase their chance of employability. On the other hand, for academia, understanding the necessary skillset is critical to make curriculum updates. To achieve these objectives, we conducted a survey, which was responded to by 628 software practitioners, who completed their undergraduate degree in Turkey, working in 13 countries. This paper sheds light on the most important (hard and soft) skills in the industry by presenting various cross-factor analyses as well as their coverage in the academic curriculum (mostly in Turkish universities). The results showed that the most important skills are related to various factors such as profiles of the practitioners (e.g., SE role(s), work experience) and the characteristics of the product developed by the practitioner. The findings revealed that both academia and industry should invest in skills improvement: academia can make necessary educational updates according to industrial needs; whereas industry can provide practical experiences to students. By creating the awareness of the expected skillset, both practitioners and academics will benefit from the results, which help close the gaps that can and should be achieved through more Industry Academia Collaborations (IACs).},
journal = {ACM Trans. Comput. Educ.},
month = dec,
articleno = {16},
numpages = {28},
keywords = {Hard skills, soft skills, knowledge area, software engineering education, industry-academia collaboration, software industry, practitioner survey}
}

@article{10.1145/3505228,
author = {Romero, Esteban Elias and Camacho, Carlos David and Montenegro, Carlos Enrique and Acosta, \'{O}scar Esneider and Crespo, Rub\'{e}n Gonz\'{a}lez and Gaona, Elvis Eduardo and Mart\'{\i}nez, Marcelo Herrera},
title = {Integration of DevOps Practices on a Noise Monitor System with CircleCI and Terraform},
year = {2022},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {2158-656X},
url = {https://doi.org/10.1145/3505228},
doi = {10.1145/3505228},
abstract = {Lowering pollution levels is one of the main principles of Sustainable Development goals dictated by the United Nations. Consequently, developments on noise monitoring contribute in great manner to this purpose, since they give the opportunity to governments and institutions to maintain track on the matter. While developing a software product for this purpose, with the growth in terms of functional and non-functional requirements, elements such as infrastructure, source code, and others also scale up. Consequently if there are not good practices to face the new challenges of the software product, then it could become more complex to refactor, maintain, and scale, causing a decrease on delivery rate and the quality of the product. DevOps is an emerging concept but still hazy, which involves a set of practices that helps organizations to speed up delivery time, improve software quality and collaboration between teams. The aim of this article is to document the implementation of some DevOps practices such as IaC, continuous integration and deployment, code quality control, and collaboration on a noise monitor system to increase the product quality and automation of deployment. The final result is a set of automated pipelines that represents the entire integration and deployment cycle of the software integrated with platforms to improve quality and maintainability of the software components.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = aug,
articleno = {36},
numpages = {24},
keywords = {DeVOps, serverless, CI/CD, sound, classification}
}

@inproceedings{10.1145/3708035.3736106,
author = {Reddy, Salil and Davies, Ronald and Vallabhajosyula, Manikya Swathi and Ramnath, Rajiv},
title = {Building a Lab-scale Cyberinfrastructure for Fun and Profit},
year = {2025},
isbn = {9798400713989},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708035.3736106},
doi = {10.1145/3708035.3736106},
abstract = {Cyberinfrastructure (CI) platforms are pivotal in meeting the growing demand for High Performance Computing (HPC) necessitated by the advent of AI and Data Science. The CETI-CI, developed by the Collaborative for Enterprise Transformation and Innovation (CETI) Lab at The Ohio State University, addresses this need by offering a scalable, mixed-use CI platform tailored for research as well as training. It integrates traditional HPC clusters managed by SLURM and Kubernetes-based orchestration for containerized workloads, supporting a broad user base of students and interdisciplinary researchers. Having been incorporated into course curriculum, the CETI-CI development and usage milestones are discussed as successfully completed Capstone research projects.},
booktitle = {Practice and Experience in Advanced Research Computing 2025: The Power of Collaboration},
articleno = {84},
numpages = {5},
keywords = {Cyberinfrastructure (CI), High Performance Computing (HPC), Kubernetes, SLURM, Mixed-use clusters, Project-based Learning, CI for Education, Research Artifact Hosting},
location = {
},
series = {PEARC '25}
}

@inproceedings{10.1145/2983990.2984000,
author = {Hanappi, Oliver and Hummer, Waldemar and Dustdar, Schahram},
title = {Asserting reliable convergence for configuration management scripts},
year = {2016},
isbn = {9781450344449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2983990.2984000},
doi = {10.1145/2983990.2984000},
abstract = {The rise of elastically scaling applications that frequently deploy new machines has led to the adoption of DevOps practices across the cloud engineering stack. So-called configuration management tools utilize scripts that are based on declarative resource descriptions and make the system converge to the desired state. It is crucial for convergent configurations to be able to gracefully handle transient faults, e.g., network outages when downloading and installing software packages. In this paper we introduce a conceptual framework for asserting reliable convergence in configuration management. Based on a formal definition of configuration scripts and their resources, we utilize state transition graphs to test whether a script makes the system converge to the desired state under different conditions. In our generalized model, configuration actions are partially ordered, often resulting in prohibitively many possible execution orders. To reduce this problem space, we define and analyze a property called preservation, and we show that if preservation holds for all pairs of resources, then convergence holds for the entire configuration. Our implementation builds on Puppet, but the approach is equally applicable to other frameworks like Chef, Ansible, etc. We perform a comprehensive evaluation based on real world Puppet scripts and show the effectiveness of the approach. Our tool is able to detect all idempotence and convergence related issues in a set of existing Puppet scripts with known issues as well as some hitherto undiscovered bugs in a large random sample of scripts.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
pages = {328–343},
numpages = {16},
keywords = {Configuration Management, Convergence, Declarative Language, DevOps, Idempotence, Puppet, System Configuration Scripts, Testing},
location = {Amsterdam, Netherlands},
series = {OOPSLA 2016}
}

@inproceedings{10.1109/MSR.2017.67,
author = {Cito, J\"{u}rgen and Schermann, Gerald and Wittern, John Erik and Leitner, Philipp and Zumberi, Sali and Gall, Harald C.},
title = {An empirical analysis of the docker container ecosystem on GitHub},
year = {2017},
isbn = {9781538615447},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MSR.2017.67},
doi = {10.1109/MSR.2017.67},
abstract = {Docker allows packaging an application with its dependencies into a standardized, self-contained unit (a so-called container), which can be used for software development and to run the application on any system. Dockerfiles are declarative definitions of an environment that aim to enable reproducible builds of the container. They can often be found in source code repositories and enable the hosted software to come to life in its execution environment. We conduct an exploratory empirical study with the goal of characterizing the Docker ecosystem, prevalent quality issues, and the evolution of Dockerfiles. We base our study on a data set of over 70000 Dockerfiles, and contrast this general population with samplings that contain the Top-100 and Top-1000 most popular Docker-using projects. We find that most quality issues (28.6%) arise from missing version pinning (i.e., specifying a concrete version for dependencies). Further, we were not able to build 34% of Dockerfiles from a representative sample of 560 projects. Integrating quality checks, e.g., to issue version pinning warnings, into the container build process could result into more reproducible builds. The most popular projects change more often than the rest of the Docker population, with 5.81 revisions per year and 5 lines of code changed on average. Most changes deal with dependencies, that are currently stored in a rather unstructured manner. We propose to introduce an abstraction that, for instance, could deal with the intricacies of different package managers and could improve migration to more light-weight images.},
booktitle = {Proceedings of the 14th International Conference on Mining Software Repositories},
pages = {323–333},
numpages = {11},
keywords = {GitHub, docker, empirical software engineering},
location = {Buenos Aires, Argentina},
series = {MSR '17}
}

@inproceedings{10.1145/2771783.2771800,
author = {Hay, Roee and Tripp, Omer and Pistoia, Marco},
title = {Dynamic detection of inter-application communication vulnerabilities in Android},
year = {2015},
isbn = {9781450336208},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2771783.2771800},
doi = {10.1145/2771783.2771800},
abstract = {A main aspect of the Android platform is Inter-Application Communication (IAC), which enables reuse of functionality across apps and app components via message passing. While a powerful feature, IAC also constitutes a serious attack surface. A malicious app can embed a payload into an IAC message, thereby driving the recipient app into a potentially vulnerable behavior if the message is processed without its fields first being sanitized or validated. We present what to our knowledge is the first comprehensive testing algorithm for Android IAC vulnerabilities. Toward this end, we first describe a catalog, stemming from our field experience, of 8 concrete vulnerability types that can potentially arise due to unsafe handling of incoming IAC messages. We then explain the main challenges that automated discovery of Android IAC vulnerabilities entails, including in particular path coverage and custom data fields, and present simple yet surprisingly effective solutions to these challenges. We have realized our testing approach as the IntentDroid system, which is available as a commercial cloud service. IntentDroid utilizes lightweight platform-level instrumentation, implemented via debug breakpoints (to run atop any Android device without any setup or customization), to recover IAC-relevant app-level behaviors. Evaluation of IntentDroid over a set of 80 top-popular apps has revealed a total 150 IAC vulnerabilities — some already fixed by the developers following our report — with a recall rate of 92% w.r.t. a ground truth established via manual auditing by a security expert.},
booktitle = {Proceedings of the 2015 International Symposium on Software Testing and Analysis},
pages = {118–128},
numpages = {11},
keywords = {Android, inter-application communication, mobile, security},
location = {Baltimore, MD, USA},
series = {ISSTA 2015}
}

@article{10.1145/3579639,
author = {Rahman, Akond and Shamim, Shazibul Islam and Bose, Dibyendu Brinto and Pandita, Rahul},
title = {Security Misconfigurations in Open Source Kubernetes Manifests: An Empirical Study},
year = {2023},
issue_date = {July 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3579639},
doi = {10.1145/3579639},
abstract = {Context: Kubernetes has emerged as the de-facto tool for automated container orchestration. Business and government organizations are increasingly adopting Kubernetes for automated software deployments. Kubernetes is being used to provision applications in a wide range of domains, such as time series forecasting, edge computing, and high-performance computing. Due to such a pervasive presence, Kubernetes-related security misconfigurations can cause large-scale security breaches. Thus, a systematic analysis of security misconfigurations in Kubernetes manifests, i.e., configuration files used for Kubernetes, can help practitioners secure their Kubernetes clusters.Objective: The goal of this paper is to help practitioners secure their Kubernetes clusters by identifying security misconfigurations that occur in Kubernetes manifests.Methodology: We conduct an empirical study with 2,039 Kubernetes manifests mined from 92 open-source software repositories to systematically characterize security misconfigurations in Kubernetes manifests. We also construct a static analysis tool called Security Linter for Kubernetes Manifests (SLI-KUBE) to quantify the frequency of the identified security misconfigurations.Results: In all, we identify 11 categories of security misconfigurations, such as absent resource limit, absent securityContext, and activation of hostIPC. Specifically, we identify 1,051 security misconfigurations in 2,039 manifests. We also observe the identified security misconfigurations affect entities that perform mesh-related load balancing, as well as provision pods and stateful applications. Furthermore, practitioners agreed to fix 60% of 10 misconfigurations reported by us.Conclusion: Our empirical study shows Kubernetes manifests to include security misconfigurations, which necessitates security-focused code reviews and application of static analysis when Kubernetes manifests are developed.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {99},
numpages = {36},
keywords = {Configuration, container orchestration, devops, devsecops, empirical study, Kubernetes, misconfiguration, security}
}

@inproceedings{10.1145/3377811.3380384,
author = {Sotiropoulos, Thodoris and Mitropoulos, Dimitris and Spinellis, Diomidis},
title = {Practical fault detection in puppet programs},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380384},
doi = {10.1145/3377811.3380384},
abstract = {Puppet is a popular computer system configuration management tool. By providing abstractions that model system resources it allows administrators to set up computer systems in a reliable, predictable, and documented fashion. Its use suffers from two potential pitfalls. First, if ordering constraints are not correctly specified whenever a Puppet resource depends on another, the non-deterministic application of resources can lead to race conditions and consequent failures. Second, if a service is not tied to its resources (through the notification construct), the system may operate in a stale state whenever a resource gets modified. Such faults can degrade a computing infrastructure's availability and functionality.We have developed an approach that identifies these issues through the analysis of a Puppet program and its system call trace. Specifically, a formal model for traces allows us to capture the interactions of Puppet resources with the file system. By analyzing these interactions we identify (1) resources that are related to each other (e.g., operate on the same file), and (2) resources that should act as notifiers so that changes are correctly propagated. We then check the relationships from the trace's analysis against the program's dependency graph: a representation containing all the ordering constraints and notifications declared in the program. If a mismatch is detected, our system reports a potential fault.We have evaluated our method on a large set of popular Puppet modules, and discovered 92 previously unknown issues in 33 modules. Performance benchmarking shows that our approach can analyze in seconds real-world configurations with a magnitude measured in thousands of lines and millions of system calls.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {26–37},
numpages = {12},
keywords = {notifiers, ordering relationships, program analysis, puppet, system calls},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/3725789.3725794,
author = {McIntosh-Smith, Simon and Alam, Sadaf and Woods, Christopher},
title = {Isambard-AI: a leadership-class supercomputer optimised specifically for Artificial Intelligence},
year = {2025},
isbn = {9798400713286},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3725789.3725794},
doi = {10.1145/3725789.3725794},
abstract = {Isambard-AI is a new, leadership-class supercomputer, designed to support AI-related research. Based on the HPE Cray EX4000 system, and housed in a new, energy efficient Modular Data Centre in Bristol, UK, Isambard-AI employs 5,448 NVIDIA Grace-Hopper GPUs to deliver over 21 ExaFLOP/s of 8-bit floating point performance for LLM training, and over 250 PetaFLOP/s of 64-bit performance, for under 5MW. Isambard-AI integrates two, all-flash storage systems: a 20 PiByte Cray ClusterStor and a 3.5 PiByte VAST solution. Combined these give Isambard-AI flexibility for training, inference and secure data accesses and sharing. But it is the software stack where Isambard-AI will be most different from traditional HPC systems. Isambard-AI is designed to support users who may have been using GPUs in the cloud, and so access will more typically be via Jupyter notebooks, MLOps, or other web-based, interactive interfaces, rather than the approach used on traditional supercomputers of ssh'ing into a system before submitting jobs to a batch scheduler. Its stack is designed to be quickly and regularly upgraded to keep pace with the rapid evolution of AI software, with full support for containers. Phase 1 of Isambard-AI is due online in May/June 2024, with the full system expected in production by the end of the year.},
booktitle = {Proceedings of the Cray User Group},
pages = {44–54},
numpages = {11},
keywords = {AI safety and trustworthiness, Artificial Intelligence (AI), GPU accelerated computing, Large Language Models (LLMs), Modular Data Centre, Supercomputing},
location = {
},
series = {CUG '24}
}

@inproceedings{10.1145/3563766.3564087,
author = {Fu, Silvery and Zhang, Hong and Ratnasamy, Sylvia and Stoica, Ion},
title = {The internet of things in a laptop: rapid prototyping for IoT applications with digibox},
year = {2022},
isbn = {9781450398992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563766.3564087},
doi = {10.1145/3563766.3564087},
abstract = {Digibox is a prototyping environment for IoT applications. It enables a novel scene-centric prototyping where developers can program an ensemble of simulated devices to capture not only their individual but also their coordinated behaviors, making it possible to test, debug, and evaluate the behaviors of an IoT application. Using Digibox, developers can download and reuse existing scenes, customize, and repurpose them towards developing new applications; or replicate others' experiment results from scientific research. Digibox's Kubernetes-based runtime further allows developers to easily scale the prototyping environment from a single laptop to a cluster running simulated devices and scenes at a scale appropriate to the application.},
booktitle = {Proceedings of the 21st ACM Workshop on Hot Topics in Networks},
pages = {24–30},
numpages = {7},
keywords = {IoT, design principles, framework, simulation},
location = {Austin, Texas},
series = {HotNets '22}
}

@inproceedings{10.1145/3626641.3626673,
author = {Putri, Rosyida Salicha Rusdarto and Bhawiyuga, Adhitya and Akbar, Sabriansyah Rizqika and Shaffan, Nur Hazbiy and Amron, Kasyful and Basuki, Achmad},
title = {Implementation of Fault-Tolerance Mechanism in Quorum-Based Blockchain Provisioning in Cloud Infrastructure Using Replication and Monitoring Protocols},
year = {2023},
isbn = {9798400708503},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626641.3626673},
doi = {10.1145/3626641.3626673},
abstract = {Decentralized and distributed blockchain technology has superior potential. Quorum, as a permissioned blockchain platform, provides enhanced privacy and performance that are suitable for enterprise needs. Cloud, as the infrastructure for Quorum-based blockchain, is vulnerable to failures. Failures originating from errors need to be tolerated through improved reliability and fault-tolerance procedures. Fault-tolerance and reliability are still challenging to implement in cloud infrastructure for Quorum-based blockchain networks. This research focuses on implementing fault-tolerance mechanisms in the provisioning of Quorum-based blockchain in a cloud environment. The research explores the use of hybrid fault tolerance by adopting a combination of reactive protocol, namely replication, and proactive protocol, namely monitoring. The replication protocol creates data redundancy with reactive treatment performed in case of failures, ensuring data availability even in failure conditions. The monitoring protocol provides real-time monitoring of the blockchain network's condition and performance, enabling proactive detection and mitigation of system failures. Overall, this research utilizes automation in its operational processes. It employs tools such as Amazon Web Services, Quorum, Docker, Terraform, Ansible, and Truffle. The research design and implementation are divided into cloud infrastructure, blockchain network, and interface. The research testing results demonstrate that the system infrastructure is capable of achieving fault tolerance using replication and monitoring protocols, as well as making transactions within the blockchain network.},
booktitle = {Proceedings of the 8th International Conference on Sustainable Information Engineering and Technology},
pages = {311–322},
numpages = {12},
keywords = {Blockchain, Cloud infrastructure, Fault-tolerance, Monitoring, Quorum, Replication},
location = {Badung, Bali, Indonesia},
series = {SIET '23}
}

@inproceedings{10.1145/3102254.3102266,
author = {Celestini, Alessandro and Guarino, Stefano},
title = {Design, implementation and test of a flexible tor-oriented web mining toolkit},
year = {2017},
isbn = {9781450352253},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3102254.3102266},
doi = {10.1145/3102254.3102266},
abstract = {Searching and retrieving information from the Web is a primary activity needed to monitor the development and usage of Web resources. Possible benefits include improving user experience (e.g. by optimizing query results) and enforcing data/user security (e.g. by identifying harmful websites). Motivated by the lack of ready-to-use solutions, in this paper we present a flexible and accessible toolkit for structure and content mining, able to crawl, download, extract and index resources from the Web. While being easily configurable to work in the "surface" Web, our suite is specifically tailored to explore the Tor dark Web, i.e. the ensemble of Web servers composing the world's most famous darknet. Notably, the toolkit is not just a Web scraper, but it includes two mining modules, respectively able to prepare content to be fed to an (external) semantic engine, and to reconstruct the graph structure of the explored portion of the Web. Other than discussing in detail the design, features and performance of our toolkit, we report the findings of a preliminary run over Tor, that clarify the potential of our solution.},
booktitle = {Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics},
articleno = {19},
numpages = {10},
keywords = {dark web, tor web graph},
location = {Amantea, Italy},
series = {WIMS '17}
}

@inproceedings{10.1145/3643991.3644921,
author = {Ksontini, Emna and Abid, Aycha and Khalsi, Rania and Kessentini, Marouane},
title = {DRMiner: A Tool For Identifying And Analyzing Refactorings In Dockerfile},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644921},
doi = {10.1145/3643991.3644921},
abstract = {Software containerization using Docker has recently become the de facto standard for delivering reusable software artifacts. Integral to Docker's functionality are Dockerfiles, which serve as scripts that define the layers and components to be incorporated within a container. Although these files serve as the bedrock of container creation, their maintenance presents intricate challenges. Specifically, the task of Dockerfile refactoring is compounded by its inherent complexity. Although the importance of refactoring inside Docker ecosystems is apparent, detecting it remains challenging. Developers usually avoid documenting their refactoring efforts, often combining them with other changes.While previous research works have delved into Docker refactoring, the predominant focus has been on empirical foundations, resulting in a constrained and narrow viewpoint. Despite all endeavors, there remains a clear gap for an exhaustive tool that can adeptly navigate the complexities of Dockerfile refactoring detection. To fill this gap, we introduce DRMiner, the first tool for identifying and analyzing refactoring in Dockerfile. Our solution, designed, implemented, and evaluated in terms of correctness and generalization, relies on a novel E-AST(Enhanced Abstract Syntax Tree) based component-matching algorithm and a set of detection rules to determine refactoring candidates. This work will serve as a fundamental building block for the refactoring detection in the realm of Docker.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {584–594},
numpages = {11},
keywords = {docker, dockerfiles, AST, refactoring, commit, git},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3696410.3714798,
author = {Schwartz, Yuval and Ben-Shimol, Lavi and Mimran, Dudu and Elovici, Yuval and Shabtai, Asaf},
title = {LLMCloudHunter: Harnessing LLMs for Automated Extraction of Detection Rules from Cloud-Based CTI},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714798},
doi = {10.1145/3696410.3714798},
abstract = {As the number and sophistication of cyber attacks have increased, threat hunting has become a critical aspect of active security, enabling proactive detection and mitigation of threats before they cause significant harm. Open-source cyber threat intelligence (OSCTI) is a valuable resource for threat hunters, however, it often comes in unstructured formats that require further manual analysis. Previous studies aimed at automating OSCTI analysis are limited since (1) they failed to provide actionable outputs, (2) they did not take advantage of images present in OSCTI sources, and (3) they focused on on-premises environments, overlooking the growing importance of cloud environments. To address these gaps, we propose LLMCloudHunter, a novel framework that leverages large language models (LLMs) to automatically generate generic-signature detection rule candidates from textual and visual OSCTI data. We evaluated the quality of the rules generated by the proposed framework using 20 annotated real-world cloud threat reports. The results show that our framework achieved a precision of 83% and recall of 99% for the task of accurately extracting API calls made by the threat actor and a precision of 99% with a recall of 97% for IoCs. Additionally, 99.18% of the generated detection rule candidates were successfully compiled and converted into Splunk queries.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {1922–1941},
numpages = {20},
keywords = {cloud, cyber threat intelligence (cti), llm, sigma rules},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3749220,
author = {Bufalino, Jacopo and Martin-Navarro, Jose Luis and Di Francesco, Mario and Aura, Tuomas},
title = {Inside Job: Defending Kubernetes Clusters Against Network Misconfigurations},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {CoNEXT3},
url = {https://doi.org/10.1145/3749220},
doi = {10.1145/3749220},
abstract = {Kubernetes has emerged as the de facto standard for container orchestration. Unfortunately, its increasing popularity has also made it an attractive target for malicious actors. Despite extensive research on securing Kubernetes, little attention has been paid to the impact of network configuration on the security of application deployments. This paper addresses this gap by conducting a comprehensive analysis of network misconfigurations in a Kubernetes cluster with specific reference to lateral movement. Accordingly, we carried out an extensive evaluation of 287 open-source applications belonging to six different organizations, ranging from IT companies and public entities to non-profits. As a result, we identified 634 misconfigurations, well beyond what could be found by solutions in the state of the art. We responsibly disclosed our findings to the concerned organizations and engaged in a discussion to assess their severity. As of now, misconfigurations affecting more than thirty applications have been fixed with the mitigations we proposed.},
journal = {Proc. ACM Netw.},
month = sep,
articleno = {20},
numpages = {25},
keywords = {deployments, helm, kubernetes, lateral movement, misconfigurations}
}

@inproceedings{10.1145/3007788.3007795,
author = {Atamli-Reineh, Ahmad and Borgaonkar, Ravishankar and Balisane, Ranjbar A. and Petracca, Giuseppe and Martin, Andrew},
title = {Analysis of Trusted Execution Environment usage in Samsung KNOX},
year = {2016},
isbn = {9781450346702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3007788.3007795},
doi = {10.1145/3007788.3007795},
abstract = {Mobile systems have become widely adopted by users to perform sensitive operations ranging from on-line payments for personal use to remote access to enterprise assets. Thus, attacks on mobile devices can cause significant loss to user's personal data as well as to valuable enterprise assets. In order to mitigate risks arising from attacks, various approaches have been proposed including the use of Trusted Execution Environment (TEE) to isolate and protect the execution of sensitive code from the rest of the system, e.g. applications and other software.However, users remain at risk of exploits via several types of software vulnerabilities - indicating that enterprises have failed to deliver the required protection, despite the use of existing isolation technologies. In this paper, we investigate Samsung KNOX and its usage of TEE as being the current technology providing secure containers. First, we study how KNOX uses TEE and perform analysis on its design consideration from a system vulnerabilities perspective. Second, we analyse and discuss recent attacks on KNOX and how those attacks exploit system vulnerabilities. Finally, we present new shortcomings emerging from our analysis of KNOX architecture. Our research exhibits that system vulnerabilities are the underlying cause of many attacks on systems and it reveals how they affect fundamental design security principles when the full potential of TEE is not exploited.},
booktitle = {Proceedings of the 1st Workshop on System Software for Trusted Execution},
articleno = {7},
numpages = {6},
keywords = {Mobile System Security, Samsung KNOX, Software Vulnerabilities, TEE},
location = {Trento, Italy},
series = {SysTEX '16}
}

@inproceedings{10.1145/3377812.3382169,
author = {Wu, Yiwen},
title = {Exploring the relationship between dockerfile quality and project characteristics},
year = {2020},
isbn = {9781450371223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377812.3382169},
doi = {10.1145/3377812.3382169},
abstract = {Dockerfile plays an important role in the Docker-based software development process, but many Dockerfile codes are infected with quality issues in practice. Previous empirical studies showed the existence of association between code quality and project characteristics. However, the relationship between Dockerfile quality and project characteristics has never been explored. In this paper, we seek to empirically study this relation through a large dataset of 6,334 projects. Using linear regression analysis, when controlled for various variables, we statistically identify and quantify the relationship between Dockerfile quality and project characteristics.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings},
pages = {128–130},
numpages = {3},
keywords = {dockerfile, dockerfile quality, project characteristics},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@inproceedings{10.1145/3084226.3084279,
author = {Garousi, Vahid and Felderer, Michael and Fernandes, Jo\~{a}o M. and Pfahl, Dietmar and M\"{a}ntyl\"{a}, Mika V.},
title = {Industry-academia collaborations in software engineering: An empirical analysis of challenges, patterns and anti-patterns in research projects},
year = {2017},
isbn = {9781450348041},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3084226.3084279},
doi = {10.1145/3084226.3084279},
abstract = {Research collaboration between industry and academia supports improvement and innovation in industry and helps to ensure industrial relevance in academic research. However, many researchers and practitioners believe that the level of joint industry-academia collaboration (IAC) in software engineering (SE) research is still relatively low, compared to the amount of activity in each of the two communities. The goal of the empirical study reported in this paper is to exploratory characterize the state of IAC with respect to a set of challenges, patterns and anti-patterns identified by a recent Systematic Literature Review study. To address the above goal, we gathered the opinions of researchers and practitioners w.r.t. their experiences in IAC projects. Our dataset includes 47 opinion data points related to a large set of projects conducted in 10 different countries. We aim to contribute to the body of evidence in the area of IAC, for the benefit of researchers and practitioners in conducting future successful IAC projects in SE. As an output, the study presents a set of empirical findings and evidence-based recommendations to increase the success of IAC projects.},
booktitle = {Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering},
pages = {224–229},
numpages = {6},
keywords = {anti-patterns, challenges, empirical study, industry-academia collaborations, patterns, research, software engineering, success factors},
location = {Karlskrona, Sweden},
series = {EASE '17}
}

@inproceedings{10.1145/1030083.1030088,
author = {Vigna, Giovanni and Robertson, William and Balzarotti, Davide},
title = {Testing network-based intrusion detection signatures using mutant exploits},
year = {2004},
isbn = {1581139616},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1030083.1030088},
doi = {10.1145/1030083.1030088},
abstract = {Misuse-based intrusion detection systems rely on models of attacks to identify the manifestation of intrusive behavior. Therefore, the ability of these systems to reliably detect attacks is strongly affected by the quality of their models, which are often called "signatures." A perfect model would be able to detect all the instances of an attack without making mistakes, that is, it would produce a 100% detection rate with 0 false alarms. Unfortunately, writing good models (or good signatures) is hard. Attacks that exploit a specific vulnerability may do so in completely different ways, and writing models that take into account all possible variations is very difficult. For this reason, it would be beneficial to have testing tools that are able to evaluate the "goodness" of detection signatures. This work describes a technique to test and evaluate misuse detection models in the case of network-based intrusion detection systems. The testing technique is based on a mechanism that generates a large number of variations of an exploit by applying mutant operators to an exploit template. These mutant exploits are then run against a victim host protected by a network-based intrusion detection system. The results of the systems in detecting these variations provide a quantitative basis for the evaluation of the quality of the corresponding detection model.},
booktitle = {Proceedings of the 11th ACM Conference on Computer and Communications Security},
pages = {21–30},
numpages = {10},
keywords = {intrusion detection, quality metrics, security testing},
location = {Washington DC, USA},
series = {CCS '04}
}

@inproceedings{10.1145/3384217.3384223,
author = {Rahman, Md Rayhanur and Enck, William and Williams, Laurie},
title = {Do configuration management tools make systems more secure? an empirical research plan},
year = {2020},
isbn = {9781450375610},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384217.3384223},
doi = {10.1145/3384217.3384223},
abstract = {Configuration Management Tools (CMT) help developers manage the system and installed application in an automated and efficient manner. However, misconfiguration in these tools can make a system vulnerable to compromises. Whether the usage of these tools makes the systems secure - this question can only be answered through empirical evidence. Hence, we propose a empirical research plan on the impact of CMT on systems where these tools have been applied. As a case, we will investigate the case of Endpoint Linux Management System managed by Puppet, a popular configuration management tool.},
booktitle = {Proceedings of the 7th Symposium on Hot Topics in the Science of Security},
articleno = {23},
numpages = {2},
keywords = {configuration management tools, puppet, security smells, static analysis},
location = {Lawrence, Kansas},
series = {HotSoS '20}
}

@inproceedings{10.1145/3550356.3561567,
author = {Nicacio, Jalves and Petrillo, Fabio},
title = {An approach to build consistent software architecture diagrams using devops system descriptors},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561567},
doi = {10.1145/3550356.3561567},
abstract = {System architecture diagrams play an essential role in understanding system architecture. They encourage more active discussion among participants and make it easier to recall system details. However, system architecture diagrams often diverge from the software. As a result, they can interfere with the understanding and maintenance of the software. We propose an approach to build system architecture diagrams using DevOps system descriptors to improve the consistency of architecture diagrams. To produce our approach, we survey problems with architecture diagrams in the software industry, developing guidelines for creating architecture diagrams. Next, we produce a taxonomy for system descriptor concepts and a process to convert system descriptors into architecture diagrams. We evaluate our approach through a case study. In this case study, we defined a Docker Compose descriptor for a newsfeed system and transformed it into a system architectural diagram using the proposed approach. Our results indicate that, currently, system descriptors generally lead to consistent diagrams only to a limited extent. However, the case study's observations indicate that the proposed approach is promising and demonstrates that system descriptors have the potential to create more consistent architectural diagrams. Further evaluation in controlled and empirical experiments is necessary to test our hypothesis in more detail.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {312–321},
numpages = {10},
keywords = {architectural diagram consistency, modelling process, software architecture, software engineering, software systems, system architecture, system descriptors},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3664476.3670437,
author = {Amadou Kountche, Djibrilla and Aubert, Jocelyn and Nguyen, Manh-Dung and Kalfa, Natalia and Durante, Nicola Gregorio and Passerini, Cristiano and Kuding, Stephane},
title = {The PRECINCT Ecosystem Platform for Critical Infrastructure Protection: Architecture, Deployment and Transferability},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3670437},
doi = {10.1145/3664476.3670437},
abstract = {The present work was done during the PRECINCT (Preparedness and Resilience Enforcement for Critical INfrastructure Cascading Cyberphysical Threats and effects with focus on district or regional protection) project. The PRECINCT Ecosystem Platform (PEP), part of the PRECINCT approach, serves to “unify” different Critical Infrastructures (CIs) – through a cybersecurity ecosystem platform - and helps in improving facility protection against cascading effects resulting from cyber-physical attacks, in minimizing service disruptions and in managing interfaces with other CIs. In recent years, CIs have been equipped with Industrial Internet of Things (IIoT) technologies including sensors and actuators which communicate using open protocols (e.g., MQTT, AMQP, CoAP, Modbus, DNP3) or commercially licensed protocols (LoRA, IEC 6870-5-101, Profibus) to share data and commands. Furthermore, the management of these CIs is built on Information Communication Technologies (ICTs) which became Critical Information Infrastructure (CII). Therefore, this paper proposes an approach for the deployment of ICT tools used in CI Protection (CIP) projects. Indeed, the PEP’s deployment in PRECINCT’s Living Labs (LLs) was described using Topology and Orchestration Specification for Cloud Applications (TOSCA). TOSCA, in addition to the usage of reference architectures, is proposed by this paper for re-usability and transferability of CIP projects outcomes.},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {167},
numpages = {8},
keywords = {Critical Infrastructure Protection, Reference Architecture, TOSCA},
location = {Vienna, Austria},
series = {ARES '24}
}

@inproceedings{10.5555/3374138.3374159,
author = {Bruzzone, Agostino G. and Sinelshchikov, Kirill and Massei, Marina},
title = {Application of blockchain in interoperable simulation for strategic decision making},
year = {2019},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {The study aims to develop an innovative system solution by creating a digital twin that combines virtual prototypes, mathematical models and simulation environments. The paper focuses on the case of a new UGV (Unmanned Ground Vehicle) devoted to operate within hot metal industries. The digital twin supports both the UGV engineering as well as the redesign of the industrial procedures and plant components. The authors address the development of the heating/cooling system able to guarantee UGV reliability within a wide spectrum of operative modes in the complex environment of industrial plant. The digital twin allows to evaluate how the vehicle configuration, boundary conditions and interactions with other plant components affect the UGV systems and subsystems performance. The complexity of interactions and factors requires extensive use of simulation.},
booktitle = {Proceedings of the 2019 Summer Simulation Conference},
articleno = {21},
numpages = {9},
keywords = {block chain, interoperable simulation, strategic engineering},
location = {Berlin, Germany},
series = {SummerSim '19}
}

@inproceedings{10.1145/3691620.3695277,
author = {Sahoo, Priyam and Pujar, Saurabh and Nalawade, Ganesh and Genhardt, Richard and Mandel, Louis and Buratti, Luca},
title = {Ansible Lightspeed: A Code Generation Service for IT Automation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695277},
doi = {10.1145/3691620.3695277},
abstract = {The availability of Large Language Models (LLMs) which can generate code, has made it possible to create tools that improve developer productivity. Integrated development environments or IDEs which developers use to write software are often used as an interface to interact with LLMs. Although many such tools have been released, almost all of them focus on general-purpose programming languages. Domain-specific languages, such as those crucial for Information Technology (IT) automation, have not received much attention. Ansible is one such YAML-based IT automation-specific language. Ansible Lightspeed is an LLM-based service designed explicitly to generate Ansible YAML, given natural language prompt.In this paper, we present the design and implementation of the Ansible Lightspeed service. We then evaluate its utility to developers using diverse indicators, including extended utilization, analysis of user edited suggestions, as well as user sentiments analysis. The evaluation is based on data collected for 10,696 real users including 3,910 returning users. The code for Ansible Lightspeed service and the analysis framework is made available for others to use.To our knowledge, our study is the first to involve thousands of users of code assistants for domain-specific languages. We are also the first code completion tool to present N-Day user retention figures, which is 13.66% on Day 30. We propose an improved version of user acceptance rate, called Strong Acceptance rate, where a suggestion is considered accepted only if less than 50% of it is edited and these edits do not change critical parts of the suggestion. By focusing on Ansible, Lightspeed is able to achieve a strong acceptance rate of 49.08% for multi-line Ansible task suggestions. With our findings we provide insights into the effectiveness of small, dedicated models in a domain-specific context. We hope this work serves as a reference for software engineering and machine learning researchers exploring code completion.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2148–2158},
numpages = {11},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3639478.3643534,
author = {Minna, Francesco and Blaise, Agathe and Massacci, Fabio and Tuma, Katja},
title = {Automated Security Repair for Helm Charts},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3643534},
doi = {10.1145/3639478.3643534},
abstract = {We aim to evaluate and compare open-source static analyzers for Helm Charts, a package manager to deploy applications on Kubernetes (K8s). Specifically, we developed a pipeline to measure what misconfigurations are found by each tool, to provide automatic misconfiguration repair, and whether this latter breaks application functionalities. To evaluate our approach, we analyzed the 60 most common Helm Charts available on Artifact Hub, seven open-source Helm Charts analyzers, and generated functionality profiles for each chart application. We found several bugs and inconsistency issues with the tools, which we reported on respective tool repositories, and concluded that such tools that should provide automatic security repair still require significant manual intervention.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {412–413},
numpages = {2},
keywords = {helm charts, automated security repair, kubernetes, misconfigurations},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@article{10.1145/3538705,
author = {Siebinga, Olger and Zgonnikov, Arkady and Abbink, David},
title = {A Human Factors Approach to Validating Driver Models for Interaction-aware Automated Vehicles},
year = {2022},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {4},
url = {https://doi.org/10.1145/3538705},
doi = {10.1145/3538705},
abstract = {A major challenge for autonomous vehicles is interacting with other traffic participants safely and smoothly. A promising approach to handle such traffic interactions is equipping autonomous vehicles with interaction-aware controllers (IACs). These controllers predict how surrounding human drivers will respond to the autonomous vehicle’s actions, based on a driver model. However, the predictive validity of driver models used in IACs is rarely validated, which can limit the interactive capabilities of IACs outside the simple simulated environments in which they are demonstrated. In this article, we argue that besides evaluating the interactive capabilities of IACs, their underlying driver models should be validated on natural human driving behavior. We propose a workflow for this validation that includes scenario-based data extraction and a two-stage (tactical/operational) evaluation procedure based on human factors literature. We demonstrate this workflow in a case study on an inverse-reinforcement-learning-based driver model replicated from an existing IAC. This model only showed the correct tactical behavior in 40% of the predictions. The model’s operational behavior was inconsistent with observed human behavior. The case study illustrates that a principled evaluation workflow is useful and needed. We believe that our workflow will support the development of appropriate driver models for future automated vehicles.},
journal = {J. Hum.-Robot Interact.},
month = sep,
articleno = {47},
numpages = {21},
keywords = {automated driving, inverse reinforcement learning driver model, interaction-aware controllers, Driver model validation}
}

@inproceedings{10.1145/3531056.3542769,
author = {Mwotil, Alex and Bainomugisha, Engineer and Araka, Stephen G.M.},
title = {mira: an Application Containerisation Pipeline for Small Software Development Teams in Low Resource Settings},
year = {2022},
isbn = {9781450396639},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531056.3542769},
doi = {10.1145/3531056.3542769},
abstract = {Cloud native applications leverage Development and Operation (DevOps), microservice architectures and containerisation for primarily availability, resilience and scalability reasons. Small developer teams in low resource settings have unique DevOps needs and harnessing its principles and practices is technically challenging and distinctly difficult in these contexts. We conducted a survey with professional developers, students and researchers situated and working in a low resource setting and the results indicate that these principles and practices are relatively new. In application containerisation, an operating system virtualisation method that can significantly optimize the use of computing resources, the respondents indicated challenges in the process steps. Particularly, small developer teams in low resource settings require custom tools and abstractions for software development and delivery automation. Informed by the developer needs, we designed and developed a custom automated containerisation pipeline, mira, for a managed cloud native platform situated in a low-resource setting. We validate mira against 6 major application frameworks, tools and/or languages and successful deployment of the resultant applications onto a cloud native platform.},
booktitle = {Proceedings of the Federated Africa and Middle East Conference on Software Engineering},
pages = {31–38},
numpages = {8},
keywords = {automation, cloud, cloud native, containers, docker, orchestration},
location = {Cairo-Kampala, Egypt},
series = {FAMECSE '22}
}

@inproceedings{10.1109/ASE51524.2021.9678585,
author = {Ksontini, Emna and Kessentini, Marouane and Ferreira, Thiago do N. and Hassan, Foyzul},
title = {Refactorings and technical debt in docker projects: an empirical study},
year = {2022},
isbn = {9781665403375},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE51524.2021.9678585},
doi = {10.1109/ASE51524.2021.9678585},
abstract = {Software containers, such as Docker, are recently considered as the mainstream technology of providing reusable software artifacts. Developers can easily build and deploy their applications based on the large number of reusable Docker images that are publicly available. Thus, a current popular trend in industry is to move towards the containerization of their applications. However, container-based projects compromise different components including the Docker and Docker-compose files, and several other dependencies to the source code combining different containers and facilitating the interactions with them. Similar to any other complex systems, container-based projects are prone to various quality and technical debt issues related to different artifacts: Docker and Docker-compose files, and regular source code ones. Unfortunately, there is a gap of knowledge in how container-based projects actually evolve and are maintained.In this paper, we address the above gap by studying refactorings, i.e., structural changes while preserving the behavior, applied in open-source Docker projects, and the technical debt issues they alleviate. We analyzed 68 projects, consisting of 19,5 MLOC, along with 193 manually examined commits. The results indicate that developers refactor these Docker projects for a variety of reasons that are specific to the configuration, combination and execution of containers, leading to several new technical debt categories and refactoring types compared to existing refactoring domains. For instance, refactorings for reducing the image size of Dockerfiles, improving the extensibility of Docker-compose files, and regular source code refactorings are mainly associated with the evolution of Docker and Docker-compose files. We also introduced 24 new Docker-specific refactorings and technical debt categories, respectively, and defined different best practices. The implications of this study will assist practitioners, tool builders, and educators in improving the quality of Docker projects.},
booktitle = {Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering},
pages = {781–791},
numpages = {11},
keywords = {technical debt, refactoring, maintenance, docker, containers},
location = {Melbourne, Australia},
series = {ASE '21}
}

@inproceedings{10.1145/3368089.3409675,
author = {Siegmund, Norbert and Ruckel, Nicolai and Siegmund, Janet},
title = {Dimensions of software configuration: on the configuration context in modern software development},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409675},
doi = {10.1145/3368089.3409675},
abstract = {With the rise of containerization, cloud development, and continuous integration and delivery, configuration has become an essential aspect not only to tailor software to user requirements, but also to configure a software system’s environment and infrastructure. This heterogeneity of activities, domains, and processes blurs the term configuration, as it is not clear anymore what tasks, artifacts, or stakeholders are involved and intertwined. However, each re- search study and each paper involving configuration places their contributions and findings in a certain context without making the context explicit. This makes it difficult to compare findings, translate them to practice, and to generalize the results. Thus, we set out to evaluate whether these different views on configuration are really distinct or can be summarized under a common umbrella. By interviewing practitioners from different domains and in different roles about the aspects of configuration and by analyzing two qualitative studies in similar areas, we derive a model of configuration that provides terminology and context for research studies, identifies new research opportunities, and allows practitioners to spot possible challenges in their current tasks. Although our interviewees have a clear view about configuration, it substantially differs due to their personal experience and role. This indicates that the term configuration might be overloaded. However, when taking a closer look, we see the interconnections and dependencies among all views, arriving at the conclusion that we need to start considering the entire spectrum of dimensions of configuration.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {338–349},
numpages = {12},
keywords = {variability, developer study, configuration management and life cycle, Dimensions of software configuration},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}

@inproceedings{10.5555/3463952.3464054,
author = {Ma, Xiaoteng and Yang, Yiqin and Li, Chenghao and Lu, Yiwen and Zhao, Qianchuan and Yang, Jun},
title = {Modeling the Interaction between Agents in Cooperative Multi-Agent Reinforcement Learning},
year = {2021},
isbn = {9781450383073},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Value-based methods of multi-agent reinforcement learning (MARL), especially the value decomposition methods, have been demonstrated on a range of challenging cooperative tasks. However, current methods pay little attention to the interaction between agents, which is essential to teamwork in games or real life. This limits the efficiency of value-based MARL algorithms in the two aspects: collaborative exploration and value function estimation. In this paper, we propose a novel cooperative MARL algorithm named as interactive actor-critic (IAC), which models the interaction of agents from the perspectives of policy and value function. On the policy side, a multi-agent joint stochastic policy is introduced by adopting a collaborative exploration module, which is trained by maximizing the entropy-regularized expected return. On the value side, we use the shared attention mechanism to estimate the value function of each agent, which takes the impact of the teammates into consideration. At the implementation level, we extend the value decomposition methods to continuous control tasks and evaluate IAC on benchmark tasks including classic control and multi-agent particle environments. Experimental results indicate that our method outperforms the state-of-the-art approaches and achieves better performance in terms of cooperation.},
booktitle = {Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {853–861},
numpages = {9},
keywords = {collaborative exploration, maximum entropy learning, multi-agent reinforcement learning},
location = {Virtual Event, United Kingdom},
series = {AAMAS '21}
}

@article{10.1145/3617173,
author = {Zhou, Yu and Zhan, Weilin and Li, Zi and Han, Tingting and Chen, Taolue and Gall, Harald},
title = {
DRIVE: Dockerfile Rule Mining and Violation Detection},
year = {2023},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3617173},
doi = {10.1145/3617173},
abstract = {A Dockerfile defines a set of instructions to build Docker images, which can then be instantiated to support containerized applications. Recent studies have revealed a considerable amount of quality issues with Dockerfiles. In this article, we propose a novel approach, Dockerfiles Rule mIning and Violation dEtection (DRIVE), to mine implicit rules and detect potential violations of such rules in Dockerfiles. DRIVE first parses Dockerfiles and transforms them to an intermediate representation. It then leverages an efficient sequential pattern mining algorithm to extract potential patterns. With heuristic-based reduction and moderate human intervention, potential rules are identified, which can then be utilized to detect potential violations of Dockerfiles. DRIVE identifies 34 semantic rules and 19 syntactic rules including 9 new semantic rules that have not been reported elsewhere. Extensive experiments on real-world Dockerfiles demonstrate the efficacy of our approach.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {30},
numpages = {23},
keywords = {violation detection, configuration files, pattern mining, dockerfile, Docker}
}

@inproceedings{10.1145/3577065.3577093,
author = {Deng, Hongwei and Li, Yike and Wang, Haishi},
title = {An Improved Compensation Time Control Strategy Based on CrM Mode Boost PFC Converter},
year = {2023},
isbn = {9781450397797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3577065.3577093},
doi = {10.1145/3577065.3577093},
abstract = {This paper aims at the problem that the average current is no longer proportional to the input voltage after the Boost PFC converter in the critical conduction mode passes through the zero value, which leads to the deterioration of the total harmonic distortion. Therefore, a control method and circuit for reducing total harmonic distortion are proposed. The method determines the new compensation time by sampling the voltage value and uses the new compensation of time compensation as the conduction time of the switch tube, so as to compensate for the average current error caused by the negative current. After testing and verification, the control strategy improves the effect of power factor correction and can effectively reduce the total harmonic distortion value.},
booktitle = {Proceedings of the 2022 5th International Conference on Telecommunications and Communication Engineering},
pages = {154–160},
numpages = {7},
keywords = {Total Harmonics Distortion(THD), Power Factor Correction(PFC), Critical Conduction Mode(CrM)},
location = {Chengdu, China},
series = {ICTCE '22}
}

@inproceedings{10.5555/3373669.3373678,
author = {Brown, Kyle and Hay, Christopher},
title = {Patterns of software development with containers},
year = {2020},
publisher = {The Hillside Group},
address = {USA},
abstract = {This pattern language is concerned with the problems inherent in building and delivering software using containers, particularly those issues that arise during the process of mapping Docker images and containers into the stages of a software development lifecycle. We discuss practical solutions to problems of security and scaling brought on by adoption of container platforms. The language assumes that the reader will be building applications following an agile approach that is characterized by Continuous Integration/Continuous Delivery. This paper is part of a larger set of patterns of cloud adoption; for information on patterns of microservices adoption that may precede these patterns see [Brown 2016].},
booktitle = {Proceedings of the 25th Conference on Pattern Languages of Programs},
articleno = {10},
numpages = {14},
keywords = {software architectures, pattern languages, containers, Docker},
location = {Portland, Oregon},
series = {PLoP '18}
}

@article{10.5555/3533760.3533764,
author = {Cook, Jack and Weiss, Richard and Mache, Jens and Mor\'{a}n, Carlos Garc\'{\i}a and Wang, Justin},
title = {An authoring process to construct docker containers to help instructors develop cybersecurity exercises},
year = {2022},
issue_date = {April 2022},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {37},
number = {10},
issn = {1937-4771},
abstract = {As instructors, we are more likely to use exercises that we can modify or that we helped to develop. The problem we address is how to help instructors create their own hands-on exercises. This paper describes the authoring process for the creation of cybersecurity exercises and the experience of creating two very different exercises. One of these exercises is about vulnerable Web services and leverages the LAMP stack and the other is about cryptography and ransomware and uses VNC. They both use Terraform to create Docker containers. We address the issues of creating exercises that involve multiple containers and can be run in a cloud environment, as well as on a single server.This paper describes the process of creating these cybersecurity exercises in our framework. The streamlined process enabled the development of totally new exercises much faster than previously experienced. In the case of the ransomware exercise, it was two weeks from start to finish, compared to months for previous exercises.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {37–47},
numpages = {11}
}

@inproceedings{10.1145/3037697.3037712,
author = {Hsiao, Chun-Hung and Narayanasamy, Satish and Khan, Essam Muhammad Idris and Pereira, Cristiano L. and Pokam, Gilles A.},
title = {AsyncClock: Scalable Inference of Asynchronous Event Causality},
year = {2017},
isbn = {9781450344654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3037697.3037712},
doi = {10.1145/3037697.3037712},
abstract = {Asynchronous programming model is commonly used in mobile systems and Web 2.0 environments. Asynchronous race detectors use algorithms that are an order of magnitude performance and space inefficient compared to conventional data race detectors. We solve this problem by identifying and addressing two important problems in reasoning about causality between asynchronous events.Unlike conventional signal-wait operations, establishing causal order between two asynchronous events is fundamentally more challenging as there is no common handle they operate on. We propose a new primitive named AsyncClock that addresses this problem by explicitly tracking causally preceding events, and show that AsyncClock can handle a wide variety of asynchronous causality models. We also address the important scalability problem of efficiently identifying heirless events whose metadata can be reclaimed.We built the first single-pass, non-graph-based Android race detector using our algorithm and applied it to find errors in 20 popular applications. Our tool incurs about 6x performance overhead, which is several times more efficient than the state-of-the-art solution. It also scales well with the execution length. We used our tool to find 147 previously unknown harmful races.},
booktitle = {Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {193–205},
numpages = {13},
keywords = {happens-before, event-driven, data races, causality, asynchronous, android},
location = {Xi'an, China},
series = {ASPLOS '17}
}

@inproceedings{10.1109/ECASE.2019.00013,
author = {Yuan, Eric},
title = {Architecture interoperability and repeatability with microservices: an industry perspective},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ECASE.2019.00013},
doi = {10.1109/ECASE.2019.00013},
abstract = {Microservices, along with supporting technologies such as containers, have become a prevalent architecture approach for today's software systems, especially in enterprise environments. They represent the latest evolutionary step in the decades-old journey towards service- and component-based software architectures. Along with virtualization technologies, microservices have enabled the loose-coupling of both service interfaces (message passing) and service integration (form and fit). This paper attempts to explore the impact of microservices on software architecture interoperability and repeatability, based on our experiences in developing two microservice-based systems. Our central thesis is that, if we view software architecture as a set of principal design decisions, the microservices approach enable us to more elegantly separate these decisions from non-architectural, domain-specific ones, and thus make these decisions more interoperable, reusable, and repeatable across disparate problem domains. We therefore propose that a microservices based reference architecture (RA) and reference implementation (RI) be created for the community-wide infrastructure for software engineering and software architecture research, along with a set of detailed considerations.},
booktitle = {Proceedings of the 2nd International Workshop on Establishing a Community-Wide Infrastructure for Architecture-Based Software Engineering},
pages = {26–33},
numpages = {8},
keywords = {software architecture, microservice, cloud computing, DevOps},
location = {Montreal, Quebec, Canada},
series = {ECASE '19}
}

@inproceedings{10.1109/ICSE43902.2021.00106,
author = {Henkel, Jordan and Silva, Denini and Teixeira, Leopoldo and d'Amorim, Marcelo and Reps, Thomas},
title = {Shipwright: A Human-in-the-Loop System for Dockerfile Repair},
year = {2021},
isbn = {9781450390859},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE43902.2021.00106},
doi = {10.1109/ICSE43902.2021.00106},
abstract = {Docker is a tool for lightweight OS-level virtualization. Docker images are created by performing a build, controlled by a source-level artifact called a Dockerfile. We studied Dockerfiles on GitHub, and---to our great surprise--- found that over a quarter of the examined Dockerfiles failed to build (and thus to produce images). To address this problem, we propose Shipwright, a human-in-the-loop system for finding repairs to broken Dockerfiles. Shipwright uses a modified version of the BERT language model to embed build logs and to cluster broken Dockerfiles. Using these clusters and a search-based procedure, we were able to design 13 rules for making automated repairs to Dockerfiles. With the aid of Shipwright, we submitted 45 pull requests (with a 42.2% acceptance rate) to GitHub projects with broken Dockerfiles. Furthermore, in a "time-travel" analysis of broken Dockerfiles that were later fixed, we found that Shipwright proposed repairs that were equivalent to human-authored patches in 22.77% of the cases we studied. Finally, we compared our work with recent, state-of-the-art, static Dockerfile analyses, and found that, while static tools detected possible build-failure-inducing issues in 20.6-33.8% of the files we examined, Shipwright was able to detect possible issues in 73.25% of the files and, additionally, provide automated repairs for 18.9% of the files.},
booktitle = {Proceedings of the 43rd International Conference on Software Engineering},
pages = {1148–1160},
numpages = {13},
keywords = {Repair, Docker, DevOps},
location = {Madrid, Spain},
series = {ICSE '21}
}

@inproceedings{10.1145/3194760.3194763,
author = {D\"{u}llmann, Thomas F. and Paule, Christina and van Hoorn, Andr\'{e}},
title = {Exploiting devops practices for dependable and secure continuous delivery pipelines},
year = {2018},
isbn = {9781450357456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3194760.3194763},
doi = {10.1145/3194760.3194763},
abstract = {Continuous delivery (CD) pipelines recently gained wide adoption. They provide means for short and high-frequent development cycles in DevOps by automating many steps after a commit has been issued and bringing it into production. CD pipelines have become essential for development and delivery. Hence, they are crucial and business-critical assets that need to be protected from harm in terms of dependability and security. DevOps practices like canary releasing and A/B testing aim to improve the quality of the software that is built by CD pipelines while keeping a high pace of development. Although CD is a part of DevOps, the DevOps practices have primarily been applied to the artifacts that are processed but not on the pipelines themselves. We outline our vision of using these DevOps practices to improve the dependability and security of CD pipelines. The goal is to detect, diagnose, and resolve dependability and security issues in the CD pipeline behavior. In this paper, we outline our envisioned roadmap and preliminary results from an ongoing industrial case study.},
booktitle = {Proceedings of the 4th International Workshop on Rapid Continuous Software Engineering},
pages = {27–30},
numpages = {4},
location = {Gothenburg, Sweden},
series = {RCoSE '18}
}

@inproceedings{10.1109/CCGrid.2015.125,
author = {Duplyakin, Dmitry and Haney, Matthew and Tufo, Henry},
title = {Highly available cloud-based cluster management},
year = {2015},
isbn = {9781479980062},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2015.125},
doi = {10.1109/CCGrid.2015.125},
abstract = {We present an architecture that increases persistence and reliability of automated infrastructure management in the context of hybrid, cluster-cloud environments. We describe our highly available implementation that builds upon Chef configuration management system and infrastructure-as-a-service cloud resources from Amazon Web Services. We summarize our experience with managing a 20-node Linux cluster using this implementation. Our analysis of utilization and cost of necessary cloud resources indicates that the designed system is a low-cost alternative to acquiring additional physical hardware for hardening cluster management.},
booktitle = {Proceedings of the 15th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {1201–1204},
numpages = {4},
keywords = {automated infrastructure management, configuration management system, high availability},
location = {Shenzhen, China},
series = {CCGRID '15}
}

@inproceedings{10.1145/3377811.3380406,
author = {Henkel, Jordan and Bird, Christian and Lahiri, Shuvendu K. and Reps, Thomas},
title = {Learning from, understanding, and supporting DevOps artifacts for docker},
year = {2020},
isbn = {9781450371216},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377811.3380406},
doi = {10.1145/3377811.3380406},
abstract = {With the growing use of DevOps tools and frameworks, there is an increased need for tools and techniques that support more than code. The current state-of-the-art in static developer assistance for tools like Docker is limited to shallow syntactic validation. We identify three core challenges in the realm of learning from, understanding, and supporting developers writing DevOps artifacts: (i) nested languages in DevOps artifacts, (ii) rule mining, and (iii) the lack of semantic rule-based analysis. To address these challenges we introduce a toolset, binnacle, that enabled us to ingest 900,000 GitHub repositories.Focusing on Docker, we extracted approximately 178,000 unique Dockerfiles, and also identified a Gold Set of Dockerfiles written by Docker experts. We addressed challenge (i) by reducing the number of effectively uninterpretable nodes in our ASTs by over 80% via a technique we call phased parsing. To address challenge (ii), we introduced a novel rule-mining technique capable of recovering two-thirds of the rules in a benchmark we curated. Through this automated mining, we were able to recover 16 new rules that were not found during manual rule collection. To address challenge (iii), we manually collected a set of rules for Dockerfiles from commits to the files in the Gold Set. These rules encapsulate best practices, avoid docker build failures, and improve image size and build latency. We created an analyzer that used these rules, and found that, on average, Dockerfiles on GitHub violated the rules five times more frequently than the Dockerfiles in our Gold Set. We also found that industrial Dockerfiles fared no better than those sourced from GitHub.The learned rules and analyzer in binnacle can be used to aid developers in the IDE when creating Dockerfiles, and in a post-hoc fashion to identify issues in, and to improve, existing Dockerfiles.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
pages = {38–49},
numpages = {12},
keywords = {DevOps, docker, mining, static checking},
location = {Seoul, South Korea},
series = {ICSE '20}
}

@article{10.5555/3447080.3447091,
author = {Border, Charles},
title = {Development of a configuration management course for computing operations students},
year = {2020},
issue_date = {October 2020},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {36},
number = {3},
issn = {1937-4771},
abstract = {The Operations side of deploying a modern computing application necessarily involves multiple groups working in concert to develop the application and the server side configuration that will support that application. This paper reports on efforts to develop a course that encourages students to dig into issues related to configuration management, security policy development, application auditing, business control issues, and most importantly, team work. While the course is entitled "Configuration Management" it is much more about students creating a process for secure iterative application deployment that borrows extensively from the DevOps movement.Ansible, our chosen configuration management tool, is relatively easy to work with at the level of complexity that can be reached in an undergraduate class. What made this class different was the attempt made to create a process that would more closely mimic the Operations side of a DevOps workflow. Initial results from the class were encouraging and many lessons were learned.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {89–101},
numpages = {13}
}

@inproceedings{10.1145/2755644.2755647,
author = {Duplyakin, Dmitry and Haney, Matthew and Tufo, Henry},
title = {Architecting a Persistent and Reliable Configuration Management System},
year = {2015},
isbn = {9781450335706},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2755644.2755647},
doi = {10.1145/2755644.2755647},
abstract = {Streamlined configuration management plays a significant role in modern, complex distributed systems. Via mechanisms that promote consistency, repeatability, and transparency, configuration management systems (CMSes) address complexity and aim to increase the efficiency of administrative procedures, including deployment and failure recovery scenarios. Considering the importance of minimizing disruptions in these systems, we design an architecture that increases persistency and reliability of infrastructure management. We present our architecture in the context of hybrid, cluster-cloud environments and describe our highly available implementation that builds upon the open source CMS called Chef and infrastructure-as-a-service cloud resources from Amazon Web Services. We demonstrate how we enabled a smooth transition from the pre-existing single-server configuration to the proposed highly available management system. We summarize our experience with managing a 20-node Linux cluster using this implementation. Our analysis of utilization and cost of necessary cloud resources indicates that the designed system is a low-cost alternative to acquiring additional physical hardware for hardening cluster management. We also highlight the prototype's security and manageability features that are suitable for larger, production-ready deployments.},
booktitle = {Proceedings of the 6th Workshop on Scientific Cloud Computing},
pages = {11–16},
numpages = {6},
keywords = {automated infrastructure management, cloud computing, computing cluster, configuration management system, high availability, hybrid systems},
location = {Portland, Oregon, USA},
series = {ScienceCloud '15}
}

@inproceedings{10.1145/3661167.3661206,
author = {Maggi, Kevin and Verdecchia, Roberto and Scommegna, Leonardo and Vicario, Enrico},
title = {CLAIM: a Lightweight Approach to Identify Microservices in Dockerized Environments},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661206},
doi = {10.1145/3661167.3661206},
abstract = {Background: Over the past decade, microservices have surged in popularity within software engineering. From a research viewpoint, mining studies are frequently employed to assess the evolution of diverse microservice properties. Despite the growing need, a validated static method to swiftly identify microservices seems to be currently missing in the literature. Aims: We present Claim, a lightweight static approach that analyzes configuration files to identify microservices in Dockerized environments, specifically designed with mining studies in&nbsp;mind. Method: To validate Claim, we conduct an empirical experiment comprising 20 repositories, 160 microservices, and 13k commits. A priori and manually defined ground truths are used to evaluate Claim’s microservice identification effectiveness and efficiency. Results: Claim detects microservices with an accuracy of 82.0%, reports a median execution time of 61ms per commit, and requires in the worst case scenario 125.5s to analyze the history of a repository comprising 1509 commits. With respect to its closest competitor, CLAIM shines most in terms of false positive reduction&nbsp;(-40%). Conclusions: While not able to reconstruct a microservice architecture in its entirety, Claim is an effective and efficient option to swiftly identify microservices in Dockerized environments, and seems especially fitted for software evolution mining studies.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {357–362},
numpages = {6},
keywords = {Docker, Microservices, Repository Mining, Static Analysis},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3282308.3282315,
author = {Sousa, Tiago Boldt and Ferreira, Hugo Sereno and Correia, Filipe Figueiredo and Aguiar, Ademar},
title = {Engineering Software for the Cloud: Automated Recovery and Scheduler},
year = {2018},
isbn = {9781450363877},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3282308.3282315},
doi = {10.1145/3282308.3282315},
abstract = {Cloud software continues to expand globally, highly motivated by how widespread the Internet is and the possibilities it unlocks with cloud computing. Still, cloud development has some intrinsic properties to it, making it complex to unexperienced developers.This research is capturing those intricacies in the form of a pattern language that gathers ten patterns for engineering software for the cloud. This paper elaborates on that research by contributing with two new patterns: AUTOMATED RECOVERY, which checks if a container is working properly, automatically recovering it in case of failure and SCHEDULER, which periodically executes actions within the infrastructure.The described patterns are useful for anyone designing software for the cloud, either to bootstrap or to validate their design decisions with the end goal of enabling them to create better software for the cloud.},
booktitle = {Proceedings of the 23rd European Conference on Pattern Languages of Programs},
articleno = {6},
numpages = {8},
keywords = {Software Engineering, Design Patterns, Cloud Computing},
location = {Irsee, Germany},
series = {EuroPLoP '18}
}

@inproceedings{10.1145/3136825.3136892,
author = {Gaur, Swati and Gaur, Sudhanshu},
title = {Component-centric application-driven framework: towards taming privilege separation in Android},
year = {2017},
isbn = {9781450353038},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3136825.3136892},
doi = {10.1145/3136825.3136892},
abstract = {Android is a Linux-based Operating-System (OS), the most prevailing Smartphone among its competitors that attracts attackers, the Malware which performs inter-application communication (IAC) precludes malware scanner. We are proposing Honified, a tool performing on-device access control mechanism to combat these vulnerabilities. Furthermore, Honified will interpose the vulnerable but benign application (app) with the code of reference monitor aka Inline reference monitoring and transforms into Honey-app. Moreover, it is derived from the concept of Honeypot, made for being attacked and compromise the security to lure the attacking application. It lures the attacking application and further it is used to provide the resilient as well as robust access control at Stock Android. Honified uses the concept of In-app reference monitoring aka Inline reference monitoring, it also thwarts the dissemination of private data of the user and prompts the user to uninstall the app to reduce monitoring overhead. Delta Micro-benchmark shows that overall score of work with Honified tool achieved 96.89% that is quite affordable.},
booktitle = {Proceedings of the 10th International Conference on Security of Information and Networks},
pages = {218–223},
numpages = {6},
keywords = {vulnerable, smartphone, malware, honified, honeypot, honey-app, Android},
location = {Jaipur, India},
series = {SIN '17}
}

@inproceedings{10.1145/1297385.1297393,
author = {Bertolli, Carlo and Coppola, Massimo and Zoccolo, Corrado},
title = {The co-replication methodology and its application to structured parallel programs},
year = {2007},
isbn = {9781595938671},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1297385.1297393},
doi = {10.1145/1297385.1297393},
abstract = {We introduce Co-Replication, a technique exploiting abstract properties of a computation to allow parallel replicas of a software module to cooperate, enhancing both the reliability and availability of the resulting component, and providing a flexible trade-off among the two properties.In Co-Replication a complete partial ordering is defined on the computation state. The formal expression of the state combination operation among replicas allows them to compute independently as a co-algorithm, and to exploit low-overhead, opportunistic strategies for spreading results and surviving to faults.Co-Replication suits structured parallel and component based programming, as it needs a high level description of the computation properties, and thus can ease exploitation ofnon fault-free, parallel platforms like large clusters and Grids. We describe the theoretical foundations of Co-Replication, and investigate the use of random gossiping strategies for the state combination. To show the applicability of the technique, we discuss the modelization of Master-Slave and task farm computations, and report test results over two applications.},
booktitle = {Proceedings of the 2007 Symposium on Component and Framework Technology in High-Performance and Scientific Computing},
pages = {39–48},
numpages = {10},
keywords = {structured parallellism, replication},
location = {Montreal, Quebec, Canada},
series = {CompFrame '07}
}

@inproceedings{10.1145/3209281.3209309,
author = {Alarabiat, Ayman and Soares, Delfina and Ferreira, Luis and de S\'{a}-Soares, Filipe},
title = {Analyzing e-governance assessment initiatives: an exploratory study},
year = {2018},
isbn = {9781450365260},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3209281.3209309},
doi = {10.1145/3209281.3209309},
abstract = {This paper presents an exploratory study aimed at identifying, exploring, and analyzing current EGOV assessment initiatives. We do so based on data obtained from a desktop research and from a worldwide questionnaire directed to the 193 countries that are part of the list used by the Statistics Division of the United Nations Department of Economic and Social Affairs (UNDESA). The study analyses 12 EGOV assessment initiatives: a) seven of them are international/regional EGOV assessment initiatives performed by the United Nations (UN), European Union (EU), Waseda-IAC, Organisation for Economic Co-operation and Development (OECD), World Bank (WB), WWW Foundation, and Open Knowledge Network (OKN); b) five of them are country-level EGOV assessment initiatives performed by Norway, Germany, India, Saudi Arabia, and the United Arab Emirates. Further, the study provides general results obtained from a questionnaire with participation from 18 countries: Afghanistan, Angola, Brazil, Cabo Verde, Denmark, Estonia, Finland, Germany, Ghana, Ireland, Latvia, the Netherlands, Norway, Oman, Pakistan, the Philippines, Portugal, and Slovenia. The findings show that there is no shortage of interest in assessing EGOV initiatives. However, the supply side of EGOV initiatives is the dominant perspective being assessed, particularly by regional and international organizations. While there is an increasing interest in assessing the users' perspective (demand side) by individual countries, such attempts still seem to be at an early stage. Additionally, the actual use and impact of various EGOV services and activities are rarely well identified and measured. This study represents a stepping stone for developing instruments for assessing EGOV initiatives in future works. For the current stage, the study presents several general suggestions to be considered during the assessment process.},
booktitle = {Proceedings of the 19th Annual International Conference on Digital Government Research: Governance in the Data Age},
articleno = {30},
numpages = {10},
keywords = {evaluation, e-government, e-governance, assessment},
location = {Delft, The Netherlands},
series = {dg.o '18}
}

@inproceedings{10.1145/3634713.3634723,
author = {Gr\"{u}nbacher, Paul and Neuwirth, Markus},
title = {Towards Feature-based Versioning for Musicological Research},
year = {2024},
isbn = {9798400708770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634713.3634723},
doi = {10.1145/3634713.3634723},
abstract = {This paper discusses the management of revisions and variants of musical works for the context of musicological research. Domain-specific languages (DSLs) are a fundamental tool in music notation and analysis, as they enable the notation of music and also support music analysis when investigating particular structural properties of melody, harmony, rhythm, or form. However, the fields of music philology and music analysis still lack a systematic approach for uniformly managing revisions and variants of musical compositions. This research-in-progress paper proposes the use of feature-based versioning to streamline the management of revisions and variants in music artifacts. We introduce an illustrative example and present research challenges regarding variability and feature-based versioning for musicological research. We present a preliminary approach which involves mapping features to specific parts of musical works and musical analyses, thereby facilitating the composition of new variants based on selected features, a prerequisite for enhanced research in music philology and music analysis.},
booktitle = {Proceedings of the 18th International Working Conference on Variability Modelling of Software-Intensive Systems},
pages = {77–82},
numpages = {6},
keywords = {domain-specific languages, feature-based version control, music and variability, musicology},
location = {Bern, Switzerland},
series = {VaMoS '24}
}

@inproceedings{10.5555/3124497.3124517,
author = {Sousa, Tiago Boldt and Correia, Filipe Figueiredo and Ferreira, Hugo Sereno},
title = {Patterns for software orchestration on the cloud},
year = {2015},
isbn = {9781941652039},
publisher = {The Hillside Group},
address = {USA},
abstract = {Software businesses are redirecting their expansion towards service-oriented businesses models, highly supported by cloud computing. While cloud computing is not a new research subject, there's a clear lack of documented best practices on how to orchestrate cloud environments, either public, private or hybrid. This paper is targeted at DevOps practitioners and explores solutions for cloud orchestration, describing them as three patterns: a) Software Containerization, providing resource sharing with minimal virtualization overhead, b) Local Reverse Proxy, allowing applications to access any service in a cluster abstracting its placement and c) Orchestration by Resource Offering, ensuring applications get orchestrated in a machine with the required resources to run it. The authors believe that these three DevOps patterns will help researchers and newcomers to cloud orchestration to identify and adopt existing best practices earlier, hence, simplifying software life cycle management.},
booktitle = {Proceedings of the 22nd Conference on Pattern Languages of Programs},
articleno = {17},
numpages = {12},
keywords = {design-patterns, cloud computing, DevOps patterns},
location = {Pittsburgh, Pennsylvania},
series = {PLoP '15}
}

@inproceedings{10.1145/2975969.2975974,
author = {F\"{o}rd\H{o}s, Vikt\'{o}ria and Cesarini, Francesco},
title = {CRDTs for the configuration of distributed Erlang systems},
year = {2016},
isbn = {9781450344319},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2975969.2975974},
doi = {10.1145/2975969.2975974},
abstract = {CRDT (Conflict-free replicated data type) is a data type that supports conflict free resolution of concurrent, distributed updates. It is often mentioned alongside storage systems that are distributed, fault-tolerant and reliable. These are similar properties and features of Erlang/OTP systems. What distributed Erlang/OTP systems lack, however, is a standardised way to configure multiple nodes. OTP middleware allows you to set configuration parameters called application environment variables on a node basis, they can be updated at runtime, but will not survive a restart unless persisted in the business logic of the system. There is no widely adopted solution to address this omission. In some installations, changes are done manually in the Erlang shell and persisted by editing the configuration files. In others, changes and updates are implemented as part of a new releases and deployed through an upgrade procedure. These tools expect a happy path, and rarely take network failures and consistency into consideration. As a result, issues have been known to cause outages and have left the system in an inconsistent state, with no automated means of detecting the root cause of the problem. In this paper, we introduce a configuration management approach designed for distributed Erlang/OTP systems. They are systems which often trade consistency for availability and scalability, making them a perfect fit for CRDTs. We use a proprietary tool called WombatOAM to update environment variables and check their consistency on both node and cluster-levels. Inconsistencies and failed updates are detected and reported in the form of an alarms, and the history and status of all performed changes are logged, facilitating troubleshooting and recovery efforts. In this paper, we show our approaches to configuration management, and discuss how we approached the issue of consistency in the presence of unreliable networks. We present a qualitative evaluation and a case study to assess the capabilities of WombatOAM’s CRDT based configuration management feature.},
booktitle = {Proceedings of the 15th International Workshop on Erlang},
pages = {42–53},
numpages = {12},
keywords = {WombatOAM, Erlang, Elixir, DevOps, Configuration management, CRDT},
location = {Nara, Japan},
series = {Erlang 2016}
}

@article{10.1613/jair.1.14386,
author = {Lyu, Xueguang and Baisero, Andrea and Xiao, Yuchen and Daley, Brett and Amato, Christopher},
title = {On Centralized Critics in Multi-Agent Reinforcement Learning},
year = {2023},
issue_date = {Jun 2023},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {77},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.14386},
doi = {10.1613/jair.1.14386},
abstract = {Centralized Training for Decentralized Execution, where agents are trained offline in a centralized fashion and execute online in a decentralized manner, has become a popular approach in Multi-Agent Reinforcement Learning (MARL). In particular, it has become popular to develop actor-critic methods that train decentralized actors with a centralized critic where the centralized critic is allowed access global information of the entire system, including the true system state. Such centralized critics are possible given offline information and are not used for online execution. While these methods perform well in a number of domains and have become a de facto standard in MARL, using a centralized critic in this context has yet to be sufficiently analyzed theoretically or empirically. In this paper, we therefore formally analyze centralized and decentralized critic approaches, and analyze the effect of using state-based critics in partially observable environments. We derive theories contrary to the common intuition: critic centralization is not strictly beneficial, and using state values can be harmful. We further prove that, in particular, state-based critics can introduce unexpected bias and variance compared to history-based critics. Finally, we demonstrate how the theory applies in practice by comparing different forms of critics on a wide range of common multi-agent benchmarks. The experiments show practical issues such as the difficulty of representation learning with partial observability, which highlights why the theoretical problems are often overlooked in the literature.},
journal = {J. Artif. Int. Res.},
month = jun,
numpages = {60}
}

@inproceedings{10.5555/1999416.1999448,
author = {Feinberg, Jerry M. and Graebener, Robert J.},
title = {The role of MSIAC in supporting modeling and simulation},
year = {2010},
publisher = {Society for Computer Simulation International},
address = {San Diego, CA, USA},
abstract = {This paper presents the roles and missions of the Modeling and Simulation Information Analysis Center (MSIAC), an organization that has provided over ten years of quality support to the DoD modeling and simulation (M&amp;S) community. Under its charter as an integrated support activity for the use, employment, and sustainment of M&amp;S, the MSIAC has helped ensure that M&amp;S capabilities resident across the DoD, within U. S. industry supporting DoD, and in academia are visible and available for re-use. The MSIAC also educates and trains a superior M&amp;S workforce to innovate, evaluate, and apply these M&amp;S capabilities.The MSIAC supports the efficient and effective development, maintenance, and application of M&amp;S through coordinating efforts at the scientific, technical, and operational support levels. This paper concentrates on four areas of coordination that underpin MSIAC technical success: the MSIAC help desk, MSIAC databases, MSIAC outreach, and MSIAC technical area tasks. These rely upon the MSIAC's understanding of the M&amp;S community, its understanding of the M&amp;S community's needs, its understanding of M&amp;S technology and solutions, and its comprehensive M&amp;S knowledge base. By combining its sustaining processes with its strong military operations and warfighter experience, the MSIAC is ensuring that it will continue to provide effective support to the M&amp;S community.},
booktitle = {Proceedings of the 2010 Summer Computer Simulation Conference},
pages = {258–263},
numpages = {6},
keywords = {policy-making, model transfer, model analysis, forecasting, decision-making},
location = {Ottawa, Ontario, Canada},
series = {SCSC '10}
}

@inproceedings{10.1145/2999572.2999602,
author = {Zhang, Wei and Hwang, Jinho and Rajagopalan, Shriram and Ramakrishnan, K.K. and Wood, Timothy},
title = {Flurries: Countless Fine-Grained NFs for Flexible Per-Flow Customization},
year = {2016},
isbn = {9781450342926},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2999572.2999602},
doi = {10.1145/2999572.2999602},
abstract = {The combination of Network Function Virtualization (NFV) and Software Defined Networking (SDN) allows flows to be flexibly steered through efficient processing pipelines. As deployment of NFV becomes more prevalent, the need to provide fine-grained customization of service chains and flow-level performance guarantees will increase, even as the diversity of Network Functions (NFs) rises. Existing NFV approaches typically route wide classes of traffic through pre-configured service chains. While this aggregation improves efficiency, it prevents flexibly steering and managing performance of flows at a fine granularity.To provide both efficiency and flexibility, we present Flurries, an NFV platform designed to support large numbers of short-lived lightweight NFs, potentially running a unique NF for each flow. Flurries maintains a pool of Docker container NFs--several thousand on each host--and resets NF memory state between flows for fast reuse. Flurries uses a hybrid of polling and interrupts to improve throughput and latency while allowing multiple NFs to efficiently share CPU cores. By assigning each NF an individual flow or a small set of flows, it becomes possible to dynamically manage the QoS and service chain functionality for flows at a very fine granularity. Our Flurries prototype demonstrates the potential for this approach to run as many as 80,000 Flurry NFs during a one second interval, while forwarding over 30Gbps of traffic, dramatically increasing data plane customizability.},
booktitle = {Proceedings of the 12th International on Conference on Emerging Networking EXperiments and Technologies},
pages = {3–17},
numpages = {15},
keywords = {cloud computing, network function virtualization, resource management, scheduling},
location = {Irvine, California, USA},
series = {CoNEXT '16}
}

@inproceedings{10.1145/2691195.2691310,
author = {Sunkpho, Jirapon and Khaemasunun, Pravit and Tubtimhin, Jirapon},
title = {Thailand new ICT master plan to promote ICT innovations and services for e-ageing},
year = {2014},
isbn = {9781605586113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2691195.2691310},
doi = {10.1145/2691195.2691310},
abstract = {Thailand new ICT Master Plan is the 3rd episode of the country's ICT development plan to cover 2014 to 2018. Four key strategies are set forth to include building optimal infrastructure, nurturing vibrant business, be a smart government and capitalizing ICT human resources which emphasize to target to the level of community and local entity in terms of development benefits and gains. Ageing people is among prioritized community to pay attention to thus in the form of e-Ageing development since according to ILO expert, Thailand will become ageing society in full stream in less than 20 years from now.In building optimal infrastructure, highlighted projects such as Free WiFi and provisional internet service are eligible to cater certain ageing communities. In real terms, common devices and platforms to facilitate the elderly are to be encouraged for embracing their lives and works at a certain level of calibrated international standard. In an effort to drive relevant vibrant business, opportunities will rest upon e-Ageing products and services ranging from life-style to healthcare goods and solutions.As for the smart government strategy, smart public service to react to expectation of ageing group of consumers is to be paid of attention as well as promotion of innovated devices and applications made specifically to serve the special needs of the elderly. While at the same time the last ICT development strategy which addresses obviously over human capital development during the five year plan will pave a distinctive channel to accommodate the elderly to succeed ICT literacy for improving their quality of life and work extensively.Through the 5-year ICT master plan, Thailand aims high to drive the country toward "Digital Society" in a smart manner, defined in ICT2020 as "Smart Thailand". ICT enabled innovations and services for e-Ageing will be prevalent for transforming the country into an incumbent silver society in the next two decades. In an utmost mode of development, the country needs to adapt itself to avoid technological traps by adopting international standard as well as regional collaboration that Thailand already holds its stakes in ASEAN, APEC, IAC and etc.The authors of this paper attempted to conduct an analysis over "Ageing Society" which Thailand has been categorized to be transitional into the dilemma among the fast evolving countries. The analysis was limited to an ICT development aspect scanning through the latest version of the country ICT master plan, since ICT, as perceived in the digital society, is an enabling tool for improving quality of life of human kind to date.},
booktitle = {Proceedings of the 8th International Conference on Theory and Practice of Electronic Governance},
pages = {308–311},
numpages = {4},
keywords = {3rd Thailand ICT master plan, ICT2020, e-ageing, smart Thailand},
location = {Guimaraes, Portugal},
series = {ICEGOV '14}
}

@inproceedings{10.1109/ICSE.2017.36,
author = {Lee, Youn Kyu and Bang, Jae young and Safi, Gholamreza and Shahbazian, Arman and Zhao, Yixue and Medvidovic, Nenad},
title = {A SEALANT for inter-app security holes in android},
year = {2017},
isbn = {9781538638682},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE.2017.36},
doi = {10.1109/ICSE.2017.36},
abstract = {Android's communication model has a major security weakness: malicious apps can manipulate other apps into performing unintended operations and can steal end-user data, while appearing ordinary and harmless. This paper presents SEALANT, a technique that combines static analysis of app code, which infers vulnerable communication channels, with runtime monitoring of inter-app communication through those channels, which helps to prevent attacks. SEALANT's extensive evaluation demonstrates that (1) it detects and blocks inter-app attacks with high accuracy in a corpus of over 1,100 real-world apps, (2) it suffers from fewer false alarms than existing techniques in several representative scenarios, (3) its performance overhead is negligible, and (4) end-users do not find it challenging to adopt.},
booktitle = {Proceedings of the 39th International Conference on Software Engineering},
pages = {312–323},
numpages = {12},
location = {Buenos Aires, Argentina},
series = {ICSE '17}
}

@inproceedings{10.1145/3339252.3341481,
author = {Leander, Bj\"{o}rn and \v{C}au\v{s}evi\'{c}, Aida and Hansson, Hans},
title = {Applicability of the IEC 62443 standard in Industry 4.0 / IIoT},
year = {2019},
isbn = {9781450371643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3339252.3341481},
doi = {10.1145/3339252.3341481},
abstract = {Today's industrial automation systems are undergoing a digital transformation that implies a shift towards the Internet of Things (IoT), leading to the Industrial Internet of Things (IIoT) paradigm. Existing Industrial Automated Control Systems (IACS), enriched with a potentially large number of IoT devices are expected to make systems more efficient, flexible, provide intelligence, and ultimately enable autonomous control. In general, the majority of such systems come with high level of criticality that calls for well-established methods and approaches when achieving cybersecurity, preferably prescribed by a standard.IEC 62443 is an industrial standard that provides procedures to manage risks related to cybersecurity threats in IACS. Given the new IIoT paradigm, it is likely that existing standards are not sufficiently aligned with the challenges related to developing and maintaining cybersecurity in such systems. In this paper we review the applicability of the IEC 62443 standard in IIoT contexts and discuss potential challenges the process owners might encounter.Our analysis underlines that some areas within the standard could prove difficult to reach compliance with. In particular, handling of cross zone communication and software updates require additional guidance.},
booktitle = {Proceedings of the 14th International Conference on Availability, Reliability and Security},
articleno = {101},
numpages = {8},
location = {Canterbury, CA, United Kingdom},
series = {ARES '19}
}

@article{10.1145/3463340,
author = {Akdur, Deniz},
title = {Skills Gaps in the Industry: Opinions of Embedded Software Practitioners},
year = {2021},
issue_date = {September 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {5},
issn = {1539-9087},
url = {https://doi.org/10.1145/3463340},
doi = {10.1145/3463340},
abstract = {Many practitioners in the software-intensive embedded industry often face difficulties after beginning their careers due to misalignment of the skills learned at the university with what is required in the workplace. Companies spend crucial resources to train personnel whose academic backgrounds are not only based on “computing disciplines” but also on non-computing ones. Analyzing the gap between the software industry and academia is important for three reasons: (1) for employers, hiring properly trained practitioners allows them to spend less time in training them while incorporating them more efficiently into the workforce; (2) for practitioners, knowing the most important skillset is helpful to increase their chance of employability; and (3) for academia, understanding the necessary skillset is critical to making curriculum changes. To achieve these objectives, we conducted a survey that yielded responses from 659 software professionals working worldwide in different roles. In this study, we only included the responses of 393 embedded software practitioners whose undergraduate degree was completed in Turkey, working in 10 countries. This article sheds light on the most important skills in the embedded software industry by presenting various cross-factor analyses. Understanding the coverage of these skills in the curriculum (mostly in Turkish universities) helps bridge the gaps, which can and should be achieved through more Industry Academia Collaborations (IACs).},
journal = {ACM Trans. Embed. Comput. Syst.},
month = jul,
articleno = {43},
numpages = {39},
keywords = {software engineering education, soft skills, practitioner survey, industry academia collaboration, embedded software industry, Hard skills}
}

@inproceedings{10.1145/3386415.3387033,
author = {Hu, Yingxin and Zhang, Jie and Lan, Zheng and Zeng, Jinhui},
title = {A Brief Overview of The Status and Prospects of Railway Static Power Conditioner},
year = {2020},
isbn = {9781450372930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3386415.3387033},
doi = {10.1145/3386415.3387033},
abstract = {The electrified railway static power conditioner not only has the ability to control the two-phase active power, reactive power and harmonic current of the traction substation and the basic functions of reducing the negative sequence but also can complete the active power fusion of the traction power supply arm on both sides, which can significantly improve the power quality of the railway traction power supply network is widely used in railway traction power supply systems. The research background, common topology, compensation principle and typical control strategy of railway power regulator are reviewed. The topology of the railway power conditioner is explained from the single-module and modular multi-level topologies, and it is considered that the new power electronics topology, advanced control strategy, soft switching technology, high-power application, and power electronic integrated system Stability, etc. will be the future research direction of railway power regulators.},
booktitle = {Proceedings of the 2nd International Conference on Information Technologies and Electrical Engineering},
articleno = {86},
numpages = {6},
keywords = {Traction substation, Reactive power, Railway static power conditioner, Harmonic, Active power},
location = {Zhuzhou, Hunan, China},
series = {ICITEE '19}
}

@inproceedings{10.1145/3387940.3392161,
author = {Zhou, Jiahong and Chen, Wei and Liu, Chang and Zhu, Jiaxin and Wu, Guoquan and Wei, Jun},
title = {DockerKG: A Knowledge Graph of Docker Artifacts},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3392161},
doi = {10.1145/3387940.3392161},
abstract = {Docker helps developers reuse software artifacts by providing a lightweight solution to the problem of operating system virtualization. A Docker image contains very rich and useful knowledge of software engineering, including the source of software packages, the correlations among software packages, the installation methods of software packages and the information on operating systems. To effectively obtain this knowledge, this paper proposes an approach to constructing a knowledge graph of Docker artifacts, named DockerKG, by analyzing a large number of Dockerfiles in Docker Hub, which contains more than 3.08 million Docker repositories (up to February 2020). Currently, DockerKG contains the domain knowledge extracted from approximately 200 thousand Dockerfiles in Docker Hub. Besides, it contains the information on Docker repositories and their semantic tags. In future work, DockerKG can be used for Docker image recommendations and online Q&amp;A service providing software engineering domain knowledge.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {367–372},
numpages = {6},
keywords = {software package, knowledge graph, Dockerfile, Docker},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@article{10.1145/2568195.2568214,
author = {Endicott-Popovsky, Barbara E. and Popovsky, Viatcheslav M.},
title = {Application of pedagogical fundamentals for the holistic development of cybersecurity professionals},
year = {2014},
issue_date = {March 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
issn = {2153-2184},
url = {https://doi.org/10.1145/2568195.2568214},
doi = {10.1145/2568195.2568214},
abstract = {Nowhere is the problem of lack of human capital more keenly felt than in the field of cybersecurity where the numbers and quality of well-trained graduates are woefully lacking [10]. In 2005, the National Academy of Sciences indicted the US education system as the culprit contributing to deficiencies in our technical workforce, sounding the alarm that we are at risk of losing our competitive edge [14]. While the government has made cybersecurity education a national priority, seeking to stimulate university and community college production of information assurance (IA) expertise, they still have thousands of IA jobs going unfilled. The big question for the last decade [17] has been 'where will we find the talent we need?' In this article, we describe one university's approach to begin addressing this problem and discuss an innovative curricular model that holistically develops future cybersecurity professionals.},
journal = {ACM Inroads},
month = mar,
pages = {57–68},
numpages = {12},
keywords = {pedagogy, education and workforce development, cybersecurity}
}

@article{10.1145/2536811,
author = {Caramiaux, B. and Bevilacqua, F. and Bianco, T. and Schnell, N. and Houix, O. and Susini, P.},
title = {The Role of Sound Source Perception in Gestural Sound Description},
year = {2014},
issue_date = {April 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {1},
issn = {1544-3558},
url = {https://doi.org/10.1145/2536811},
doi = {10.1145/2536811},
abstract = {We investigated gesture description of sound stimuli performed during a listening task. Our hypothesis is that the strategies in gestural responses depend on the level of identification of the sound source and specifically on the identification of the action causing the sound. To validate our hypothesis, we conducted two experiments. In the first experiment, we built two corpora of sounds. The first corpus contains sounds with identifiable causal actions. The second contains sounds for which no causal actions could be identified. These corpora properties were validated through a listening test. In the second experiment, participants performed arm and hand gestures synchronously while listening to sounds taken from these corpora. Afterward, we conducted interviews asking participants to verbalize their experience while watching their own video recordings. They were questioned on their perception of the listened sounds and on their gestural strategies. We showed that for the sounds where causal action can be identified, participants mainly mimic the action that has produced the sound. In the other case, when no action can be associated with the sound, participants trace contours related to sound acoustic features. We also found that the interparticipants’ gesture variability is higher for causal sounds compared to noncausal sounds. Variability demonstrates that, in the first case, participants have several ways of producing the same action, whereas in the second case, the sound features tend to make the gesture responses consistent.},
journal = {ACM Trans. Appl. Percept.},
month = apr,
articleno = {1},
numpages = {19},
keywords = {sound tracing, sound source identification, sound mimicry, environmental sound perception, embodied cognition, cross-modal relationships, Gesture}
}

@article{10.14778/2809974.2809975,
author = {K\"{o}hler, Henning and Link, Sebastian and Zhou, Xiaofang},
title = {Possible and certain SQL keys},
year = {2015},
issue_date = {July 2015},
publisher = {VLDB Endowment},
volume = {8},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/2809974.2809975},
doi = {10.14778/2809974.2809975},
abstract = {Driven by the dominance of the relational model, the requirements of modern applications, and the veracity of data, we revisit the fundamental notion of a key in relational databases with NULLs. In SQL database systems primary key columns are NOT NULL by default. NULL columns may occur in unique constraints which only guarantee uniqueness for tuples which do not feature null markers in any of the columns involved, and therefore serve a different function than primary keys. We investigate the notions of possible and certain keys, which are keys that hold in some or all possible worlds that can originate from an SQL table, respectively. Possible keys coincide with the unique constraint of SQL, and thus provide a semantics for their syntactic definition in the SQL standard. Certain keys extend primary keys to include NULL columns, and thus form a sufficient and necessary condition to identify tuples uniquely, while primary keys are only sufficient for that purpose. In addition to basic characterization, axiomatization, and simple discovery approaches for possible and certain keys, we investigate the existence and construction of Armstrong tables, and describe an indexing scheme for enforcing certain keys. Our experiments show that certain keys with NULLs do occur in real-world databases, and that related computational problems can be solved efficiently. Certain keys are therefore semantically well-founded and able to maintain data quality in the form of Codd's entity integrity rule while handling the requirements of modern applications, that is, higher volumes of incomplete data from different formats.},
journal = {Proc. VLDB Endow.},
month = jul,
pages = {1118–1129},
numpages = {12}
}

@article{10.1145/265665.265679,
author = {van der Rijst, Nardo B. J.},
title = {Communication oriented organizational modeling},
year = {1997},
issue_date = {Aug. 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {2372-7403},
url = {https://doi.org/10.1145/265665.265679},
doi = {10.1145/265665.265679},
abstract = {Modeling of organizations currently has a strong focus on the business process. In contrast to e.g. data modeling, process modeling tries to provide a clear understanding of the whole business process without giving attention to the current organizational structure. Not only because of efforts in the area of total quality management, continuous improvement and business process engineering, it is possible to observe this shift. More important are developments in the direction of new organizational forms (i.e. networked organizations) and hence the coordination of activities.In this paper the DEMO modeling approach is presented. The approach entails a framework with several models incorporated in a methodology. Primary aim of the method is to provide insight in the business process, combining the notions of action, information and communication.The DEMO approach is founded in the Language Action Perspective (Winograd and Flores, 1986). This view on organizations strongly opposes the mechanical way in which many information system analysis and development methods approach organizations. Important insights from the original impetus by Flores and Ludlow (1980) stimulated many research groups around the world to incorporate the Speech Act theory (Searle, 1969) in their methods and tools.The methodology DEMO (Dynamic Essential Modeling nf Organizations) has been described and reported upon several times (Dietz, 1992; 1994a; 1994b). Its practical value has been demonstrated for a few small scale application domains like in (van der Rijst and Dietz, 1993; van Reijswoud and van der Rijst, 1995), and recently in a large scale project (Jansen and Poot, 1996) as well.The major motivation behind the development of DEMO was the strongly felt need for information systems analysts to have a theory about organizations (and, by way of analogy, about discrete dynamic systems in general) that is only and purely based on the role of information, taken in a very general sense. Having such a theory at one's disposal would make it possible to understand organizations in a new and original way.The theory would be independent of other theories, in particular the economic theories about organizations, like the Value Chain Theory (Porter, 1985), or the Transaction Cost Theory (1985). It would have its own value and just be complementary to those other theories. Because of this property, DEMO is most valuable for providing an original informatical contribution to Business Process Redesign and Reengineering, next to and in harmony with contributions from other disciplines, e.g. the economically founded discipline of business administration. The core concepts are discussed in the next sections.},
journal = {SIGGROUP Bull.},
month = aug,
pages = {48–52},
numpages = {5}
}

@INPROCEEDINGS{8367077,
  author={Rahman, Akond},
  booktitle={2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)}, 
  title={Anti-Patterns in Infrastructure as Code}, 
  year={2018},
  volume={},
  number={},
  pages={434-435},
  abstract={In DevOps, infrastructure as code (IaC) scripts are used by practitioners to create and manage an automated deployment pipeline that enables IT organizations to release their software changes rapidly at scale. Low quality IaC scripts can have serious consequences, potentially leading to wide-spread system outages and service discrepancies. The goal of this research is to help practitioners increase the quality of infrastructure as code (IaC) scripts by identifying anti-patterns in IaC scripts and development of IaC scripts. Using open source repositories, we conduct three initial studies to (i) quantify the frequency and categorize the defects in IaC scripts; and (ii) identify operations that characterize defective IaC scripts. Based on our empirical analysis we observe (i) the dominant defect defect categories to be related to syntax and configuration assignments, and (ii) three operations that characterize defective IaC scripts. The above-mentioned findings motivate us to identify anti-patterns in IaC scripts and IaC development. To this end, we propose three studies that identify (i) process anti-patterns; and (ii) security-related anti-patterns in IaC.},
  keywords={Software;Security;Organizations;Tools;Feature extraction;Predictive models;Syntactics;anti pattern;continuous deployment;devops;infrastructure as code;configuration as code;puppet;defect},
  doi={10.1109/ICST.2018.00057},
  ISSN={},
  month={April},}@INPROCEEDINGS{9284113,
  author={Rahman, Akond and Farhana, Effat and Parnin, Chris and Williams, Laurie},
  booktitle={2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)}, 
  title={Gang of Eight: A Defect Taxonomy for Infrastructure as Code Scripts}, 
  year={2020},
  volume={},
  number={},
  pages={752-764},
  abstract={Defects in infrastructure as code (IaC) scripts can have serious consequences, for example, creating large-scale system outages. A taxonomy of IaC defects can be useful for understanding the nature of defects, and identifying activities needed to fix and prevent defects in IaC scripts. The goal of this paper is to help practitioners improve the quality of infrastructure as code (IaC) scripts by developing a defect taxonomy for IaC scripts through qualitative analysis. We develop a taxonomy of IaC defects by applying qualitative analysis on 1,448 defect-related commits collected from open source software (OSS) repositories of the Openstack organization. We conduct a survey with 66 practitioners to assess if they agree with the identified defect categories included in our taxonomy. We quantify the frequency of identified defect categories by analyzing 80,425 commits collected from 291 OSS repositories spanning across 2005 to 2019. Our defect taxonomy for IaC consists of eight categories, including a category specific to IaC called idempotency (i.e., defects that lead to incorrect system provisioning when the same IaC script is executed multiple times). We observe the surveyed 66 practitioners to agree most with idempotency. The most frequent defect category is configuration data i.e., providing erroneous configuration data in IaC scripts. Our taxonomy and the quantified frequency of the defect categories may help in advancing the science of IaC script quality.},
  keywords={Time-frequency analysis;Taxonomy;Organizations;Tools;Large-scale systems;Open source software;Software engineering;bug;category;configuration as code;configuration scripts;defect;devops;infrastructure as code;puppet;software quality;taxonomy},
  doi={10.1145/3377811.3380409},
  ISSN={1558-1225},
  month={Oct},}@INPROCEEDINGS{10910699,
  author={Saxena, Adarsh and Singh, Sudhakar and Prakash, Shiv and Yang, Tiansheng and Rathore, Rajkumar Singh},
  booktitle={2024 IEEE Silchar Subsection Conference (SILCON 2024)}, 
  title={DevOps Automation Pipeline Deployment with IaC (Infrastructure as Code)}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={DevOps pipeline is a set of automated tasks or processes or jobs that has tasks assigned to execute automatically that allow the Development team and Operations team to collaborate for building and deployment of the software or services. DevOps as a culture includes better collaboration between different teams within an organization and the removal of silos between them. This paper aims to streamline the current software development and deployment process that is being followed in most of today”s generation DevOps deployment as Continuous Integration and Continuous Delivery (CI/CD) pipelines. Centered to the level of software development life cycle (SDLC), it also describes the current ambiguous definition to clarify the implementation of DevOps in practice along a sample CI/CD pipeline deployment. The further objective of the paper is to demonstrate the implementation strategy of DevOps Infrastructure as Code (IaC) and Pipeline as a code and the removal of ambiguity in the definition of DevOps Infrastructure as a Code methodology.},
  keywords={DevOps;Codes;Automation;Pipelines;Buildings;Collaboration;Organizations;Continuous integration;Software;DevOps;CI/CD Pipeline;Continuous Integration;Continuous Delivery;SDLC},
  doi={10.1109/SILCON63976.2024.10910699},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10092598,
  author={Sokolowski, Daniel and Salvaneschi, Guido},
  booktitle={2023 IEEE 20th International Conference on Software Architecture Companion (ICSA-C)}, 
  title={Towards Reliable Infrastructure as Code}, 
  year={2023},
  volume={},
  number={},
  pages={318-321},
  abstract={Modern Infrastructure as Code (IaC) programs are increasingly complex and much closer to traditional software than to simple configuration scripts. Their reliability is crucial because their failure prevents the deployment of applications, and incorrect behavior can introduce malfunction and severe security issues. Yet, software engineering tools to develop reliable programs, such as testing and verification, are barely used in IaC. In fact, we observed that developers mainly rely on integration testing, a slow and expensive practice that can increase confidence in end-to-end functionality but is infeasible to systematically test IaC programs in various configurations—which is required to ensure robustness. On the other hand, fast testing techniques, such as unit testing, are cumbersome with IaC programs because, today, they require significant coding overhead while only providing limited confidence.To solve this issue, we envision the automated testing tool ProTI, reducing the manual overhead and boosting confidence in the test results. ProTI embraces modern unit testing techniques to test IaC programs in many different configurations. Out of the box, ProTI is a fuzzer for Pulumi TypeScript IaC programs, randomly testing the program in many different configurations for termination, configuration correctness, and existing policy compliance. Then developers can add specifications to their program to guide random-based value generation, test additional properties, and add further mocking, making ProTI a property-based testing tool. Lastly, we aim at automatically verifying IaC-specific properties, e.g., access paths between resources.},
  keywords={Codes;Software architecture;Writing;Reliability engineering;Market research;Software;Robustness;Infrastructure as Code;Cloud Engineering;Fuzzing;Property-based Testing;Verification},
  doi={10.1109/ICSA-C57050.2023.00072},
  ISSN={2768-4288},
  month={March},}@INPROCEEDINGS{8449631,
  author={Rahman, Akond},
  booktitle={2018 IEEE/ACM 40th International Conference on Software Engineering: Companion (ICSE-Companion)}, 
  title={Characteristics of Defective Infrastructure as Code Scripts in DevOps}, 
  year={2018},
  volume={},
  number={},
  pages={476-479},
  abstract={Defects in infrastructure as code (IaC) scripts can have serious consequences for organizations who adopt DevOps. By identifying which characteristics of IaC scripts correlate with defects, we can identify anti-patterns, and help software practitioners make informed decisions on better development and maintenance of IaC scripts, and increase quality of IaC scripts. The goal of this paper is to help practitioners increase the quality of IaC scripts by identifying characteristics of IaC scripts and IaC development process that correlate with defects, and violate security and privacy objectives. We focus on characteristics of IaC scripts and IaC development that (i) correlate with IaC defects, and (ii) violate security and privacy-related objectives namely, confidentiality, availability, and integrity. For our initial studies, we mined open source version control systems from three organizations: Mozilla, Openstack, and Wikimedia, to identify the defect-related characteristics and conduct our case studies. From our empirical analysis, we identify (i) 14 IaC code and four churn characteristics that correlate with defects; and (ii) 12 process characteristics such as, frequency of changes, and ownership of IaC scripts that correlate with defects. We propose the following studies: (i) identify structural characteristics that correlate with defects; (ii) with respect to prediction performance, compare which characteristics of IaC scripts are more correlated with defects; and (iii) identify characteristics that violate security and privacy objectives.},
  keywords={Software;Organizations;Security;Measurement;Privacy;Predictive models;Tools;defect;devops;infrastructure as code;metric},
  doi={},
  ISSN={2574-1934},
  month={May},}@INPROCEEDINGS{10479426,
  author={Suwanachote, Nabhan and Pornmaneerattanatri, Soratouch and Kashiwa, Yutaro and Ichikawa, Kohei and Leelaprute, Pattara and Rungsawang, Arnon and Manaskasemsak, Bundit and Iida, Hajimu},
  booktitle={2023 30th Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={A Pilot Study of Testing Infrastructure as Code for Cloud Systems}, 
  year={2023},
  volume={},
  number={},
  pages={584-588},
  abstract={Infrastructure as Code (IaC) has become the de-facto standard method for managing cloud resources. Just like general source code (e.g., Java, etc.), infrastructure code also has numerous bugs so it needs to be tested. While several testing frameworks for IaC for cloud systems have been developed in practice, researchers have paid little attention to their testing. This study presents an empirical investigation of the use of tests for IaC for cloud systems. Our empirical results show that (i) 55.2% of the repositories using Terratest have at least one server infrastructure test; (ii) developers often maintain server infrastructure tests (1.7%-11.3% commits out of all the commits); (iii) many repositories have tests for system functionality (28%), deployment (20%), and configuration (17%).},
  keywords={Java;Codes;Source coding;Computer bugs;Servers;Standards;Testing;Infrastructure as Code;Software Testing;Cloud System},
  doi={10.1109/APSEC60848.2023.00075},
  ISSN={2640-0715},
  month={Dec},}@INPROCEEDINGS{8449603,
  author={Rahman, Akond and Stallings, Jonathan and Williams, Laurie},
  booktitle={2018 IEEE/ACM 40th International Conference on Software Engineering: Companion (ICSE-Companion)}, 
  title={Poster: Defect Prediction Metrics for Infrastructure as Code Scripts in DevOps}, 
  year={2018},
  volume={},
  number={},
  pages={414-415},
  abstract={Use of infrastructure as code (IaC) scripts helps software teams manage their configuration and infrastructure automatically. Information technology (IT) organizations use IaC scripts to create and manage automated deployment pipelines to deliver services rapidly. IaC scripts can be defective, resulting in dire consequences, such as creating wide-scale service outages for end-users. Prediction of defective IaC scripts can help teams to mitigate defects in these scripts by prioritizing their inspection efforts. The goal of this paper is to help software practitioners in prioritizing their inspection efforts for infrastructure as code (IaC) scripts by proposing defect prediction model-related metrics. IaC scripts use domain specific languages (DSL) that are fundamentally different from object-oriented programming (OOP) languages. Hence, the OOP-based metrics that researchers used in defect prediction might not be applicable for IaC scripts. We apply Constructivist Grounded Theory (CGT) on defect-related commits mined from version control systems to identify metrics suitable for IaC scripts. By applying CGT, we identify 18 metrics. Of these metrics, 13 are related to IaC, for example, count of string occurrences in a script. Four of the identified metrics are related to churn, and one metric is lines of code.},
  keywords={Measurement;Software;Organizations;Syntactics;Inspection;Software engineering;Predictive models;Continuous Deployment;DevOps;Infrastructure as Code;Metrics},
  doi={},
  ISSN={2574-1934},
  month={May},}@INPROCEEDINGS{9983681,
  author={Petrović, Nenad and Cankar, Matija and Luzar, Anže},
  booktitle={2022 30th Telecommunications Forum (TELFOR)}, 
  title={Automated Approach to IaC Code Inspection Using Python-Based DevSecOps Tool}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={One of main benefits enabled by DevOps ideology is to automatize activities and operations related to development, testing, integration and deployment of software, to fulfill the needs of relevant organization’s goals. On the other side, quality of code, security, together with compliance according to given standards represent highly relevant considerations. In this paper, we present an open-source Python-based tool with web-based graphical interface which enables automation of static code analysis and checks when it comes to Infrastructure as Code (IaC) scripts. The proposed tool is evaluated in several scenarios when it comes to terraform scripts.},
  keywords={Codes;Automation;Manuals;Machine learning;Inspection;Software;Telecommunications;DevOps;DevSecOps;IaC;Python},
  doi={10.1109/TELFOR56187.2022.9983681},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10671452,
  author={Zeini, Ammar and Lennon, Ruth G. and Lennon, Patrick},
  booktitle={2023 Cyber Research Conference - Ireland (Cyber-RCI)}, 
  title={Securing Infrastructure as Code (IaC) through DevSecOps:A Comprehensive Risk Management Framework}, 
  year={2023},
  volume={},
  number={},
  pages={1-11},
  abstract={Despite the evident advantages of Infrastructure as Code (IaC) in software development, the nature of bugs and potential threats arising from its implementation remains subject to ongoing investigation. The formulation of a list, enumerating potential threats during the IaC process remains an unattained goal. However, it is not enough to recounting IaC threats only, it is imperative for Development (Dev), Security (Sec), and Operations (Ops) teams to synergistically collaborate from early developmental stages to conduct thorough risks’ analysis, estimation, and mitigation procedures concerning IaC-related risks. Moreover, adhering to security standards and risk management framework throughout the IaC lifecycle will enhance the overall security of the deployment process. A risk management framework for IaC is essential. The extant risk management and threat modeling methodologies may necessitate tailoring to effectively protect the Software Development Lifecycle (SDLC) from IaC misuse. This research aims to identify threats that threaten IaC lifecycle or arise from the utilization of IaC. In addition, it tries to integrate IaC practices with the DevSecOps culture to devise a robust risk management framework and prescribe pertinent practices conducive to fostering secure IaC implementation.},
  keywords={Threat modeling;Codes;Prevention and mitigation;Computer bugs;Estimation;Risk management;Security;Infrastructure as Code;DevSecOps;Risk Management framework;Secure Deployment},
  doi={10.1109/Cyber-RCI59474.2023.10671452},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8812041,
  author={Rahman, Akond and Parnin, Chris and Williams, Laurie},
  booktitle={2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)}, 
  title={The Seven Sins: Security Smells in Infrastructure as Code Scripts}, 
  year={2019},
  volume={},
  number={},
  pages={164-175},
  abstract={Practitioners use infrastructure as code (IaC) scripts to provision servers and development environments. While developing IaC scripts, practitioners may inadvertently introduce security smells. Security smells are recurring coding patterns that are indicative of security weakness and can potentially lead to security breaches. The goal of this paper is to help practitioners avoid insecure coding practices while developing infrastructure as code (IaC) scripts through an empirical study of security smells in IaC scripts. We apply qualitative analysis on 1,726 IaC scripts to identify seven security smells. Next, we implement and validate a static analysis tool called Security Linter for Infrastructure as Code scripts (SLIC) to identify the occurrence of each smell in 15,232 IaC scripts collected from 293 open source repositories. We identify 21,201 occurrences of security smells that include 1,326 occurrences of hard-coded passwords. We submitted bug reports for 1,000 randomly-selected security smell occurrences. We obtain 212 responses to these bug reports, of which 148 occurrences were accepted by the development teams to be fixed. We observe security smells can have a long lifetime, e.g., a hard-coded secret can persist for as long as 98 months, with a median lifetime of 20 months.},
  keywords={Password;Encoding;Tools;Software;Servers;Static analysis;devops, devsecops, empirical study, infrastructure as code, puppet, security, smell, static analysis},
  doi={10.1109/ICSE.2019.00033},
  ISSN={1558-1225},
  month={May},}@INPROCEEDINGS{9779848,
  author={Chiari, Michele and De Pascalis, Michele and Pradella, Matteo},
  booktitle={2022 IEEE 19th International Conference on Software Architecture Companion (ICSA-C)}, 
  title={Static Analysis of Infrastructure as Code: a Survey}, 
  year={2022},
  volume={},
  number={},
  pages={218-225},
  abstract={The increasing use of Infrastructure as Code (IaC) in DevOps leads to benefits in speed and reliability of deployment operation, but extends to infrastructure challenges typical of software systems. IaC scripts can contain defects that result in security and reliability issues in the deployed infrastructure: techniques for detecting and preventing them are needed. We analyze and survey the current state of research in this respect by conducting a literature review on static analysis techniques for IaC. We describe analysis techniques, defect categories and platforms targeted by tools in the literature.},
  keywords={Codes;Software architecture;Conferences;Bibliographies;Static analysis;Software systems;Software reliability;infrastructure as code;cloud computing;static analysis;model checking;verification;survey},
  doi={10.1109/ICSA-C54293.2022.00049},
  ISSN={2768-4288},
  month={March},}@INPROCEEDINGS{10174011,
  author={Opdebeeck, Ruben and Zerouali, Ahmed and De Roover, Coen},
  booktitle={2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)}, 
  title={Control and Data Flow in Security Smell Detection for Infrastructure as Code: Is It Worth the Effort?}, 
  year={2023},
  volume={},
  number={},
  pages={534-545},
  abstract={Infrastructure as Code is the practice of developing and maintaining computing infrastructure through executable source code. Unfortunately, IaC has also brought about new cyber attack vectors. Prior work has therefore proposed static analyses that detect security smells in Infrastructure as Code files. However, they have so far remained at a shallow level, disregarding the control and data flow of the scripts under analysis, and may lack awareness of specific syntactic constructs. These limitations inhibit the quality of their results. To address these limitations, in this paper, we present GASEL, a novel security smell detector for the Ansible IaC language. It uses graph queries on program dependence graphs to detect 7 security smells. Our evaluation on an oracle of 243 real-world security smells and comparison against two state-of-the-art security smell detectors shows that awareness of syntax, control flow, and data flow enables our approach to substantially improve both precision and recall. We further question whether the additional effort required to develop and run such an approach is justified in practice. To this end, we investigate the prevalence of indirection through control and data flow in security smells across more than 15 000 Ansible scripts. We find that over 55% of security smells contain data-flow indirection, and over 32% require a whole-project analysis to detect. These findings motivate the need for deeper static analysis tools to detect security vulnerabilities in IaC.},
  keywords={Codes;Source coding;Detectors;Static analysis;Syntactics;Software;Security;Infrastructure as Code;Ansible;code smells;security;program dependence graph;empirical study},
  doi={10.1109/MSR59073.2023.00079},
  ISSN={2574-3864},
  month={May},}@INPROCEEDINGS{10653392,
  author={Diaz-de-Arcaya, Josu and López-de-Armentia, Juan and Zárate, Gorka and Torre-Bastida, Ana I.},
  booktitle={2024 IEEE/ACM International Workshop on Automated Program Repair (APR)}, 
  title={Towards the Self-Healing of Infrastructure as Code Projects Using Constrained LLM Technologies}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={The generalization of the use of cloud computing and edge computing solutions in industry requires innovative techniques to keep up with the complexity of these scenarios. In particular, the large heterogeneity of the infrastructural devices and the myriad of services offered by the various private and cloud providers represent a challenge. Infrastructure as Code (IaC) technologies have been adopted to reduce the complexity of these scenarios, but even IaC technologies have their drawbacks, as the errors resulting from their use often combine the complexities of the underlying layers and require a high level of expertise. In this regard, the recent upsurge of Large Language Models represents an opportunity as they are able to tackle different problems. In this article, we aspire to shed light on the automated patching of IaC projects with the help of LLMs. We evaluate the suitability of this hypothesis by using a well-known LLM that is able to solve all the scenarios we envisioned and assess the possibility of doing the same with smaller, offline LLMs, which could lead to the use of these technologies in resource-constrained environments, such as edge computing.},
  keywords={Industries;Cloud computing;Codes;Large language models;Conferences;Computational modeling;Maintenance engineering;Information systems → Computing platforms;• Applied computing → IT architectures;Decision analysis.;Infrastructure as Code;IaC;Large Language Models;LLMs;self-healing;automated patching},
  doi={10.1145/3643788.3648014},
  ISSN={},
  month={April},}@ARTICLE{10516612,
  author={Sokolowski, Daniel and Spielmann, David and Salvaneschi, Guido},
  journal={IEEE Transactions on Software Engineering}, 
  title={Automated Infrastructure as Code Program Testing}, 
  year={2024},
  volume={50},
  number={6},
  pages={1585-1599},
  abstract={Infrastructure as Code (IaC) enables efficient deployment and operation, which are crucial to releasing software quickly. As setups can be complex, developers implement IaC programs in general-purpose programming languages like TypeScript and Python, using PL-IaC solutions like Pulumi and AWS CDK. The reliability of such IaC programs is even more relevant than in traditional software because a bug in IaC impacts the whole system. Yet, even though testing is a standard development practice, it is rarely used for IaC programs. For instance, in August 2022, less than 1 % of the public Pulumi IaC programs on GitHub implemented tests. Available IaC program testing techniques severely limit the development velocity or require much development effort. To solve these issues, we propose Automated Configuration Testing (ACT), a methodology to test IaC programs in many configurations quickly and with low effort. ACT automatically mocks all resource definitions in the IaC program and uses generator and oracle plugins for test generation and validation. We implement ACT in ProTI, a testing tool for Pulumi TypeScript with a type-based generator and oracle, and support for application specifications. Our evaluation with 6 081 programs from GitHub and artificial benchmarks shows that ProTI can directly be applied to existing IaC programs, quickly finds bugs where current techniques are infeasible, and enables reusing existing generators and oracles thanks to its pluggable architecture.},
  keywords={Testing;Generators;Software;Cloud computing;Engines;Codes;Libraries;Property-based testing;fuzzing;infrastructure as code;DevOps},
  doi={10.1109/TSE.2024.3393070},
  ISSN={1939-3520},
  month={June},}@INPROCEEDINGS{11126823,
  author={Vo, Quoc-Huy and Dao, Ha and Fukuda, Kensuke},
  booktitle={2025 IEEE 49th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Harnessing the Power of LLMs for Code Smell Detection in Terraform Infrastructure as Code}, 
  year={2025},
  volume={},
  number={},
  pages={533-542},
  abstract={Terraform is a widely used Infrastructure as Code (IaC) tool that simplifies cloud resource management through declarative configuration. However, Terraform configurations often exhibit code smells, which can introduce security vulnerabilities, maintainability challenges, and operational inefficiencies. While code smells have been extensively studied in other IaC platforms, research on Terraform remains limited, and existing static analysis tools struggle to detect a broad range of code smells. In this paper, we harness large language models (LLMs) for automated Terraform code smell detection, leveraging their ability to generalize beyond predefined rule-based heuristics. We construct a synthetic benchmark dataset of 42 Terraform configurations covering 14 distinct code smells and evaluate detection performance across traditional linters and LLM-based approaches. Our results show that LLMs significantly outperform static analysis tools, detecting a broader range of code smells, especially logic-related code smells. We extend our analysis to real-world repositories with 71 high-quality Terraform projects from GitHub. Our findings reveal that 84.5% of repositories contain at least one code smell. Notably, some repositories accumulate a high number of unique code smells, with one exhibiting nine distinct issues, underscoring severe quality concerns. Moreover, we find that code smells persist across repositories regardless of popularity, affecting even widely used projects with thousands of stars and forks.},
  keywords={Codes;Large language models;Prevention and mitigation;Stars;Static analysis;Software;Security;Resource management;Synthetic data;Software development management;IaC;code smell;LLM},
  doi={10.1109/COMPSAC65507.2025.00075},
  ISSN={2836-3795},
  month={July},}@ARTICLE{9321740,
  author={Dalla Palma, Stefano and Di Nucci, Dario and Palomba, Fabio and Tamburri, Damian A.},
  journal={IEEE Transactions on Software Engineering}, 
  title={Within-Project Defect Prediction of Infrastructure-as-Code Using Product and Process Metrics}, 
  year={2022},
  volume={48},
  number={6},
  pages={2086-2104},
  abstract={Infrastructure-as-code (IaC) is the DevOps practice enabling management and provisioning of infrastructure through the definition of machine-readable files, hereinafter referred to as IaC scripts. Similarly to other source code artefacts, these files may contain defects that can preclude their correct functioning. In this paper, we aim at assessing the role of product and process metrics when predicting defective IaC scripts. We propose a fully integrated machine-learning framework for IaC Defect Prediction, that allows for repository crawling, metrics collection, model building, and evaluation. To evaluate it, we analyzed 104 projects and employed five machine-learning classifiers to compare their performance in flagging suspicious defective IaC scripts. The key results of the study report Random Forest as the best-performing model, with a median AUC-PR of 0.93 and MCC of 0.80. Furthermore, at least for the collected projects, product metrics identify defective IaC scripts more accurately than process metrics. Our findings put a baseline for investigating IaC Defect Prediction and the relationship between the product and process metrics, and IaC scripts’ quality.},
  keywords={Measurement;Software;Predictive models;Machine learning;Radon;Cloud computing;Task analysis;Infrastructure-as-code;defect prediction;empirical software engineering},
  doi={10.1109/TSE.2021.3051492},
  ISSN={1939-3520},
  month={June},}@INPROCEEDINGS{10425162,
  author={Bali, Milandeep Kour and Walia, Ranjan},
  booktitle={2023 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS)}, 
  title={Enhancing Efficiency Through Infrastructure Automation: An In-Depth Analysis of Infrastructure as Code (IaC) Tools}, 
  year={2023},
  volume={},
  number={},
  pages={857-863},
  abstract={Due to the increasing demand for efficient management and provisioning of infrastructure resources, Infrastructure as Code (IaC) tools have become indispensable in modern IT environments. Ensuring the scalability of these tools is crucial for accommodating organizations changing requirements and maintaining their effectiveness. Our investigation delves into the visualization of IaC tool scalability and reliability, illustrated by a line chart. On the x-axis, each tool is depicted, with scalability ratings or metrics plotted on the y-axis. IaC tools can be easily compared and evaluated for scalability with the aid of this chart. It provides valuable insight for organizations looking to make informed decisions about selecting the most appropriate tool based on their specific infrastructure needs and growth potential. The chart summarizes and compares key scalability features, making it easier to identify the best tool for meeting performance expectations.},
  keywords={Measurement;Visualization;Codes;Scalability;Organizations;Reliability;Intelligent systems;IaC;APL AWS;Azure;Terraform;Cloud Computing;DevOps},
  doi={10.1109/ICCCIS60361.2023.10425162},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9457903,
  author={Akasaka, Kohei and Nakamura, Akihito},
  booktitle={2020 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Reproducible Software Vulnerability Testing with IaC}, 
  year={2020},
  volume={},
  number={},
  pages={36-42},
  abstract={Cybersecurity is more important now than ever. Attackers maliciously use vulnerabilities to exploit IT systems. Software developers are responsible for fixing the reported vulnerabilities in their own products, while system administrators should assess the impacts of attacks against their working systems. However, they are wasting time to make the problem appear because provisioning is a complex and troublesome process. This paper presents a model of vulnerability testing and our original system which enables efficient and automatic reproduction of the vulnerable environments and replicable execution of attacks. We utilize the Infrastructure as Code (IaC) principle. Vulnerability testing is represented as code and the system automates the process of provisioning vulnerable environments and executing attacks through machine-readable definitions, rather than manual configuration and execution. A simple human-readable YAML language is used for writing testing definitions. If the definitions are maintained in publicly accessible repositories, security experts have a chance to contribute their knowledge and expertise to the community and an open-source style ecosystem may be created.},
  keywords={Scientific computing;Ecosystems;Manuals;Writing;Metadata;Computer security;Open source software;cyberattack;vulnerability;security testing},
  doi={10.1109/CSCI51800.2020.00013},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8367034,
  author={Rahman, Akond and Williams, Laurie},
  booktitle={2018 IEEE 11th International Conference on Software Testing, Verification and Validation (ICST)}, 
  title={Characterizing Defective Configuration Scripts Used for Continuous Deployment}, 
  year={2018},
  volume={},
  number={},
  pages={34-45},
  abstract={In software engineering, validation and verification (V&V) resources are limited and characterization of defective software source files can help in efficiently allocating V&V resources. Similar to software source files, defects occur in the scripts used to automatically manage configurations and software deployment infrastructure, often known as infrastructure as code (IaC) scripts. Defects in IaC scripts can have dire consequences, for example, creating large-scale system outages. Identifying the characteristics of defective IaC scripts can help in mitigating these defects by allocating V&V efforts efficiently based upon these characteristics. The objective of this paper is to help software practitioners to prioritize validation and verification efforts for infrastructure as code (IaC) scripts by identifying the characteristics of defective IaC scripts. Researchers have previously extracted text features to characterize defective software source files written in general purpose programming languages. We investigate if text features can be used to identify properties that characterize defective IaC scripts. We use two text mining techniques to extract text features from IaC scripts: the bag-of-words technique, and the term frequency-inverse document frequency (TF-IDF) technique. Using the extracted features and applying grounded theory, we characterize defective IaC scripts. We also use the text features to build defect prediction models with tuned statistical learners. We mine open source repositories from Mozilla, Openstack, and Wikimedia Commons, to construct three case studies and evaluate our methodology. We identify three properties that characterize defective IaC scripts: filesystem operations, infrastructure provisioning, and managing user accounts. Using the bag-of-word technique, we observe a median F-Measure of 0.74, 0.71, and 0.73, respectively, for Mozilla, Openstack, and Wikimedia Commons. Using the TF-IDF technique, we observe a median F-Measure of 0.72, 0.74, and 0.70, respectively, for Mozilla, Openstack, and Wikimedia Commons.},
  keywords={Feature extraction;Software;Predictive models;Text mining;Organizations;Measurement;DSL;configuration as code;continuous deployment;defect;devops;infrastructure as code;puppet},
  doi={10.1109/ICST.2018.00014},
  ISSN={},
  month={April},}@ARTICLE{9915031,
  author={Alonso, Juncal and Piliszek, Radosław and Cankar, Matija},
  journal={IEEE Software}, 
  title={Embracing IaC Through the DevSecOps Philosophy: Concepts, Challenges, and a Reference Framework}, 
  year={2023},
  volume={40},
  number={1},
  pages={56-62},
  abstract={We introduce the challenges of DevSecOps philosophy and its applicability to the development and operation of trustworthy infrastructure-as-code, and we combine the solutions into a single framework covering all crucial steps. Finally, we discuss how the proposed framework addresses the challenges and introduce an initial design for it.},
  keywords={Security;Runtime;Codes;Software engineering;Monitoring;Software testing;Inspection},
  doi={10.1109/MS.2022.3212194},
  ISSN={1937-4194},
  month={Jan},}@INPROCEEDINGS{9787876,
  author={Hassan, Mohammad Mehedi and Rahman, Akond},
  booktitle={2022 IEEE Conference on Software Testing, Verification and Validation (ICST)}, 
  title={As Code Testing: Characterizing Test Quality in Open Source Ansible Development}, 
  year={2022},
  volume={},
  number={},
  pages={208-219},
  abstract={Infrastructure as code (IaC) scripts, such as Ansible scripts, are used to provision computing infrastructure at scale. Existence of bugs in IaC test scripts, such as, configuration and security bugs, can be consequential for the provisioned computing infrastructure. A characterization study of bugs in IaC test scripts is the first step to understand the quality concerns that arise during testing of IaC scripts, and also provide recommendations for practitioners on quality assurance. We conduct an empirical study with 4,831 Ansible test scripts mined from 104 open source software (OSS) repositories where we quantify bug frequency, and categorize bugs in test scripts. We further categorize testing patterns, i.e., recurring coding patterns in test scripts, which also correlate with appearance of bugs. From our empirical study, we observe 1.8% of 4,831 Ansible test scripts to include a bug, and 45.2% of the 104 repositories to contain at least one test script that includes bugs. We identify 7 categories of bugs, which includes security bugs and performance bugs that are related with metadata extraction. We also identify 3 testing patterns that correlate with appearance of bugs: 'assertion roulette’, 'local only testing’, and 'remote mystery guest‘. Based on our findings, we advocate for detection and mitigation of the 3 testing patterns as these patterns can have negative implications for troubleshooting failures, reproducible deployments of software, and provisioning of computing infrastructure.},
  keywords={Software testing;Codes;Quality assurance;Computer bugs;Metadata;Inspection;Encoding;ansible;bug;configuration as code;empirical study;infrastructure as code;quality;test},
  doi={10.1109/ICST53961.2022.00031},
  ISSN={2159-4848},
  month={April},}@INPROCEEDINGS{10589858,
  author={Bessghaier, Narjes and Begoug, Mahi and Mebarki, Chemseddine and Ouni, Ali and Sayagh, Mohammed and Mkaouer, Mohamed Wiem},
  booktitle={2024 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={On the Prevalence, Co-occurrence, and Impact of Infrastructure-as-Code Smells}, 
  year={2024},
  volume={},
  number={},
  pages={23-34},
  abstract={In modern software systems, Infrastructure-as-Code (IaC) tools play a pivotal role in automating the management of various infrastructure resources such as networks, databases, and services. This automation is done through code-based specification files, commonly known as IaC files. Similarly to other code files, IaC files can suffer from violations of established implementation and design standards, i.e., IaC smells. Although prior research has studied various aspects of traditional smells in non-IaC artifacts, there is little knowledge of how IaC smells are prevalent, co-occurring, and impacting the change and defect proneness of IaC code. To fill this gap, we conduct an empirical study encompassing 82 Puppet-based open-source projects. Our investigation focused on 12 types of IaC smells in both implementation and design levels. Our findings reveal that IaC smells do not manifest uniformly, as IaC smells that are particularly associated with modularity issues, exhibit high prevalence rates across projects. Additionally, we found that 74% of IaC files are smelly and over 52% of the smelly IaC files have at least two co-occurring IaC smells. Furthermore, our findings highlight that, on average, smelly IaC files are modified nearly 3.8 times, in terms of number of commits, more frequently than non-smelly IaC files. Furthermore, smelly IaC files are found to be 3.1 times more prone to larger code changes, in terms of code churn, than non-smelly IaC files. Additionally, we found that smelly IaC files are 3.3 times more prone to the introduction of defects that are likely to persist in 1.65 more commits before being fixed than non-smelly IaC files. These findings advocate developers to be more aware of IaC smells in their projects and consider their correction.},
  keywords={Encapsulation;Codes;Automation;Databases;Computer bugs;Design standards;Software systems;Infrastructure-as-Code (IaC);Puppet;Code change;IaC smells;Defects-proneness},
  doi={10.1109/SANER60148.2024.00009},
  ISSN={2640-7574},
  month={March},}@INPROCEEDINGS{11029328,
  author={Xiang, Yiming and Yang, Zhenning and Peng, Jingjia and Bauer, Hermann and Kon, Patrick Tser Jern and Qiu, Yiming and Chen, Ang},
  booktitle={2025 IEEE/ACM International Workshop on Cloud Intelligence & AIOps (AIOps)}, 
  title={Automated Bug Discovery in Cloud Infrastructure-as-Code Updates with LLM Agents}, 
  year={2025},
  volume={},
  number={},
  pages={20-25},
  abstract={Cloud environments are increasingly managed by Infrastructure-as-Code (IaC) platforms (e.g., Terraform), which allow developers to define their desired infrastructure as a configuration program that describes cloud resources and their dependencies. This shields developers from low-level operations for creating and maintaining resources, since they are automatically performed by IaC platforms when compiling and deploying the configuration. However, while IaC platforms are rigorously tested for initial deployments, they exhibit myriad errors for runtime updates, e.g., adding/removing resources and dependencies. IaC updates are common because cloud infrastructures are long-lived but user requirements fluctuate over time. Unfortunately, our experience shows that updates often introduce subtle yet impactful bugs. The update logic in IaC frameworks is hard to test due to the vast and evolving search space, which includes diverse infrastructure setups and a wide range of provided resources with new ones frequently added. We introduce TerraFault, an automated, efficient, LLM-guided system for discovering update bugs, and report our findings with an initial prototype. TerraFault incorporates various optimizations to navigate the large search space efficiently and employs techniques to accelerate the testing process. Our prototype has successfully identified bugs even in simple IaC updates, showing early promise in systematically identifying update bugs in today's IaC frameworks to increase their reliability.},
  keywords={Software testing;Runtime;Navigation;Computer bugs;Prototypes;Life estimation;Debugging;Software reliability;Logic;Optimization;Infrastructure-as-Code;Program update;Using LLMs for Cloud Ops;Reliability;Software testing and debugging},
  doi={10.1109/AIOps66738.2025.00011},
  ISSN={},
  month={May},}@ARTICLE{9845795,
  author={Sokolowski, Daniel and Weisenburger, Pascal and Salvaneschi, Guido},
  journal={IEEE Software}, 
  title={Decentralizing Infrastructure as Code}, 
  year={2023},
  volume={40},
  number={1},
  pages={50-55},
  abstract={Infrastructure as code (IaC) automates deployments for single teams, falling short of decentralized deployments across groups. We need mature IaC solutions that embrace and consolidate software engineering principles to enable testing and automation advances for decentralized organizations.},
  keywords={Authentication;Software engineering;Organizations;Manuals;Codes;Software testing;Software measurement;DevOps;Infrastructure as Code;Cloud},
  doi={10.1109/MS.2022.3192968},
  ISSN={1937-4194},
  month={Jan},}@INPROCEEDINGS{11025603,
  author={Kosbar, Seif and Hamdaqa, Mohammad},
  booktitle={2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR)}, 
  title={Smells-sus: Sustainability Smells in IaC}, 
  year={2025},
  volume={},
  number={},
  pages={801-812},
  abstract={Practitioners use Infrastructure as Code (IaC) scripts to efficiently configure IT infrastructures through machine-readable definition files. However, during the development of these scripts, some code patterns or deployment choices may lead to sustainability issues, like inefficient resource utilization or redundant provisioning. We call this type of patterns sustainability smells. These inefficiencies pose significant environmental and financial challenges, given the growing scale of cloud computing. This research focuses on Terraform, a widely adopted IaC tool. Our study involves defining seven sustainability smells and validating them through a survey with 19 IaC practitioners. We utilized a dataset of 28,327 Terraform scripts from 395 open-source repositories. We performed a detailed qualitative analysis of a randomly sampled $\mathbf{1, 8 6 0}$ Terraform scripts from the original dataset to identify code patterns that correspond to the sustainability smells and used the other 26,467 Terraform scripts to study the prevalence of the defined sustainability smells. Our results indicate varying prevalence rates of these smells across the dataset. The most prevalent smell is NonModular Configurations, which appears in $9.67 \%$ of the scripts. Additionally, our findings highlight the complexity of conducting root cause analysis for sustainability issues, as these smells often arise from a confluence of script structures, configuration choices, and deployment contexts.},
  keywords={Surveys;Cloud computing;Root cause analysis;Codes;Statistical analysis;Energy efficiency;Software;Complexity theory;Resource management;Sustainable development;Cloud Computing;Sustainability;Infrastructure as Code;Energy Efficiency},
  doi={10.1109/MSR66628.2025.00117},
  ISSN={2574-3864},
  month={April},}@INPROCEEDINGS{11025691,
  author={Begoug, Mahi and Ouni, Ali and Chouchen, Moataz},
  booktitle={2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR)}, 
  title={How Do Infrastructure-as-Code Practitioners Update Their Dependencies? An Empirical Study on Terraform Module Updates}, 
  year={2025},
  volume={},
  number={},
  pages={642-653},
  abstract={Infrastructure-as-Code (IaC) enables practitioners to configure and manage software infrastructure through machine-readable code files. Various IaC tools facilitate code reuse and modularity via IaC modules that act as dependencies. These modules are maintained by IaC providers to introduce new features, resolve bugs, or address security vulnerabilities. However, there is a limited understanding of how practitioners update their IaC module dependencies in their software projects, including updates frequency, delays, as well as motivations behind such updates. To fill this gap, this paper aims to understand current update practices in IaC module dependencies, focusing on Terraform (TF), being currently one of the most popular IaC tools. In particular, we investigate (i) the frequency in which IaC practitioners update their module dependencies, (ii) the technical lag phenomena, which represents the time that the infrastructure configurations remain outdated relative to their upstream modules, and (iii) the motivations that drive these updates. To achieve these, we conduct an empirical study on 13,490 TF-related commits from 131 open-source projects. Our results reveal that only 1.2% of the analyzed commits involve updating module dependencies. Furthermore, we observe an increasing technical lag from 2021 until 2024, reaching ten months on average by 2024. Then, we conduct a qualitative study using thematic analysis on code changes involving TF module dependencies updates to investigate practitioners’ motivations behind such updates. We identify that TF practitioners revolve around six main motivations, with IaC Ecosystem Compatibility, Security Vulnerabilities Fixes, and IaC Code Quality Improvement being the three most prevalent motivations. Our findings advocate that TF practitioners need customized IaC tool support for safe module dependency updates while addressing compatibility concerns.},
  keywords={Time-frequency analysis;Codes;Pandemics;Ecosystems;Organizations;Market research;Software;Stability analysis;Security;Software development management;Infrastructure-as-Code;Terraform Modules;Infrastructure Dependencies},
  doi={10.1109/MSR66628.2025.00100},
  ISSN={2574-3864},
  month={April},}@ARTICLE{10879172,
  author={Hong, Hyunsun and Lee, Sungu and Ryu, Duksan and Baik, Jongmoon},
  journal={Journal of Web Engineering}, 
  title={Code Smell-Guided Prompting for LLM-Based Defect Prediction in Ansible Scripts}, 
  year={2024},
  volume={23},
  number={8},
  pages={1107-1126},
  abstract={Ensuring the reliability of infrastructure as code (IaC) scripts, like those written in Ansible, is vital for maintaining the performance and security of edge-cloud systems. However, the scale and complexity of these scripts make exhaustive testing impractical. To address this, we propose a large language model (LLM)-based software defect prediction (SDP) approach that uses code-smell-guided prompting (CSP). In some cases, CSP enhances LLM performance in defect prediction by embedding specific code smell indicators directly into the prompts. We explore various prompting strategies, including zero-shot, one-shot, and chain of thought CSP (CoT-CSP), to evaluate how code smell information can improve defect detection. Unlike traditional prompting, CSP uniquely leverages code context to guide LLMs in identifying defect-prone code segments. Experimental results reveal that while zero-shot prompting achieves high baseline performance, CSP variants provide nuanced insights into the role of code smells in improving SDP. This study represents exploration of LLMs for defect prediction in Ansible scripts, offering a new perspective on enhancing software quality in edge-cloud deployments.},
  keywords={Codes;Large language models;Image edge detection;Refining;Software quality;Predictive models;Software reliability;Security;Defect detection;Testing;Edge-cloud;Ansible;large language models;software defect prediction},
  doi={10.13052/jwe1540-9589.2383},
  ISSN={1544-5976},
  month={November},}@INPROCEEDINGS{11024517,
  author={Wei, Haoran and Madhavji, Nazim and Steinbacher, John},
  booktitle={2025 IEEE/ACM 22nd International Conference on Software and Systems Reuse (ICSR)}, 
  title={A Framework for Reusable Infrastructure as Code Templates in Cloud-Native Environments}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Cloud-native technologies enable the development of scalable, secure, and resilient applications in diverse cloud environments. However, deploying and configuring these technologies can be complex and error-prone. Existing reusable Infrastructure as Code (IaC) solutions often suffer from inconsistent structures, limited customization, and potential vendor lock-in, hindering their effectiveness and usability. To mitigate this, this paper presents a framework for creating standardized and reusable IaC templates for deploying and configuring cloud-native infrastructure components. We conducted a needs analysis to identify key developer requirements and established ten design principles for creating reusable IaC templates. Additionally, we conducted a multivocal review of relevant literature to summarize best practices for implementing these principles. Leveraging these insights, we developed five IaC templates and evaluated their effectiveness and usability against existing solutions. This proposed framework integrates conceptual guidance with practical implementations of reusable templates to simplify cloud-native infrastructure setup and enhance developer productivity.},
  keywords={Productivity;Reviews;Software;Usability;Best practices;cloud-native;infrastructure as code;reusable templates;IaC principles;IaC best practices},
  doi={10.1109/ICSR66718.2025.00007},
  ISSN={},
  month={April},}@INPROCEEDINGS{10920371,
  author={Singh, Rashika and Yeboah-Ofori, Abel and Kumar, Saurabh and Ganiyu, Aishat},
  booktitle={2024 International Conference on Electrical and Computer Engineering Researches (ICECER)}, 
  title={Fortifying Cloud DevSecOps Security Using Terraform Infrastructure as Code Analysis Tools}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Fortifying Cloud Security has become inevitable due to challenges such as misconfigurations, coding errors, and compromised secrets or passwords that impact infrastructure as a service during infrastructure such as code automation (IaC). These challenges require code analysis tools to enhance security during infrastructure automation. Setting up a simple cloud architecture is quick, but human errors are still common, especially when cloud infrastructure can be deployed with just a few clicks. Terraform provides a ready-made infrastructure as code modules to build and scale cloud-hosted applications. However, cyber attackers exploit these vulnerabilities and gain access to sensitive data or resources without authorization due to configuration errors, inadequate storage, and infrastructure manipulation, resulting in unauthorized deployments or alterations. That affects the availability of resources during infrastructure deployment using attacks such as DoS attacks, injection attacks, Man in the Middle (MITM), malware spread, remote code execution (RCE), and phishing attacks to penetrate the cloud infrastructures. The paper aims to analyze Terraforms infrastructure as code in cloud security to fortify codes and assist DevSecOps engineers in identifying misconfiguration in Terraform scripts. The paper's contributions are threefold. First, we explore cloud security by securing IaC solutions on Terraform. We consider security issues, including misconfigurations and coding errors, present in Terraform IaC. Secondly, we implement a static analysis tool for terraform by comparatively analyzing existing tools. Finally, we provide a comparative analysis of terraform IaC on tools including Checkov, Tfsec, Tflint, and Terrascan for suitability based on their key features and performance metrics to enhance security.},
  keywords={Measurement;Codes;Automation;Runtime;Cloud computing security;Static analysis;Encoding;Security;Standards;Software development management;Terraform;Cloud Security;IaC;Coding Error;Cyber Security;Static Analysis Tool;DevSecOps},
  doi={10.1109/ICECER62944.2024.10920371},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10992548,
  author={Opdebeeck, Ruben and Adams, Bram and De Roover, Coen},
  booktitle={2025 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={Analysing Software Supply Chains of Infrastructure as Code: Extraction of Ansible Plugin Dependencies}, 
  year={2025},
  volume={},
  number={},
  pages={181-192},
  abstract={The digital infrastructures supporting modern software have grown too complex to manage by hand. Therefore, Infrastructure as Code (IaC) has become a widely adopted practice to programmatically automate deploying such infrastructures. As infrastructure code may rely on third-party libraries and packages, understanding the software supply chains generated by these deployment dependencies is crucial to ensure reproducibility and security of software deployments. Nonetheless, deployment software supply chains remain an understudied topic. This paper aims to bridge this gap by first investigating which types of third-party software IaC may depend upon, then building an automated mechanism to identify such dependencies from infrastructure implementations. We focus our investigation on Ansible, one of the most popular IaC tools, and its plugins, which implement the interactions with the deployment platforms under configuration. From a manual analysis of 266 documented third-party requirements of Ansible plugins, we construct a taxonomy of 7 types of third-party software dependencies and their properties. We also found that a plugin's dependencies are typically only described informally in the plugin's documentation, which may be unstructured, incorrect, or incomplete, which encumbers the automatic generation of Software Bills of Materials (SBOMs) for deployment code. Therefore, we design an automated Software Composition Analysis (SCA) that extracts these dependencies from an Ansible plugin's implementation, leveraging 5 dependency implementation patterns identified in our manual analysis. This approach achieves a recall of 61 %-77% and a precision of 74%-95%. Finally, we apply the SCA in a large-scale quantitative experiment on 11,241 plugins, and find that 38% have third-party dependencies. The taxonomy presented in this paper can serve as a reference to design deployment SBOMs for these plugins, whereas our SCA forms a first step towards automatically generating such SBOMs.},
  keywords={Hands;Codes;Supply chains;Taxonomy;Manuals;Documentation;Software;Libraries;Reproducibility of results;Security;software supply chain;infrastructure as code;deployment automation;third-party dependencies;software composition analysis},
  doi={10.1109/SANER64311.2025.00025},
  ISSN={2640-7574},
  month={March},}@INPROCEEDINGS{10224925,
  author={Reddy Konala, Pandu Ranga and Kumar, Vimal and Bainbridge, David},
  booktitle={2023 IEEE International Conference on Cyber Security and Resilience (CSR)}, 
  title={SoK: Static Configuration Analysis in Infrastructure as Code Scripts}, 
  year={2023},
  volume={},
  number={},
  pages={281-288},
  abstract={This SoK paper presents findings from a survey conducted on the current state of tools and techniques used in the static configuration analysis of Infrastructure as Code (IaC). Our findings highlight the increasing importance of ensuring the quality of IaC scripts through techniques such as detecting code and security smells. Our findings reveal that regular expressions are widely used, but this may not be a long-term or fully automated solution for detecting smells. Additionally, our study found that the majority of the tools and techniques are developed for infrastructure provisioning, rather than configuration management and image building. This raises concerns because configuring software is a high-risk task, with malicious actors constantly targeting software systems. Therefore, it is crucial for researchers to develop efficient and advanced techniques for detecting defects in configuration management and image building. The aim of this paper is to provide a detailed overview of the current state of research in this field, and to identify areas for future development.},
  keywords={Surveys;Codes;Buildings;Configuration management;Software systems;Security;Task analysis;devops;devsecops;sok;survey;empirical study;infrastructure as code;code;security;smells;defects;static configuration analysis},
  doi={10.1109/CSR57506.2023.10224925},
  ISSN={},
  month={July},}@INPROCEEDINGS{8539175,
  author={Chen, Wei and Wu, Guoquan and Wei, Jun},
  booktitle={2018 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)}, 
  title={An Approach to Identifying Error Patterns for Infrastructure as Code}, 
  year={2018},
  volume={},
  number={},
  pages={124-129},
  abstract={Infrastructure as Code (IaC), which specifies system configurations in an imperative or declarative way, automates environment set up, system deployment and configuration. Despite wide adoption, developing and maintaining high-quality IaC artifacts is still challenging. This paper proposes an approach to handling the fine-grained and frequently occurring IaC code errors. The approach extracts code changes from historical commits and clusters them into groups, by constructing a feature model of code changes and employing an unsupervised machine learning algorithm. It identifies error patterns from the clusters and proposes a set of inspection rules to check the potential IaC code errors. In practice, we take Puppet code artifacts as subject objects and perform a comprehensive study on 14 popular Puppet artifacts. In our experiment, we get 41 cross-artifact error patterns, covering 42% crawled code changes. Based on these patterns, 30 rules are proposed, covering 60% identified error patterns, to proactively check IaC artifacts. The approach would be helpful in improving code quality of IaC artifacts.},
  keywords={Feature extraction;Tools;Computer bugs;Syntactics;Inspection;Software;Machine learning algorithms;Infrastructure as Code;Error pattern;Puppet artifact},
  doi={10.1109/ISSREW.2018.00-19},
  ISSN={},
  month={Oct},}@ARTICLE{11131627,
  author={Begoug, Mahi and Ouni, Ali and Khelifi, Jasem},
  journal={IEEE Transactions on Services Computing}, 
  title={Understanding AWS Provider Dependencies Updates in Infrastructure-as-Code: Empirical Study, Taxonomy, and Insights}, 
  year={2025},
  volume={},
  number={},
  pages={1-17},
  abstract={Infrastructure-as-Code (IaC) automates the configuration of cloud platforms through code. As business needs evolve, IaC files often become complex, containing hundreds of lines and multiple dependencies. These configurations rely on third-party providers to provision system infrastructure. Practitioners regularly update IaC code to align with evolving cloud provider specifications (i.e., AWS, GCP, Azure) and to address security issues or defects. Although prior work highlights the risks of outdated dependencies, it remains unclear whether IaC practitioners consistently update provider dependencies in accordance with official releases. To address this gap, we conduct a mixed-method empirical study focused on the Amazon Web Services (AWS) provider, one of the most widely used providers for provisioning cloud infrastructures. We analyze 23,404 Terraform (TF) related commits from 194 open-source TF projects, focusing on: (i) technical lag, which captures how long AWS provider dependencies remain unchanged in code; (ii) the frequency of dependency updates; (iii) the code review effort involved in updating AWS provider dependencies; and (iv) the motivations behind such updates. Our findings reveal that Terraform developers frequently rely on outdated provider versions, with the technical lag increasing steadily from 2017 to early 2025, reaching a monthly average of approximately 9 months by 2025. Quantitative analysis reveals that only 1.86% of TF-related commits involve updates to AWS provider dependencies, indicating that such updates are not a priority. Moreover, related code reviews are substantial, affecting a median of 7 files across multiple directories. Through thematic analysis, we identify nine key motivations for updating the AWS provider dependencies, with the top three being: Providers Dependency Management, Terraform Compatibility Management, and Security Management. These insights highlight a clear need for better support and tooling to help practitioners manage provider updates more effectively, minimizing disruption while modernizing infrastructure. We recommend adopting automated dependency management tools and improved update workflows to reduce technical lag and lower the cost of staying up to date.},
  keywords={Codes;Reviews;Virtual machines;Computer bugs;Web services;Taxonomy;Ions;Delays;Testing;Statistical analysis;Infrastructure-as-Code;Amazon Web Services Provider;Infrastructure Dependencies},
  doi={10.1109/TSC.2025.3601051},
  ISSN={1939-1374},
  month={},}@INPROCEEDINGS{9251924,
  author={Opdebeeck, Ruben and Zerouali, Ahmed and Velázquez-Rodríguez, Camilo and Roover, Coen De},
  booktitle={2020 IEEE 20th International Working Conference on Source Code Analysis and Manipulation (SCAM)}, 
  title={Does Infrastructure as Code Adhere to Semantic Versioning? An Analysis of Ansible Role Evolution}, 
  year={2020},
  volume={},
  number={},
  pages={238-248},
  abstract={Ansible, a popular Infrastructure-as-Code platform, provides reusable collections of tasks called roles. Roles are often contributed by third parties, and like general-purpose libraries, they evolve. As such, new releases of roles need to be tagged with version numbers, for which Ansible recommends adhering to the semantic versioning format. However, roles significantly differ from general-purpose libraries, and it is not yet known what constitutes a breaking change or the addition of a feature to a role. Consequently, this can cause confusion for clients of a role and new role contributors. To alleviate this issue, we perform an empirical study on semantic versioning in Ansible roles to uncover the types of changes that trigger certain types of version bumps. We collect a dataset of over 70000 version increments spanning upwards of 7800 Ansible roles. Moreover, we design a novel structural model for these roles, and implement a domainspecific structural change extraction algorithm to calculate structural difference metrics. Afterwards, we quantitatively investigate the state of semantic versioning in Ansible roles and identify the most commonly changed components. Then, using the structural difference metrics, we train a Random Forest classifier to predict applicable version bumps for Ansible role releases. Lastly, we confirm our empirical findings with a developer survey. Our observations show that although most Ansible role developers follow the semantic versioning format, it appears that they do not always consistently follow the same rules when selecting the version bump to apply.},
  keywords={Measurement;Semantics;Prediction algorithms;Libraries;Classification algorithms;Task analysis;Guidelines;Ansible;Infrastructure as Code;Semantic Versioning;empirical study;mining software repositories},
  doi={10.1109/SCAM51674.2020.00032},
  ISSN={2470-6892},
  month={Sep.},}@INPROCEEDINGS{8919181,
  author={Guerriero, MIchele and Garriga, Martin and Tamburri, Damian A. and Palomba, Fabio},
  booktitle={2019 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Adoption, Support, and Challenges of Infrastructure-as-Code: Insights from Industry}, 
  year={2019},
  volume={},
  number={},
  pages={580-589},
  abstract={Infrastructure-as-code (IaC) is the DevOps tactic of managing and provisioning infrastructure through machine-readable definition files, rather than physical hardware configuration or interactive configuration tools. From a maintenance and evolution perspective, the topic has picked the interest of practitioners and academics alike, given the relative scarcity of supporting patterns, best practices, tools, and software engineering techniques. Using the data coming from 44 semistructured interviews to senior developers of as many companies, in this paper we shed light on the state of the practice in the adoption of IaC and the key software engineering challenges in the field. Particularly, we investigate (i) how practitioners adopt and develop IaC, (ii) which support is currently available, i.e., the typically used tools and their advantages/disadvantages, and (iii) what are the practitioner's needs when dealing with IaC development, maintenance, and evolution. Our findings clearly highlight the need for more research in the field: the support provided by currently available tools is still limited, and developers feel the need of novel techniques for testing and maintaining IaC code.},
  keywords={Tools;Interviews;Companies;Cloud computing;Software maintenance;Maintenance engineering;Infrastructure-as-Code;DevOps;Software Maintenance & Evolution;Cloud Automation},
  doi={10.1109/ICSME.2019.00092},
  ISSN={2576-3148},
  month={Sep.},}@INPROCEEDINGS{8590193,
  author={Schwarz, Julian and Steffens, Andreas and Lichter, Horst},
  booktitle={2018 11th International Conference on the Quality of Information and Communications Technology (QUATIC)}, 
  title={Code Smells in Infrastructure as Code}, 
  year={2018},
  volume={},
  number={},
  pages={220-228},
  abstract={Ensuring high quality in software systems is a wellknown and big challenge. Infrastructure as Code (IaC) gathered increasing popularity in recent years, but there is only little research done in terms of quality of this code. Like with programming languages we find a high diversity of languages and technologies. Existing research introduced code smells from traditional software engineering to the popular provisioning tool Puppet, which uses IaC to specify the desired state of environments. Results show that code smells are an adequate method to assess the quality of Puppet code. In this paper we extend the existing research by first applying code the IaC smells to an other technology and investigate if similar results can be achieved. We applied the code smells in two case studies to open and closed source IaC code repositories. The presented results indicate that IaC smells are present in other tools and technologies. Furthermore the results show that IaC smells are agnostic to the applied technology and can be defined on a technology agnostic level. Second, we introduce new code smells from the field of software engineering, which were not covered yet, to the domain of IaC. The paper presents a catalogue of 17 code smells which were applied to Chef and whose implementation is available as Open Source.},
  keywords={Tools;Software systems;Best practices;Software engineering;Computer architecture;Measurement;Infrastructure As Code;DevOps;static analysis;code smells;software quality;refactoring},
  doi={10.1109/QUATIC.2018.00040},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9779653,
  author={Falazi, Ghareeb and Breitenbücher, Uwe and Leymann, Frank and Stötzner, Miles and Ntentos, Evangelos and Zdun, Uwe and Becker, Martin and Heldwein, Elena},
  booktitle={2022 IEEE 19th International Conference on Software Architecture Companion (ICSA-C)}, 
  title={On Unifying the Compliance Management of Applications Based on IaC Automation}, 
  year={2022},
  volume={},
  number={},
  pages={226-229},
  abstract={Infrastructure-as-Code (IaC) technologies are used to automate the deployment of cloud applications. They promote the usage of code to define and configure the IT infrastructure of cloud applications allowing them to benefit from conventional software development practices, which facilitates the rapid deployment of new versions of application infrastructures without sacrificing quality or stability. On the other hand, enterprise applications need to conform to compliance regarding external regulations and internal policies. Many of these compliance rules affect the application architecture on which IaC code operates. However, managing the architectural compliance of IaC-based application deployments faces a number of challenges, such as configuration drift and the heterogeneity of IaC technologies. Therefore, in this work, we present a vision on how to uniformly manage the compliance of the infrastructure of applications that utilize heterogeneous IaC technologies for deployment automation. To this end, we introduce an initial design for the IaC-based Architectural Compliance Management Framework and discuss how it addresses the corresponding challenges.},
  keywords={Codes;Automation;Software architecture;Conferences;Computer architecture;Software;Regulation;Compliance;Software Architecture;Software Infrastructure;Infrastructure-as-Code},
  doi={10.1109/ICSA-C54293.2022.00050},
  ISSN={2768-4288},
  month={March},}@INPROCEEDINGS{9779836,
  author={Novakova Nedeltcheva, Galia and De La Fuente Ruiz, Alfonso and Orue-Echevarria Arrieta, Leire and Bat, Nejc and Blasi, Lorenzo},
  booktitle={2022 IEEE 19th International Conference on Software Architecture Companion (ICSA-C)}, 
  title={Towards Supporting the Generation of Infrastructure as Code Through Modelling Approaches - Systematic Literature Review}, 
  year={2022},
  volume={},
  number={},
  pages={210-217},
  abstract={The present paper aims at presenting a structured literature review for what concerns the following aspects: Infrastructure as a Code (IaC) languages, modelling approaches supporting the generation of IaC, categories of languages, and their characteristics, and security analysis techniques. Finally, the paper draws conclusions and gives some future research perspectives.More specifically, the objective is to identify, analyze and interpret all available evidence from primary studies related to four specific research questions which involve the review, planning, conducting, and reporting stages, as suggested by the PRISMA methodology. More than 100 articles in the latest years are surveyed and thus a current, justified state of the art is presented hereby.},
  keywords={Analytical models;Codes;Systematics;Software architecture;Bibliographies;Conferences;Planning;Systematic Literature Review (SLR);Infrastructure as Code (IaC);Modelling approaches;Generation of IaC code;Parsers;Cybersecurity},
  doi={10.1109/ICSA-C54293.2022.00048},
  ISSN={2768-4288},
  month={March},}@INPROCEEDINGS{10734039,
  author={Low, En and Cheh, Carmen and Chen, Binbin},
  booktitle={2024 IEEE Secure Development Conference (SecDev)}, 
  title={Repairing Infrastructure-as-Code using Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={20-27},
  abstract={Infrastructure-as-Code (IaC) is the practice of provisioning and managing cloud resources using machine-readable code. IaC is seeing increased adoption because it enhances transparency and reliability of infrastructure operations. However, as any software code, IaC can also contain misconfigurations, which can lead to insecure infrastructure, which may result in data breaches. Existing IaC scanning tools are able to detect common misconfigurations in IaC but they require IaC developers to manually repair the code. Recent advances in Large Language Models (LLMs) have led to promising results in applying LLMs to Automatic Program Repair (APR) tasks for code written in different languages. In this work, we propose an LLM-based approach to fix misconfigurations in IaC code. After misconfigurations in IaC code are identified by scanning tools, we feed the LLMs with the IaC code, details about the misconfigurations, and additional context provided by a human-in-the-loop and prompt the LLM to generate the repaired IaC code. We tested our approach on several vulnerable IaC repositories and found that the GPT-4 model from OpenAI suggests fixes that reduce up to 84.7% of the misconfiguration alarms produced by the scanners and our two-pass solution significantly improves the performance over a one-pass only approach. However, of the fixes suggested, we manually determined that only 79.6% actually solve the problem, while the remaining 20.4% are hallucinated fixes. Specifically, LLM hallucinations in the generated outputs pass checks for misconfigurations but fail other syntax and schema validation checks or do not address the underlying security issue. We propose a few potential approaches to tackle this challenge.},
  keywords={Codes;Large language models;Semantics;Maintenance engineering;Syntactics;Human in the loop;Software;Software reliability;Security;Feeds;infrastructure as code;large language model;automatic program repair},
  doi={10.1109/SecDev61143.2024.00008},
  ISSN={},
  month={Oct},}@ARTICLE{9373305,
  author={Alnafessah, Ahmad and Gias, Alim Ul and Wang, Runan and Zhu, Lulai and Casale, Giuliano and Filieri, Antonio},
  journal={IEEE Access}, 
  title={Quality-Aware DevOps Research: Where Do We Stand?}, 
  year={2021},
  volume={9},
  number={},
  pages={44476-44489},
  abstract={DevOps is an emerging paradigm that reduces the barriers between developers and operations teams to offer continuous fast delivery and enable quick responses to changing requirements within the software life cycle. A significant volume of activity has been carried out in recent years with the aim of coupling DevOps stages with tools and methods to improve the quality of the produced software and the underpinning delivery methodology. While the research community has produced a sustained effort by conducting numerous studies and innovative development tools to support quality analyses within DevOps, there is still a limited cohesion between the research themes in this domain and a shortage of surveys that holistically examine quality engineering work within DevOps. In this paper, we address the gap by comprehensively surveying existing efforts in this area, categorizing them according to the stage of the DevOps lifecycle to which they primarily contribute. The survey holistically spans across all the DevOps stages, identify research efforts to improve architectural design, modeling and infrastructure-as-code, continuous-integration/continuous-delivery (CI/CD), testing and verification, and runtime management. Our analysis also outlines possible directions for future work in quality-aware DevOps, looking in particular at AI for DevOps and DevOps for AI software.},
  keywords={Software;Testing;Artificial intelligence;Computer architecture;Tools;Production;Software architecture;DevOps;CI/CD;infrastructure as code;testing;artificial intelligence;verification},
  doi={10.1109/ACCESS.2021.3064867},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11181404,
  author={Chang, Jui-Hsuan and Chen, Tong-I and Ho, Wayne},
  booktitle={2025 25th Asia-Pacific Network Operations and Management Symposium (APNOMS)}, 
  title={FEET: A Framework for End-to-End Testability of FreeRADIUS via Containerization and CI Pipelines}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={This paper introduces FEET, a comprehensive testing framework designed to streamline FreeRADIUS deployments through containerization and automation. By integrating Docker-in-Docker and Docker Network technologies within GitLab CI pipelines, FEET enables precise simulation of realistic client-server authentication scenarios. Continuous static code analysis through SonarQube further ensures robust software quality. Experimental evaluations demonstrate significant performance improvements, including up to $50 \%$ higher throughput under high concurrency compared to traditional bare-metal setups. Ultimately, FEET provides a scalable, secure, and easily replicable model for infrastructure-as-code in authentication services.},
  keywords={Codes;DevOps;Pipelines;Authentication;Software quality;Throughput;Robustness;Stress;Testing;Software engineering;Software Engineering;FreeRADIUS;DevOps;end-to-end testing;infrastructure as code},
  doi={10.23919/APNOMS67058.2025.11181404},
  ISSN={2576-8565},
  month={Sep.},}@INPROCEEDINGS{9407320,
  author={Shimizu, Ryo and Kanuka, Hideyuki},
  booktitle={2020 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)}, 
  title={Test-Based Least Privilege Discovery on Cloud Infrastructure as Code}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Infrastructure as Code (IaC) for cloud is an important practice due to its efficient and reproducible provisioning of cloud environments. On a cloud IaC definition (template), developers need to manage permissions for each cloud services as well as a desired cloud environment. To minimize the risk of cyber-attacks, retaining least privilege, i.e., giving a minimum set of permissions, on IaC templates is important and widely regarded as best practice. However, discovering least privilege on a target IaC template at one time is an error-prone and burdensome task for developers. One reason is that some actions of a cloud service implicitly use other services and require corresponding permissions, which are hard to recognize without actual executions on the cloud and burden the development process with iterations of permission setting and provisioned result checking. In this paper, we present a technique to automatically discover least privilege. Our method incrementally finds the least privilege by the iteration of testing on the cloud and (re)configuring permissions on the basis of test results. We conducted case studies and found that our approach can identify least privilege on Amazon Web Services within a practical time. Our experiments also show that the proposed algorithm can reduce the number of test executions, which directly affects the time and cost on cloud to determine least privilege, by 69.3% and 39.8% compared with the random and heuristic methods, respectively, on average.},
  keywords={Cloud computing;Web services;Heuristic algorithms;IEEE Sections;Clustering algorithms;Prototypes;Tools;Cloud Computing;Infrastructure as Code;Least Privilege;Cloud Application Development;Software Testing},
  doi={10.1109/CloudCom49646.2020.00007},
  ISSN={2330-2186},
  month={Dec},}@ARTICLE{10965635,
  author={Toprani, Dheer and Madisetti, Vijay K.},
  journal={IEEE Access}, 
  title={LLM Agentic Workflow for Automated Vulnerability Detection and Remediation in Infrastructure-as-Code}, 
  year={2025},
  volume={13},
  number={},
  pages={69175-69181},
  abstract={This paper presents a multi-agent, AI-driven strategy employing Large Language Models (LLMs), retrieval-augmented generation, and a continuously updated knowledge base for the detection and remediation of security vulnerabilities win cloud frameworks. By examining Infrastructure as Code (IaC) templates alongside pertinent best-practice snippets, the system discerns context-specific misconfigurations commonly overlooked by static tools, achieving a detection rate of 85% with some occurrences of false positives. Automated remediation guidance, anchored in current security standards, provides actionable solutions that seamlessly integrate into standard continuous integration/continuous development (CI/CD) workflows. Experimental results indicate the solution’s efficacy and scalability, heralding a proactive, context-aware approach to IaC security.},
  keywords={Security;Retrieval augmented generation;Static analysis;Runtime;Best practices;Vectors;Scalability;Large language models;Cognition;Organizations;Infrastructure-as-code;large language models;vulnerability detection;security automation;CI/CD;LLM workflows},
  doi={10.1109/ACCESS.2025.3560911},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9860198,
  author={Ntentos, Evangelos and Zdun, Uwe and Falazi, Ghareeb and Breitenbücher, Uwe and Leymann, Frank},
  booktitle={2022 IEEE International Conference on Services Computing (SCC)}, 
  title={Assessing Architecture Conformance to Security-Related Practices in Infrastructure as Code Based Deployments}, 
  year={2022},
  volume={},
  number={},
  pages={123-133},
  abstract={Infrastructure as Code (IaC) enables developers and operations teams to automatically deploy and manage an IT infrastructure via software. Among other uses, IaC is widely used in the context of continuously released deployments such as those of microservice and other cloud-based systems. Although IaC-based deployments have been utilized by many companies, there are no approaches on checking their conformance to architectural aspects yet. In this paper, we focus on security-related practices including observability, access control, and traffic control in IaC-based deployments. While best practices for this topic have been documented in some gray literature sources such as practitioners’ blogs and public repositories, approaches enabling automated checking of conformance to such best practices do not yet exist. We propose a model-based approach based on generic, technology-independent metrics, tied to typical architectural design decisions on IaC-based deployments. With this approach, we can measure conformance to security-related practices. We demonstrate and assess the validity and appropriateness of these metrics in assessing a system’s conformance to practices through regression analysis.},
  keywords={Measurement;Codes;Service computing;Microservice architectures;Computer architecture;Traffic control;Software;Infrastructure as code;metrics;software architecture;modeling;best practices},
  doi={10.1109/SCC55611.2022.00029},
  ISSN={2474-2473},
  month={July},}@INPROCEEDINGS{10927871,
  author={Ashtagi, Rashmi and Belani, Chirag and Bhalerao, Prasanna and Bhalerao, Yash and Chawle, Atharva},
  booktitle={2025 International Conference on Computational, Communication and Information Technology (ICCCIT)}, 
  title={Building Resilient CICD Pipelines: A DevOps Security-First Framework}, 
  year={2025},
  volume={},
  number={},
  pages={828-834},
  abstract={Continuous Integration and Continuous Deployment are now integrated in automated systems that enhance code stability, and accelerate the deployment process as well as improving monitoring of the whole system in the software development field. This document deals with setting up of a strong CI/CD process involving AWS cloud services and DevOps. The infrastructure is built with the help of Terraform which ensures the scalability and repeatability applying the Infrastructure as Code (IaC) approach. A safe Virtual Private Cloud (VPC) is designed consisting of public and private subnets, load balancing for traffic distribution, and CloudFront CDN to improve geographical distribution. Jenkins is used in CI process to perform disk analysis, OWASP and Trivy vulnerability scanning, and making Docker images. The CD phase use ArgoCD for updates on Kubernetes and integrates Monitoring and observability using Prometheus and Grafana. Notifications are produced to JIRA and email communication for improvement. With the help of the offered cloud services and DevOps tool it is possible to consolidate the SDLC and bring effects in code safety, testing and utilization. This document also provides an overview of methods, instruments, and outcomes, demonstrating how the CI/CD automation influences the development and operation positively.},
  keywords={Cloud computing;DevOps;Codes;Scalability;Pipelines;Continuous integration;Security;Observability;Monitoring;Testing;Continuous Integration/Continuous Delivery (CI/CD);DevOps workflow;Infrastructure as Code (IaC);Amazon Web Services (AWS) Cloud Solutions;Terraform;Kubernetes;Docker;Jenkins;ArgoCD;SonarQube;OWASP Dependency Checker;Trivy;Prometheus;Grafana;Version control systems;Cloud system architecture;Containerization technology;Scalability solutions;Observability tools;Automated testing processes;Continuous deployment;Build automation techniques;Email/JIRA integration},
  doi={10.1109/ICCCIT62592.2025.10927871},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{11100474,
  author={Bialas, Karol and Sengupta, Souvik and Orzecliowski, Michal and Ruiz, Jesus and Parasporo, Manfredi and Gerbino, Gabriele},
  booktitle={2024 IEEE Globecom Workshops (GC Wkshps)}, 
  title={Enhancing Cloud Marketplace Operations with Infrastructure as Code: DOME - A Case Study}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In the realm of cloud infrastructure management, Infrastructure as Code (IaC) has become a pivotal framework, catalyzing advancements in modern digital marketplaces. The study at hand delves into the nuanced application of IaC within the Distributed Open Marketplace for Europe (DOME) project. Utilizing the GitOps methodology, complemented by tools such as ArgoCD, Helm, Kustomize, and Bitnami Sealed Secrets, this project achieves heightened levels of operational efficacy, scalability, and security. The empirical analysis underscores that IaC not only simplifies the provisioning and administration of infrastructure assets but also fosters operational consistency and agility. This establishes a robust blueprint for deploying dependable cloud and edge services throughout Europe.},
  keywords={Hands;Codes;Scalability;Conferences;Europe;Security;Infrastructure as Code (IaC);e-Marketplace;GitOps;DevSecOps;TM Forum Open API},
  doi={10.1109/GCWkshp64532.2024.11100474},
  ISSN={2166-0077},
  month={Dec},}@INPROCEEDINGS{10960053,
  author={Wang, Chih-Chia and Tseng, Chien-Chao},
  booktitle={2024 International Computer Symposium (ICS)}, 
  title={Provisioning a Reliable Kubernetes cluster with CI/CD}, 
  year={2024},
  volume={},
  number={},
  pages={65-70},
  abstract={In today’s fast-paced IT environment, adopting Infrastructure-as-Code mechanisms to automate the provisioning of servers, virtual machines, and Kubernetes clusters has become essential. However, relying solely on IaC mechanisms can result in issues such as package versions, configuration errors, and manual script modifications leading to provisioning failures and wasted time. This study introduces the CSIT Golden IaC Framework at the Computer Science Information Technologies Center of National Yang Ming Chiao Tung University, which combines Golden Images with existing IaC scripts and integrates Continuous Integration/Continuous Delivery mechanisms to ensure rapid and reliable provisioning of identical environments. Experimental results show significant time savings and error reduction, paving the way for automated management of Kubernetes clusters.},
  keywords={Technological innovation;Image resolution;Costs;Manuals;Continuous integration;Virtual machines;Reliability;Servers;Information technology;Testing;Kubernetes;Infrastructure as Code;Golden Image;Continuous Integration;Continuous Delivery;Automation;Testing},
  doi={10.1109/ICS64339.2024.00020},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10092644,
  author={Zhang, Yue and Wu, Fan and Rahman, Akond},
  booktitle={2023 IEEE 20th International Conference on Software Architecture Companion (ICSA-C)}, 
  title={Practitioner Perceptions of Ansible Test Smells}, 
  year={2023},
  volume={},
  number={},
  pages={1-3},
  abstract={The practice of infrastructure as code (IaC) recommends automated management of computing infrastructure with application of quality assurance, such as linting and testing. To that end, researchers recently have investigated quality concerns in IaC test manifests by deriving a catalog of test smells. The relevance of the identified smells need to be quantified by obtaining feedback from practitioners. Such feedback can help the IaC community understand if smells have relevance amongst practitioners, and derive future research directions. We survey 30 practitioners to assess the relevance of three Ansible test smell categories namely, assertion roulette, local only testing, and remote mystery guest. We observe local only testing to be the most agreed upon test smell category, whereas, assertion roulette is the least agreed upon test smell category. Our findings provide a nuanced perspective of test smells for IaC, and lays the groundwork for future research.},
  keywords={Quality assurance;Codes;Software architecture;Testing;ansible;devops;empirical study;infrastructure as code;testing;smells},
  doi={10.1109/ICSA-C57050.2023.00074},
  ISSN={2768-4288},
  month={March},}@INPROCEEDINGS{9730211,
  author={Almuhtadi, Wahab and Fenwick, Wynn and Henley-Vachon, Liam and Mitchell, Peter},
  booktitle={2022 IEEE International Conference on Consumer Electronics (ICCE)}, 
  title={Assessing Network Infrastructure-as-Code Security using Open Source Software Analysis Techniques Applied to BGP/BIRD}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, the security quality of an open-source software application for IP networks called BIRD is examined. Free and open-source software applications are used in all areas of modern software development. BIRD handles the Border Gateway Protocol (BGP) sessions between many different Autonomous Systems (AS) and is a very popular routing engine used at Internet Exchange Points (IXP's) around the world. It is essential to perform an in-depth analysis when using open-source software to understand risks, develop or improve products to offset the risks of lenient source code acceptance criteria and easier exploit insertion. Testing consists of three different stages: Open Source Intelligence (OSINT) conducted on the contributors to determine intentions for involvement, Static Application Security Testing (SAST) carried out to examine the source code for potential bugs and security risks, and Dynamic Application Security Testing (DAST) dealing with verifying the stability of the program during run-time. Test results and analysis are in section IV.},
  keywords={Codes;Computer bugs;Stability criteria;Logic gates;Routing;Birds;Application security;Autonomous Systems;Border Gateway Protocol;Internet Exchange Point;Open-Source Intelligence;Static Application Security Testing;Dynamic Application Security Testing;run-time;Wireshark;Scapy;Ubuntu;Kali Linux;fuzzing;Google Cloud Platform;VMware ESXi;BIRD},
  doi={10.1109/ICCE53296.2022.9730211},
  ISSN={2158-4001},
  month={Jan},}@INPROCEEDINGS{9767473,
  author={Rinta-Jaskari, Eetu and Allen, Christopher and Meghla, Tamara and Taibi, Davide},
  booktitle={2022 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)}, 
  title={Testing Approaches And Tools For AWS Lambda Serverless-Based Applications}, 
  year={2022},
  volume={},
  number={},
  pages={686-692},
  abstract={With serverless-based applications are increasing their popularity, little is known on testing practices and tools available to test serverless functions. This work aims to identify testing approaches for serverless functions built for the Amazon Web Services cloud platform, and to demonstrate how to implement them to a full-stack application. For this purpose, we implemented unit, integration and system tests to an existing open source application providing insights of the testing practices and and tools applicable. Results shows that all the testing practices are applicable, even if there is a lack of tools to support end-to-end tests, especially for debugging.},
  keywords={Pervasive computing;Web services;Conferences;FAA;Debugging;Software;Reliability;software testing;serverless testing;faas test;lambda test;serverless function;Amazon Web Services;Lambda;Function-as-a-Service;Infrastructure-as-Code},
  doi={10.1109/PerComWorkshops53856.2022.9767473},
  ISSN={},
  month={March},}@INPROCEEDINGS{9357104,
  author={Vladusic, Daniel and Radolovic, Dragan},
  booktitle={2020 22nd International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)}, 
  title={Infrastructure as Code for Heterogeneous Computing}, 
  year={2020},
  volume={},
  number={},
  pages={1-2},
  abstract={Setting up an infrastructure for application deployment is a non-trivial task. We usually simplify the task by using the Infrastructure as Code (IaC) approach. Through IaC we set-up software defined infrastructure, able to run applications. Several tools and platforms have been developed to describe the system and to implement the actual deployment of the application (e.g., Puppet, Chef, Ansible, Terraform, etc.). When the infrastructure is heterogeneous (e.g., combination of Cloud and HPC) the challenges to set up a collaborative infrastructure is even harder, as the paradigms and environments differ significantly. Cloud infrastructure is focusing on servers, events, functions, while the HPC infrastructure is procedural and takes the application and merely executes it, usually on bare metal. As expected, the applications deployed on the respective systems differ in their dynamics and longevity. Whilst deployment of applications on the Cloud can be solved with the aforementioned tools, the HPC systems are in this respect in their infancy � the application is usually scheduled to be executed on a pre-defined set of processors and from that point on, the scripts merely gather input data, execute the application and then organize the output data. Merging the two approaches is thus currently rather hard and requires an explicit boundary between the Cloud and HPC parts of the application, posing a significant issue for the overall modelling and thus set-up of the system with the IaC approach. SODALITE, an H2020 project, is targeting simplification of the application deployment complexity while retaining or improving application performance on targeted HPC heterogeneous and cloud systems. The application deployment is abstracted through modelling of application's component relationships, policies and performance. The application is deployed using appropriate container technologies, matching the targeted heterogeneous HPC and cloud-based platforms. The starting point is the definition of the system and the application within an AI-supported IDE, using a straightforward, TOSCA-similar language. The smart IDE backed with the Graph DB knowledge base supports the user with the suggestions on how the system and application could (or should) be modelled. In the next general step, this definition is executed through an orchestrator, resulting in an execution of the application within the software-defined environment. In cases where the source code is available, it is optimised for the targeted infrastructure before execution. This step ensures that the application performance is not lost due to abstraction. However, in all cases, the execution of the application is monitored, as SODALITE is using machine learning and controltheory approaches to improve runtime performance. SODALITE is currently in the middle of its development thus not all of its functionalities are available. Whilst we first addressed the typical private Cloud infrastructures (e.g. OpenStack) and HPC (e.g. Torque job scheduler) using containers to encapsulate the applications, there is still work to be done to address public Clouds (e.g. AWS) and other HPC schedulers (e.g. Slurm). The IDE is functional, however it still requires further improvements and enhancements. Finally, not all optimisation approaches are developed at the moment. The aim of the proposed approach is to flatten the learning curve for Ops enabling them to concentrate on domain problems, resulting in lower overall costs of development and application lifecycle management.},
  keywords={Cloud computing;Tutorials;Codes;Training;Task analysis;Optimization;Deep learning},
  doi={10.1109/SYNASC51798.2020.00011},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10612535,
  author={Paul, Alen and Manoj, Rishi and S, Udhayakumar},
  booktitle={2024 International Conference on Expert Clouds and Applications (ICOECA)}, 
  title={Amazon Web Services Cloud Compliance Automation with Open Policy Agent}, 
  year={2024},
  volume={},
  number={},
  pages={313-317},
  abstract={The security challenges posed by Infrastructure as code (IaC) are outgrowing established security procedures in an era of rapidly adopting cloud computing and DevOps methodologies. Using security principles to be integrated into the CI/CD pipeline for continuous validation and remediation, this research work proposes a DevSecOps approach to enable cloud environment IaC security. The proposed architecture evaluates CloudFormation Template file to the specified security policy by utilizing Open Policy Agent (OPA). Any violations are flagged by OPA, which may force the deployment process to stop. By incorporating security and compliance considerations into the development pipeline, this method guarantees that vulnerabilities are kept out of production systems. Organizations can improve the overall security posture of their cloud systems by proactively identifying and remediating security problems by implementing a DevSecOps approach. By ensuring that IaC deployments adhere to specified security policies based on the compliance requirements, OPA's continuous security validation reduces the possibility of misconfigurations and security flaws.},
  keywords={Cloud computing;Production systems;Codes;DevOps;Web services;Pipelines;Force;DevSecOps;Infrastructure as Code (IaC);Cloud Security;Continuous Integration/Continuous Deployment;Open Policy Agent;Security Policies;IAM Roles;CloudFormation Templates},
  doi={10.1109/ICOECA62351.2024.00063},
  ISSN={},
  month={April},}@INPROCEEDINGS{10125250,
  author={Soll, Marcus and Helmken, Hendrik and Belde, Michel and Schimpfhauser, Sebastian and Nguyen, Felix and Versick, Daniel},
  booktitle={2023 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Building an IT Security Laboratory for Complex Teaching Scenarios Using ‘Infrastructure as Code’}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={There are increasing demands for IT security education which could be partly met by easier access to IT security laboratories. This paper proposes the use of ‘Infrastructure as Code’ (IaC) as a central building block for introducing dynami-cally adaptable teaching scenarios to laboratories in the context of IT security. The decision was made based on our didactical concept (which is built on Bloom's Taxonomy). The concept we propose is intended for use in a virtual laboratory, where the whole laboratory set-up is distributed over and contained within virtual machines. This way, we are able to build realistic, complex teaching scenarios. After comparing multiple IaC solutions, we decided to build our implementation on Terraform. The most important building blocks written in Terraform are presented. In addition, a user interface was created to meet demands of students and teachers. We will describe example teaching scenarios including one where students are tasked with gaining access to vulnerable data via a 2-step attack.},
  keywords={Computer science;Laboratories;Taxonomy;Buildings;User interfaces;Virtual machining;Security;Computer science education;educational tech-nology;infrastructure as code;penetration testing;Terraform},
  doi={10.1109/EDUCON54358.2023.10125250},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10803297,
  author={Bolhuis, Koen and Feitosa, Daniel and Andrikopoulos, Vasilios},
  booktitle={2024 50th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={A Catalog of Cost Patterns and Antipatterns for Infrastructure as Code}, 
  year={2024},
  volume={},
  number={},
  pages={399-406},
  abstract={Cloud adoption is historically driven by cost considerations. As the complexity of the software systems deployed on the cloud continuously increases, and with it also the need to manage larger and more complex infrastructures, Infrastructure as Code (IaC) approaches become invaluable tools. However, not many existing works have looked into the cost implications of IaC use for cloud-based software. In this work we build on an existing dataset that has looked into cost-related commits on IaC artifacts in open-source repositories in order to identify recurring solutions and ineffective practices in cost management. We present a catalog of patterns and antipatterns organizing our findings, and discuss its implication for practitioners and researchers.},
  keywords={Costs;Codes;Software systems;Complexity theory;Software engineering;cloud computing;infrastructure as code;cost awareness;software patterns;mining software repositories},
  doi={10.1109/SEAA64295.2024.00067},
  ISSN={2376-9521},
  month={Aug},}@INPROCEEDINGS{7515473,
  author={Garousi, Vahid and Herkiloglu, Kadir},
  booktitle={2016 IEEE International Conference on Software Testing, Verification and Validation (ICST)}, 
  title={Selecting the Right Topics for Industry-Academia Collaborations in Software Testing: An Experience Report}, 
  year={2016},
  volume={},
  number={},
  pages={213-222},
  abstract={The global software industry and the Software Engineering (SE) academia are two large communities. However, unfortunately, the level of joint industry-academia collaborations (IAC) in SE is still relatively very low, compared to the amount of activity in each of the two communities. Selecting the right topic for a new IAC has been reported to be challenging and often a deal-maker or-breaker for the start of IACs. Motivated by the above need, the goal of this paper is to propose experience-based guidelines from our 10+ software testing IACs in the past several years in Canada and Turkey to effectively and efficiently select right topics for IACs in software testing (also easily generalizable to other areas of SE), for the benefit of SE researchers and practitioners in starting new IACs. The experience and evidence supporting the guidelines in this paper are drawn from the authors' past projects and also seven on-going software-testing projects in the context of a large Turkish software and systems company. The topic-selection process has involved interaction with company representatives in the form of both multiple group discussions and separate face-to-face meetings while utilizing grounded-theory to find (converge to) topics which would be 'interesting' and useful from both industrial and academic perspectives. To increase the success of our topic selection process, we also utilized two other sources of information from the literature: (1) a set of four fitness criteria for topic selection in industry experiments, and (2) challenges and best practices for IAC, specific to project inception, as synthesized in a recent systematic literature review. We believe the results of this paper would be helpful for other researchers and practitioners not only in software testing but also in software engineering in general in increasing their chances of success in project inception and topic selection phase.},
  keywords={Industries;Collaboration;Software testing;Context;Software engineering;Guidelines;Software;Software engineering;software testing;industry-academia collaborations;topic selection;empirical study;grounded theory;experience report},
  doi={10.1109/ICST.2016.7},
  ISSN={},
  month={April},}@INPROCEEDINGS{10305615,
  author={Hu, Hanyang and Bu, Yani and Wong, Kristen and Sood, Gaurav and Smiley, Karen and Rahman, Akond},
  booktitle={2023 IEEE Secure Development Conference (SecDev)}, 
  title={Characterizing Static Analysis Alerts for Terraform Manifests: An Experience Report}, 
  year={2023},
  volume={},
  number={},
  pages={7-13},
  abstract={While Terraform has gained popularity to implement the practice of infrastructure as code (IaC), there is a lack of characterization of static analysis for Terraform manifests. Such lack of characterization hinders practitioners to assess how to use static analysis for their Terraform development process, as it happened for Company A, an organization who uses Terraform to create automated software deployment pipelines. In this experience report, we have investigated 491 static analysis alerts that occur for 10 open source and one proprietary Terraform repositories. From our analysis we observe: (i) 10 categories of static analysis alerts to appear for Terraform manifests, of which five are related to security, (ii) Terraform resources with dependencies to have more static analysis alerts than that of resources with no dependencies, and (iii) practitioner perceptions to vary from one alert category to another while deciding on taking actions for reported alerts. We conclude our paper by providing a list of lessons for practitioners and toolsmiths on how to improve static analysis for Terraform manifests.},
  keywords={Codes;Pipelines;Static analysis;Companies;Software;Security;configuration as code;empirical study;experience report;infrastructure as code;static analysis;terraform},
  doi={10.1109/SecDev56634.2023.00014},
  ISSN={},
  month={Oct},}@ARTICLE{8959180,
  author={Sandobalín, Julio and Insfran, Emilio and Abrahão, Silvia},
  journal={IEEE Access}, 
  title={On the Effectiveness of Tools to Support Infrastructure as Code: Model-Driven Versus Code-Centric}, 
  year={2020},
  volume={8},
  number={},
  pages={17734-17761},
  abstract={Infrastructure as Code (IaC) is an approach for infrastructure automation that is based on software development practices. The IaC approach supports code-centric tools that use scripts to specify the creation, updating and execution of cloud infrastructure resources. Since each cloud provider offers a different type of infrastructure, the definition of an infrastructure resource (e.g., a virtual machine) implies writing several lines of code that greatly depend on the target cloud provider. Model-driven tools, meanwhile, abstract the complexity of using IaC scripts through the high-level modeling of the cloud infrastructure. In a previous work, we presented an infrastructure modeling approach and tool (Argon) for cloud provisioning that leverages model-driven engineering and supports the IaC approach. The objective of the present work is to compare a model-driven tool (Argon) with a well-known code-centric tool (Ansible) in order to provide empirical evidence of their effectiveness when defining the cloud infrastructure, and the participants' perceptions when using these tools. We, therefore, conducted a family of three experiments involving 67 Computer Science students in order to compare Argon with Ansible as regards their effectiveness, efficiency, perceived ease of use, perceived usefulness, and intention to use. We used the AB/BA crossover design to configure the individual experiments and the linear mixed model to statistically analyze the data collected and subsequently obtain empirical findings. The results of the individual experiments and meta-analysis indicate that Argon is more effective as regards supporting the IaC approach in terms of defining the cloud infrastructure. The participants also perceived that Argon is easier to use and more useful for specifying the infrastructure resources. Our findings suggest that Argon accelerates the provisioning process by modeling the cloud infrastructure and automating the generation of scripts for different DevOps tools when compared to Ansible, which is a code-centric tool that is greatly used in practice.},
  keywords={Tools;Cloud computing;Software;Argon;Unified modeling language;Computational modeling;Automation;Infrastructure as code;DevOps;model-driven engineering;controlled experiments;crossover design;linear mixed model},
  doi={10.1109/ACCESS.2020.2966597},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9302794,
  author={Lin, Yuhui and Briggs, Jack and Barker, Adam},
  booktitle={2020 IEEE/ACM 13th International Conference on Utility and Cloud Computing (UCC)}, 
  title={FIFE: an Infrastructure-as-Code Based Framework for Evaluating VM Instances from Multiple Clouds}, 
  year={2020},
  volume={},
  number={},
  pages={91-100},
  abstract={To choose an optimal VM, Cloud users often need to step a process of evaluating the performance of VMs by benchmarking or running a black-box search technique such as Bayesian optimisation. To facilitate the process, we develop a generic and highly configurable Framework with Infrastructure-as-Code (IaC) support For VM Evaluation (FIFE). FIFE abstract the process as a searcher, selector, deployer and interpreter. It allows users to specify the target VM sets and evaluation objectives with JSON to automate the process. We demonstrate the use of the framework by setting up of a Bayesian optimization VM searching system. We evaluate the system with various experimental setups, i.e. different combinations of cloud provider numbers and parallel search. The results show that the search efficiency remains the same for the case when the search space is consist of VM from multiple cloud providers, and the parallel search can significantly reduce search time when the number of parallelisation is set properly.},
  keywords={Bayes methods;Cloud computing;Optimization;Search problems;Software;Benchmark testing;Uncertainty;Cloud Computing;Infrastructure-as-Code;VM Evaluation Framework;Bayesian Optimization},
  doi={10.1109/UCC48980.2020.00028},
  ISSN={},
  month={Dec},}@ARTICLE{9388795,
  author={Rahman, Akond and Williams, Laurie},
  journal={IEEE Security & Privacy}, 
  title={Different Kind of Smells: Security Smells in Infrastructure as Code Scripts}, 
  year={2021},
  volume={19},
  number={3},
  pages={33-41},
  abstract={In this article, we summarize our recent research findings related to infrastructure as code (IaC) scripts, where we have identified 67,801 occurrences of security smells that include 9,175 hard-coded passwords. We hope our work will facilitate awareness among practitioners who use IaC.},
  keywords={Computer security;Password;Servers;Encoding;IP networks;Cloud computing},
  doi={10.1109/MSEC.2021.3065190},
  ISSN={1558-4046},
  month={May},}@INPROCEEDINGS{7832899,
  author={Sharma, Tushar and Fragkoulis, Marios and Spinellis, Diomidis},
  booktitle={2016 IEEE/ACM 13th Working Conference on Mining Software Repositories (MSR)}, 
  title={Does Your Configuration Code Smell?}, 
  year={2016},
  volume={},
  number={},
  pages={189-200},
  abstract={Infrastructure as Code (IaC) is the practice of specifying computing system configurations through code, and managing them through traditional software engineering methods. The wide adoption of configuration management and increasing size and complexity of the associated code, prompt for assessing, maintaining, and improving the configuration code's quality. In this context, traditional software engineering knowledge and best practices associated with code quality management can be leveraged to assess and manage configuration code quality. We propose a catalog of 13 implementation and 11 design configuration smells, where each smell violates recommended best practices for configuration code. We analyzed 4,621 Puppet repositories containing 8.9 million lines of code and detected the cataloged implementation and design configuration smells. Our analysis reveals that the design configuration smells show 9% higher average co-occurrence among themselves than the implementation configuration smells. We also observed that configuration smells belonging to a smell category tend to co-occur with configuration smells belonging to another smell category when correlation is computed by volume of identified smells. Finally, design configuration smell density shows negative correlation whereas implementation configuration smell density exhibits no correlation with the size of a configuration management system.},
  keywords={Best practices;Software;Software engineering;Correlation;Context;Production;Data mining;Infrastructure as Code;Code quality;Configuration smells;Technical debt;Maintainability},
  doi={},
  ISSN={},
  month={May},}@INPROCEEDINGS{10092684,
  author={Zhang, Yue and Rahman, Muktadir and Wu, Fan and Rahman, Akond},
  booktitle={2023 IEEE 20th International Conference on Software Architecture Companion (ICSA-C)}, 
  title={Quality Assurance for Infrastructure Orchestrators: Emerging Results from Ansible}, 
  year={2023},
  volume={},
  number={},
  pages={1-3},
  abstract={Infrastructure as code (IaC) is the practice of automatically managing computing infrastructure at scale. Despite yielding multiple benefits for organizations, the practice of IaC is susceptible to quality concerns, which can lead to large-scale consequences. While researchers have studied quality concerns in IaC manifests, quality aspects of infrastructure orchestrators, i.e., tools that implement the practice of IaC, remain an under-explored area. A systematic investigation of defects in infrastructure orchestrators can help foster further research in the domain of IaC. From our empirical study with 22,445 commits mined from the Ansible infrastructure orchestrator we observe (i) a defect density of 17.9 per KLOC, (ii) 12 categories of Ansible components for which defects appear, and (iii) the ‘Module’ component to include more defects than the other 11 components. Based on our empirical study, we provide recommendations for researchers to conduct future research to enhance the quality of infrastructure orchestrators.},
  keywords={Quality assurance;Codes;Systematics;Correlation;Software architecture;Taxonomy;Organizations;ansible;devops;infrastructure as code},
  doi={10.1109/ICSA-C57050.2023.00073},
  ISSN={2768-4288},
  month={March},}@INPROCEEDINGS{9798991,
  author={Kaplan, Adam},
  booktitle={2021 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={A Dev-Ops Practicum Course for Information Technology Majors}, 
  year={2021},
  volume={},
  number={},
  pages={872-877},
  abstract={Since the inception of the CSUN CIT major one decade ago, the IT industry has experienced two large paradigm shifts: from on-premise virtual servers to scalable cloud-hosted services, and from full virtual machine deployment to containerized application deployment. Many IT professionals are now dev-ops specialists. Rather than install and configure individual servers, dev-ops specialists program and maintain Infrastructure as Code (IaC). In this manner, application testing, deployment, and scaling can be orchestrated automatically to respond to changing network and service conditions. Such dev-ops skills are increasingly demanded of new Information Technology graduates. Thus, we have redesigned our experimental senior-level CIT project course to be structured as a dev-ops practicum. This course now comprises six hands-on projects in web application deployment, automated testing, source code repository management, cloud hosting, infrastructure as code, and application containerization. Student outcomes were extremely positive, owing to individual rather than team projects, synchronous (virtual) lecture format as opposed to a flipped classroom, a broad set of project topics and practiced skills, and frequent one-on-one help sessions.},
  keywords={Cloud computing;Codes;Scientific computing;Pipelines;Virtual machining;Servers;Online services;dev-ops;information technology;cloud computing;Infrastructure as Code (IaC)},
  doi={10.1109/CSCI54926.2021.00204},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11126149,
  author={Mittal, Akshay and Venkatesan, Vivek},
  booktitle={2025 IEEE International Conference on Service-Oriented System Engineering (SOSE)}, 
  title={Practical Integration of Large Language Models into Enterprise CI/CD Pipelines for Security Policy Validation: An Industry-Focused Evaluation}, 
  year={2025},
  volume={},
  number={},
  pages={197-203},
  abstract={Manual security policy validation of Infrastructure-as-Code (IaC) creates bottlenecks in enterprise CI/CD pipelines, with 90% of cloud breaches involving misconfigured IaC. Traditional static analyzers struggle with evolving cloud services and custom policies. We propose a production-ready framework augmenting conventional scans with Large Language Models (LLMs) for Kubernetes, IAM, and Terraform validation. Our evaluation on 500 synthetic IaC cases shows ensemble methods achieve F1 = 0.95 at 3.1s latency. LLMs detect complex violations missed by rule-based tools, reducing manual review by 60% and maintenance by 70%. Real-world testing in Jenkins and Bamboo confirms cross-platform compatibility. We provide: (i) privacy-preserving CI/CD architecture, (ii) safeguards against prompt injection and hallucination, and (iii) phased rollout strategy for regulated enterprises balancing security and velocity.},
  keywords={Training;Codes;Reviews;Service-oriented systems engineering;Large language models;Pipelines;Manuals;Security;Bamboo;Testing;automation;cloud security;continuous deployment;continuous integration;DevSecOps;Infrastructure as Code;large language models;policy as code;security operations},
  doi={10.1109/SOSE67019.2025.00027},
  ISSN={2642-6587},
  month={July},}@INPROCEEDINGS{8780414,
  author={Moedjiono, Sardjoeni and Saepudin and Kusdaryono, Aries},
  booktitle={2018 Third International Conference on Informatics and Computing (ICIC)}, 
  title={Application Development Based On Mobile Learning Framework On Rice And Vegetable Agriculture}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={In rice and vegetable production, farmers face many obstacles, such as the problem of seed, pest and disease control, commodity prices and so on. To overcome these problems, farmers need information on the latest efficient technologies. However, farmers are also experiencing problems in accessing the information. Therefore, mobile learning approach is expected to be the solution to these problems. Mobile learning provides the advantage because mobile learning can be accessed anywhere and anytime with the support for Internet network technology using personal computers, smart phones and tablet personal computer. This study aimed to create a mobile learning framework-based application that can provide instructional information about the technology of rice and vegetable production needed by farmers. The method used was Design Science Research Methodology (DSRM) with a framework approach to instructional design ADDIE (Analysis, Design, Development, Implementation, Evaluation).},
  keywords={Testing;Agriculture;Prototypes;Process control;Mobile handsets;Diseases;Systems architecture;Mobile Learning;Mobile Learning Farming;Mobile Learning Framework;Design Science Research Methodology (DSRM);Instructional Systems Design (ISD);ADDIE (Analysis;Design;Development;Implementation;Evaluation)},
  doi={10.1109/IAC.2018.8780414},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{7476775,
  author={Adams, Bram and McIntosh, Shane},
  booktitle={2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)}, 
  title={Modern Release Engineering in a Nutshell -- Why Researchers Should Care}, 
  year={2016},
  volume={5},
  number={},
  pages={78-90},
  abstract={The release engineering process is the process that brings high quality code changes from a developer's workspace to the end user, encompassing code change integration, continuous integration, build system specifications, infrastructure-as-code, deployment and release. Recent practices of continuous delivery, which bring new content to the end user in days or hours rather than months or years, have generated a surge of industry-driven interest in the release engineering pipeline. This paper argues that the involvement of researchers is essential, by providing a brief introduction to the six major phases of the release engineering pipeline, a roadmap of future research, and a checklist of three major ways that the release engineering process of a system under study can invalidate the findings of software engineering studies. The main take-home message is that, while release engineering technology has flourished tremendously due to industry, empirical validation of best practices and the impact of the release engineering process on (amongst others) software quality is largely missing and provides major research opportunities.},
  keywords={Pipelines;Servers;Software;Organizations;Testing;Facebook;release engineering;integration;continuous integration;build system;infrastructure-as-code;deployment;release},
  doi={10.1109/SANER.2016.108},
  ISSN={},
  month={March},}@INPROCEEDINGS{8780410,
  author={Amalia, Amalia and Sharif, Amer and Haisar, Fikri and Gunawan, Dani and Nasution, Benny B},
  booktitle={2018 Third International Conference on Informatics and Computing (ICIC)}, 
  title={Meme Opinion Categorization by Using Optical Character Recognition (OCR) and Naïve Bayes Algorithm}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={Generally, a meme is an image which is produced by the society which is used to comment a certain event, followed with a particular template from the decent online images. The distribution of meme becomes the phenomenon and very popular in the last few years. The problem is, some of these memes contain negative contents to harm others. One type of meme image that trends in social media is aimed at government, either to support the performance of the government or to insinuate and dislike of a government. Therefore, Political view by the citizen can be identified by viral memes on the internet. The aim of this research is classifying the types of a meme by applying image processing and OCR Tesseract which are combined with Naïve Bayes Algorithm. OCR Tesseract is required to recognize text in an image, meanwhile Naive Bayes algorithm which is used to find the highest probability to classify the testing dataset into the correct category. This research uses a meme as the dataset. The result is meme which is successfully classified. The accuracy depends on the OCR result which utilizes tesseract engine.},
  keywords={Optical character recognition software;Government;Social networking (online);Character recognition;Engines;Sentiment analysis;Optical imaging;sentiment analysis;meme classification;ocr;naïve Bayes},
  doi={10.1109/IAC.2018.8780410},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{7037674,
  author={Scheuner, Joel and Leitner, Philipp and Cito, Jürgen and Gall, Harald},
  booktitle={2014 IEEE 6th International Conference on Cloud Computing Technology and Science}, 
  title={Cloud Work Bench -- Infrastructure-as-Code Based Cloud Benchmarking}, 
  year={2014},
  volume={},
  number={},
  pages={246-253},
  abstract={In order to optimally deploy their applications, users of Infrastructure-as-a-Service clouds are required to evaluate the costs and performance of different combinations of cloud configurations to find out which combination provides the best service level for their specific application. Unfortunately, benchmarking cloud services is cumbersome and error-prone. In this paper, we propose an architecture and concrete implementation of a cloud benchmarking Web service, which fosters the definition of reusable and representative benchmarks. In distinction to existing work, our system is based on the notion of Infrastructure-as-Code, which is a state of the art concept to define IT infrastructure in a reproducible, well-defined, and testable way.},
  keywords={Benchmark testing;Servers;Libraries;Standards;Cloud computing;Schedules;Cloud Computing;Benchmarking;IaaS;IaC;Virtual Machines},
  doi={10.1109/CloudCom.2014.98},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9825800,
  author={Rahman, Akond and Sharma, Tushar},
  booktitle={2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={Lessons from Research to Practice on Writing Better Quality Puppet Scripts}, 
  year={2022},
  volume={},
  number={},
  pages={63-67},
  abstract={Infrastructure as Code (IaC) scripts, such as Puppet scripts, provide practitioners the opportunity to provision computing infrastructure automatically at scale. Poorly written IaC scripts impact various facets of quality (such as security and maintainability) and, in turn, may lead to serious consequences. Many of the ill-effects can be avoided or rectified easily by following recommendations derived from research and best practices gleaned from experience. While researchers have investigated methods to improve quality aspects of Puppet scripts, such research needs to be summarized and synthesized for industry practitioners. In this article, we summarize recent research in the IaC domain by discussing key quality issues, specifically security and maintainability smells, that may arise in an IaC script. We also mine open-source repositories from three organizations (Mozilla, Openstack, and Wikimedia) and report our observations on the identified smells. Furthermore, we also synthesize recommendations from the literature for software practitioners that could improve the quality of IaC scripts. Software development teams dealing with large computing infrastructure can get benefited from the actionable recommended practices. In addition, researchers in the domain may use this study to find opportunities to improve the state-of-the-art.},
  keywords={Industries;Codes;Pipelines;Organizations;Writing;Particle measurements;Frequency measurement;puppet;code smell;infrastructure as code;devops;quality;empirical study;bugs;security},
  doi={10.1109/SANER53432.2022.00019},
  ISSN={1534-5351},
  month={March},}@ARTICLE{10934743,
  author={Masoumzadeh, Sogol and Saavedra, Nuno and Maipradit, Rungroj and Wei, Lili and Ferreira, João F. and Varró, Dániel and McIntosh, Shane},
  journal={IEEE Transactions on Software Engineering}, 
  title={Do Experts Agree About Smelly Infrastructure?}, 
  year={2025},
  volume={51},
  number={5},
  pages={1472-1486},
  abstract={Code smells are anti-patterns that violate code understandability, re-usability, changeability, and maintainability. It is important to identify code smells and locate them in the code. For this purpose, automated detection of code smells is a sought-after feature for development tools; however, the design and evaluation of such tools depends on the quality of oracle datasets. The typical approach for creating an oracle dataset involves multiple developers independently inspecting and annotating code examples for their existing code smells. Since multiple inspectors cast votes about each code example, it is possible for the inspectors to disagree about the presence of smells. Such disagreements introduce ambiguity into how smells should be interpreted. Prior work has studied developer perceptions of code smells in traditional source code; however, smells in Infrastructure-as-Code (IaC) have not been investigated. To understand the real-world impact of disagreements among developers and their perceptions of IaC code smells, we conduct an empirical study on the oracle dataset of GLITCH—a state-of-the-art detection tool for security code smells in IaC. We analyze GLITCH's oracle dataset for code smell issues, their types, and individual annotations of the inspectors. Furthermore, we investigate possible confounding factors associated with the incidences of developer misaligned perceptions of IaC code smells. Finally, we triangulate developer perceptions of code smells in traditional source code with our results on IaC. Our study reveals that unlike developer perceptions of smells in traditional source code, their perceptions of smells in IaC are more substantially impacted by subjective interpretation of smell types and their co-occurrence relationships. For instance, the interpretation of admins by default, empty passwords, and hard-coded secrets varies considerably among raters and are more susceptible to misidentification than other IaC code smells. Consequently, the manual identification of IaC code smells involves annotation disagreements among developers—46.3% of studied IaC code smell incidences have at least one dissenting vote among three inspectors. Meanwhile, only 1.6% of code smell incidences in traditional source code are affected by inspector bias stemming from these disagreements. Hence, relying solely on the majority voting, would not fully represent the breadth of interpretation of the IaC under scrutiny.},
  keywords={Codes;Source coding;Labeling;Security;Passwords;Annotations;Training;Software;Servers;Imaging;Code smells;infrastructure as code;developer perceptions;oracle datasets},
  doi={10.1109/TSE.2025.3553383},
  ISSN={1939-3520},
  month={May},}@INPROCEEDINGS{10851730,
  author={Gupta, Tushar},
  booktitle={2024 8th Cyber Security in Networking Conference (CSNet)}, 
  title={Kubernetes-Driven Network Security for Distributed ACL Management}, 
  year={2024},
  volume={},
  number={},
  pages={236-242},
  abstract={Access Control List (ACL) management in complex, distributed network environments poses significant challenges for organizations relying on heterogeneous infrastructures. This paper proposes a novel architecture leveraging Infrastructure as Code principles, containerization, and Kubernetes orchestration to automate and streamline ACL management at scale. Our solution incorporates a CI/CD pipeline for ACL generation, utilizing Capirca for platform-agnostic policy definition and Docker for consistent packaging. A Kubernetes Deployment Controller manages the safe rollout of ACLs across diverse network devices, employing a phased approach with canary deployments. A Drift Detection Controller ensures continuous compliance by monitoring and rectifying unauthorized changes. The architecture integrates with external systems like NetBox for efficient device inventory management. By automating the entire ACL lifecycle, our approach significantly reduces manual errors, enhances security posture, and improves operational efficiency. Performance evaluation reveals strong scalability, with optimization opportunities for large-scale deployments. This work contributes to the evolving field of network security automation, offering a framework for managing network security policies in modern, complex infrastructures.},
  keywords={Performance evaluation;Access control;Automation;Scalability;Pipelines;Network security;Packaging;Scheduling;Time factors;Optimization;Access Control Lists (ACLs);Network Security;Kubernetes;Infrastructure as Code (IaC);Continuous Integration/Continuous Deployment (CI/CD)},
  doi={10.1109/CSNet64211.2024.10851730},
  ISSN={2768-0029},
  month={Dec},}@INPROCEEDINGS{8306001,
  author={Song, Dong Hun and Seo, Yongjin and Kim, Hyeon Soo},
  booktitle={2017 24th Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={Test Environment Construction Method Using Parameterized Test Environments}, 
  year={2017},
  volume={},
  number={},
  pages={677-682},
  abstract={To achieve test automation, all stages such as the creation of test cases and data necessary to execute tests and the construction of test environments should be executed without any involvement of the tester. However, among the stages, the test environment construction process cannot be easily automated because it is executed through the tester's physical acts. To solve this problem, existing studies construct test environments using technologies such as virtualization or Infrastructure as Code. However, existing studies automate only a part of the test environment construction process. Therefore, this paper proposes the parameterized test environments, which are test environments expressed by parameter sets that characterize test environments. When this method is used, test environments can be constructed with only the inputs of parameters so that the problem of test environment construction, which was an obstacle to test automation, can be improved.},
  keywords={Libraries;Java;Automation;Virtualization;Software;Virtual machining;Test Automation;Test Environment;Parameterized Test Environment;Infrastructure as Code;Docker},
  doi={10.1109/APSEC.2017.84},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8780465,
  author={Santoso, Halim Budi and Delima, Rosa and Wahyuni},
  booktitle={2018 Third International Conference on Informatics and Computing (ICIC)}, 
  title={Webuse Usability Testing for Farmer and Farmer Group Data Collection System}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Farmers are the main actors and play significant role to develop agriculture. They cultivate the land, grow the plant, and harvest the crop. Farmers gather with its community and found farmers Group. A system to collect data from farmers and its Group has been developed. This system is to help data collection for farmer's personal identity, farmer Group organization detail, and farmer Group membership. This system also covers organization structure for farmer Group. This system should be tested to know system usability level before it is deployed. Website Evaluation Tool (Webuse) method was used to test system usability. The respondents of this test are farmers and farmers Group from two regions, Temanggung and Gombong, Central Java. This study found that this system got Good level of usability. But, in the administration tools, the system got Moderate level. The test also gives some recommendations to improve usability level of the system. There are some weaknesses should be enhanced, including language consistency, coloring consistency, button and link consistency, menu consistency, and menu accuracy. Recommendation is built based on the data analysis.},
  keywords={Usability;Testing;Data collection;Organizations;Agriculture;Task analysis;Tools;Usability;Usability Level;Usability Test;Recommendation;WEBUSE;Farmer Group Data Collection System;Information Technology for Agriculture},
  doi={10.1109/IAC.2018.8780465},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10083442,
  author={Golis, Tomáš and Dakić, Pavle and Vranić, Valentino},
  booktitle={2022 IEEE 16th International Scientific Conference on Informatics (Informatics)}, 
  title={Creating Microservices and using infrastructure as code within the CI/CD for dynamic container creation}, 
  year={2022},
  volume={},
  number={},
  pages={114-119},
  abstract={Many current companies tend to use microservice architecture. The reasons are clear: speed, efficiency, flexibility, autonomy, and ease of use. However, to use them effectively, the implementation of containers and clusters requires a well-built infrastructure. This requires a pattern of version development and deployment known as continuous integration/continuous deployment (CI/CD). CI/CD allows organizations to deliver software to production quickly and efficiently, identify defects, and ensure that the code meets best practices. This document will cover the design of custom CI/CD software following best practices for the processes of building, testing, and deploying an application to a server. The purpose of the research is a case study and an understanding of the technologies required to create a complex microservices-based infrastructure.},
  keywords={Codes;Microservice architectures;Production;Containers;IEEE Fellows;Software;Servers;CI/CD;Pipeline Scripts;A research study;Soft-ware;YAML},
  doi={10.1109/Informatics57926.2022.10083442},
  ISSN={},
  month={Nov},}@ARTICLE{10102545,
  author={Rahman, Akond and Parnin, Chris},
  journal={IEEE Transactions on Software Engineering}, 
  title={Detecting and Characterizing Propagation of Security Weaknesses in Puppet-Based Infrastructure Management}, 
  year={2023},
  volume={49},
  number={6},
  pages={3536-3553},
  abstract={Despite being beneficial for managing computing infrastructure automatically, Puppet manifests are susceptible to security weaknesses, e.g., hard-coded secrets and use of weak cryptography algorithms. Adequate mitigation of security weaknesses in Puppet manifests is thus necessary to secure computing infrastructure that are managed with Puppet manifests. A characterization of how security weaknesses propagate and affect Puppet-based infrastructure management, can inform practitioners on the relevance of the detected security weaknesses, as well as help them take necessary actions for mitigation. We conduct an empirical study with 17,629 Puppet manifests with Taint Tracker for Puppet Manifests (TaintPup). We observe 2.4 times more precision, and 1.8 times more F-measure for TaintPup, compared to that of a state-of-the-art security static analysis tool. From our empirical study, we observe security weaknesses to propagate into 4,457 resources, i.e, Puppet-specific code elements used to manage infrastructure. A single instance of a security weakness can propagate into as many as 35 distinct resources. We observe security weaknesses to propagate into 7 categories of resources, which include resources used to manage continuous integration servers and network controllers. According to our survey with 24 practitioners, propagation of security weaknesses into data storage-related resources is rated to have the most severe impact for Puppet-based infrastructure management.},
  keywords={Security;Codes;Static analysis;Passwords;Syntactics;Encryption;Memory;Configuration as code;devops;devsecops;empirical study;infrastructure as code;puppet;static analysis},
  doi={10.1109/TSE.2023.3265962},
  ISSN={1939-3520},
  month={June},}@INPROCEEDINGS{9978237,
  author={Palma, Stefano Dalla and Di Nucci, Dario and Tamburri, Damian},
  booktitle={2022 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Defuse: A Data Annotator and Model Builder for Software Defect Prediction}, 
  year={2022},
  volume={},
  number={},
  pages={479-483},
  abstract={We propose a language-agnostic tool for software defect prediction, called DEFUSE. The tool automatically collects and classifies failure data, enables the correction of those classifications, and builds machine learning models to detect defects based on those data. We instantiated the tool in the scope of Infrastructure-as-Code, the DevOps practice enabling management and provisioning of infrastructure through the definition of machine-readable files. We present its architecture and provide examples of its application.Demo video: https://youtu.be/37mmLdCX3jU.},
  keywords={Software maintenance;Costs;Instruments;Machine learning;Computer architecture;Predictive models;Maintenance engineering;defect prediction;machine learning;mining software repositories},
  doi={10.1109/ICSME55016.2022.00063},
  ISSN={2576-3148},
  month={Oct},}@INPROCEEDINGS{10916477,
  author={Tkáč, Andrej and Bobák, Martin},
  booktitle={2025 Cybernetics & Informatics (K&I)}, 
  title={Virtual Infrastructure Management}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The paper provides a comparative analysis of virtual infrastructure management and explores Infrastructure as Code (IaC) tools. The analysis identifies a missing OpenTofu component from the Terraform ecosystem - a management platform. The paper result is a proof of concept for the management platform leveraging the OpenTofu tool, which aims to be a complementary component for OpenTofu similar to Terraform and Terraform Cloud/HCP Terraform. The platform offers a graphical user interface through which a user can manage virtual infrastructures. It allows the use of configurations in the declarative Terraform Configuration Language (HCL) format for deployment or modification of infrastructures, along with adjustable values outside the given configuration. The user can execute an apply or destroy action with a given configuration and variables, prompting the management platform to create a plan by invoking OpenTofu.},
  keywords={Cloud computing;Codes;Ecosystems;Prototypes;Graphical user interfaces;virtual infrastructures;cloud;infrastructure as code;opentofu;terraform},
  doi={10.1109/KI64036.2025.10916477},
  ISSN={2767-875X},
  month={Feb},}@INPROCEEDINGS{10601420,
  author={Abbas, Syed Imran and Garg, Ankit},
  booktitle={2024 3rd International Conference on Sentiment Analysis and Deep Learning (ICSADL)}, 
  title={AIOps in DevOps: Leveraging Artificial Intelligence for Operations and Monitoring}, 
  year={2024},
  volume={},
  number={},
  pages={64-70},
  abstract={This research work investigates the significant effects of implementing AIOps (Artificial Intelligence for IT Operations) on many aspects of system management and IT infrastructure performance improvement. AIOps led to a 15% improvement in anomaly detection accuracy, a 30% decrease in system outages, a 50% increase in incident management effectiveness, and a 15% reduction in cloud infrastructure costs. These developments show how AI-driven solutions have a big influence on IT operations and hold the promise of more dependable and effective systems. A hybrid approach combining supervised and unsupervised learning technique is proposed for anomaly detection, showcasing improved accuracy compared to traditional rule-based methods. Predictive analytics using time series analysis and forecasting models enables proactive issue resolution by detecting resource constraints and preventing performance bottlenecks. NLP techniques are explored for automating incident management, resulting in significant time savings and improved accuracy.},
  keywords={Sentiment analysis;Accuracy;DevOps;Costs;System performance;Time series analysis;Artificial intelligence;IaC;API;AWS;Azure;Cloud Computing;Artificial intelligence;NLP},
  doi={10.1109/ICSADL61749.2024.00016},
  ISSN={},
  month={March},}@ARTICLE{9380710,
  author={Werner, Colin and Li, Ze Shi and Lowlind, Derek and Elazhary, Omar and Ernst, Neil and Damian, Daniela},
  journal={IEEE Transactions on Software Engineering}, 
  title={Continuously Managing NFRs: Opportunities and Challenges in Practice}, 
  year={2022},
  volume={48},
  number={7},
  pages={2629-2642},
  abstract={Non-functional requirements (NFR), which include performance, availability, and maintainability, are vitally important to overall software quality. However, research has shown NFRs are, in practice, poorly defined and difficult to verify. Continuous software engineering practices, which extend agile practices, emphasize fast paced, automated, and rapid release of software that poses additional challenges to handling NFRs. In this multi-case study we empirically investigated how three organizations, for which NFRs are paramount to their business survival, manage NFRs in their continuous practices. We describe four practices these companies use to manage NFRs, such as offloading NFRs to cloud providers or the use of metrics and continuous monitoring, both of which enable almost real-time feedback on managing the NFRs. However, managing NFRs comes at a cost—as we also identified a number of challenges these organizations face while managing NFRs in their continuous software engineering practices. For example, the organizations in our study were able to realize an NFR by strategically and heavily investing in configuration management and infrastructure as code, in order to offload the responsibility of NFRs; however, this offloading implied potential loss of control. Our discussion and key research implications show the opportunities, trade-offs, and importance of the unique give-and-take relationship between continuous software engineering and NFRs. Research artifacts may be found at https://doi.org/10.5281/zenodo.3376342.},
  keywords={Organizations;Software;Software engineering;Testing;Tools;Requirements engineering;Interviews;Non-functional requirements;continuous software engineering},
  doi={10.1109/TSE.2021.3066330},
  ISSN={1939-3520},
  month={July},}@INPROCEEDINGS{11014940,
  author={Duarte, Carlos Eduardo},
  booktitle={2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C)}, 
  title={Automated Microservice Pattern Instance Detection Using Infrastructure-as-Code Artifacts and Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={161-166},
  abstract={Documenting software architecture is essential to preserve architecture knowledge, even though it is frequently costly. Architecture pattern instances, including microservice pattern instances, provide important structural software information. Practitioners should document this information to prevent knowledge vaporization. However, architecture patterns may not be detectable by analyzing source code artifacts, requiring the analysis of other types of artifacts. Moreover, many existing pattern detection instance approaches are complex to extend. This article presents our ongoing PhD research, early experiments, and a prototype for a tool we call MicroPAD for automating the detection of microservice pattern instances. The prototype uses Large Language Models (LLMs) to analyze Infrastructure-as-Code (IaC) artifacts to aid detection, aiming to keep costs low and maximize the scope of detectable patterns. Early experiments ran the prototype thrice in 22 GitHub projects. We verified that 83% of the patterns that the prototype identified were in the project. The costs of detecting the pattern instances were minimal. These results indicate that the approach is likely viable and, by lowering the entry barrier to automating pattern instance detection, could help democratize developer access to this category of architecture knowledge. Finally, we present our overall research methodology, planned future work, and an overview of MicroPAD's potential industrial impact.},
  keywords={Costs;Software architecture;Large language models;Source coding;Microservice architectures;Prototypes;Computer architecture;Software;Knowledge management;Software development management;software architecture;architecture patterns;architecture documentation;pattern identification;knowledge retrieval;microservices;microservice patterns},
  doi={10.1109/ICSA-C65153.2025.00030},
  ISSN={2768-4288},
  month={March},}@INPROCEEDINGS{11025653,
  author={Bühler, Christoph and Spielmann, David and Meier, Roland and Salvaneschi, Guido},
  booktitle={2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR)}, 
  title={TerraDS: A Dataset for Terraform HCL Programs}, 
  year={2025},
  volume={},
  number={},
  pages={654-658},
  abstract={Infrastructure as Code (IaC) aims to automate infrastructure management by enabling the definition of infrastructure configurations in programs, rather than manually configuring hardware or cloud resources. Terraform is one of the most widely used IaC tools, gaining significant traction in recent years, as highlighted by its large and active user community and widespread adoption in both open-source and enterprise environments. Terraform’s code is written in the HashiCorp Configuration Language (HCL), which defines the infrastructure in a declarative manner. Despite the widespread adoption of Terraform, there is no large-scale dataset available for researchers to study IaC Terraform programs systematically. To address this gap, we present TerraDS, the first dataset of publicly available Terraform programs written in HCL. TerraDS contains the HCL code and the metadata of 67,360 open source repositories with permissive open-source licenses. The dataset includes 279,344 Terraform modules with 1,773,991 registered resources, all compiled into a reusable archive ($\sim 335 \mathrm{MB}$).},
  keywords={Codes;Source coding;Stars;Static analysis;Metadata;Licenses;Open source software;Testing;Software development management;Indexing;Cloud Computing;Configuration Management;Open Source Software;Static Analysis},
  doi={10.1109/MSR66628.2025.00101},
  ISSN={2574-3864},
  month={April},}@INPROCEEDINGS{10295601,
  author={Bahaweres, Rizal Broer and Muhammad Najib, Farhan},
  booktitle={2023 10th International Conference on Electrical Engineering, Computer Science and Informatics (EECSI)}, 
  title={Provisioning of Disaster Recovery with Terraform and Kubernetes: A Case Study on Software Defect Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={183-189},
  abstract={Natural disasters and device failures can damage organizational infrastructure and data, giving substantial issues for modern firms that rely on information systems and technology, especially cloud-based solutions. To maintain firm operations, information and technology systems must be protected. The conventional catastrophic recovery technique trades speed, complexity, and cost. Infrastructure as a Code (IaC) may improve complex disaster recovery operations in firms. This study analyzes Infrastructure as Code as a potential solution to cloud disaster recovery issues. The study examines how Terraform and Kubernetes affect cloud-based disaster recovery procedures and durations by simulating a disaster event. The findings of the study indicate that the implementation of Terraform for constructing intricate infrastructure, such as a deployment pipeline, has a notable impact on the reduction of required steps and the time required. The number of steps is significantly reduced to a single step and reduce the time required by 235% when compared to manual manufacturing. Terraform demonstrates its ability to optimise disaster recovery. The utilization of Kubernetes has been found to significantly enhance the efficiency of software deployment. The use of Kubernetes resulting in a notable reduction in deployment time by approximately 530%. This improvement in deployment speed is expected to have implications for the software recovery process in the event of a disaster. The duration of catastrophe recovery using Terraform and Kubernetes is 190% shorter compared to the duration of manual recovery. It reduces the use of unutilized surplus infrastructure resources and makes rebuilding easier, but it takes longer than standby infrastructure.},
  keywords={Electrical engineering;Computer science;Codes;Costs;Pipelines;Manuals;Software;Infrastructure as a Code;Kubernetes;Terraform;Disaster Recovery;Software Defect Predicition},
  doi={10.1109/EECSI59885.2023.10295601},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11111516,
  author={Yelo-Sarrión, J. and Sieber, J. and Gurevich, S.V. and Javaloyes, J.},
  booktitle={2025 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC)}, 
  title={A Time-Delayed Renewal Model for Kerr Frequency Combs}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The main workhorses of analysis and numerical simulations of Kerr optical frequency combs have been the Ikeda map (IM), as well as its mean-field approximation, the Lugiato-Lefever equation (LLE) [1], [2]. Each approach has its limitations: e.g., the solutions of the IM do not necessarily verify the continuity of the field, and it has been so far difficult to perform bifurcation analysis of the IM using numerical path-continuation methods. Similarly, even if the LLE is suitable for bifurcation analysis, it does not take into account multiple modes of cavity, although an alternative strategy was proposed in [3]. Furthermore, and contrary to the IM, the mean-field approximation in the LLE precludes the appearance of Kelly sidebands which are an experimental reality [4].},
  keywords={Time-frequency analysis;Europe;Bifurcation;Numerical simulation;Amplitude modulation;Optical harmonic generation;Mathematical models},
  doi={10.1109/CLEO/Europe-EQEC65582.2025.11111516},
  ISSN={2833-1052},
  month={June},}@INPROCEEDINGS{10859822,
  author={Ragothaman, Hariharan and Udayakumar, Saai Krishnan},
  booktitle={2024 IEEE 2nd International Conference on Electrical Engineering, Computer and Information Technology (ICEECIT)}, 
  title={Optimizing Service Deployments With NLP Based Infrastructure Code Generation - An Automation Framework}, 
  year={2024},
  volume={},
  number={},
  pages={216-221},
  abstract={In this paper we discuss how we combine natural language processing (NLP) techniques and infrastructure as code (IaC) tools like Terraform; to build a framework that converts natural language queries into Terraform code, enabling users to generate multi-cloud infrastructure configurations. We detail the construction of the NLP engine, the implementation for benchmarking various context-aware models, and the validation and execution of code, which leads to the integration of the model with DevSecOps pipelines. For benchmarking, we test models such as RoBERTa, GPT-4, T5 and Llama on their performance in terms of accuracy, latency and capacity to translate complex infrastructure requirements given as conversational queries into deployable terraform configuration. On one hand, this framework enhances the accessibility and efficiency of writing Terraform code (TF-code), while on the other, it results in a 73% reduction in the overall time required to bring a service from development to production deployment, relative to comparable efforts performed through manual processes. This modularity allows the entire framework to be customized and integrated into larger systems, especially in a DevSecOps context where flexibility and extensibility are crucial. Finally, the paper provides both technical insights and practical benchmarks, offering a comprehensive solution for organizations seeking to optimize cloud service deployment pipelines using advanced NLP techniques.},
  keywords={Training;Adaptation models;Codes;Automation;Computational modeling;Pipelines;Manuals;Benchmark testing;Natural language processing;Context modeling;Natural Language Processing (NLP);Infrastructure as Code (IaC);Terraform;Context-Aware NLP Models;DevSecOps Pipelines;Cloud Provisioning},
  doi={10.1109/ICEECIT63698.2024.10859822},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10601402,
  author={Abbas, Syed Imran and Singh, Monika},
  booktitle={2024 3rd International Conference on Sentiment Analysis and Deep Learning (ICSADL)}, 
  title={Enhancing Operational Efficiency and User Experience in Virtual Workspaces: A Comprehensive Analysis and Action Plan}, 
  year={2024},
  volume={},
  number={},
  pages={52-58},
  abstract={The effectiveness and user experience of virtual collaboration technologies become critical as the distant work environment changes. The conclusions and recommendations drawn from a thorough examination of the “Virtual Workspace” feature—a crucial part of the cloud-based collaboration capabilities offered by a fictional SaaS company—are summarized in this abstract. Key operational obstacles were found by the investigation, including inconsistent user engagement, platform responsiveness, and connectivity problems. The diverse range of experiences had by prominent individuals like Elon Musk, Sundar Pichai, and others highlights the complexity of these issues. The remedies that are suggested take a comprehensive approach, addressing technical issues by means of network infrastructure upgrades, honing platform responsiveness through focused development sprints, and encouraging user participation by means of feature improvements. Establishing an ongoing feedback loop and monitoring system also guarantees proactive problem detection and fixing.},
  keywords={Deep learning;Feedback loop;Sentiment analysis;Cloud computing;Collaboration;User experience;Remote working;IaC;AWS;Azure;Cloud Computing;IoT;DevOps},
  doi={10.1109/ICSADL61749.2024.00014},
  ISSN={},
  month={March},}@INPROCEEDINGS{8452102,
  author={Rahman, Akond and Partho, Asif and Morrison, Patrick and Williams, Laurie},
  booktitle={2018 IEEE/ACM 4th International Workshop on Rapid Continuous Software Engineering (RCoSE)}, 
  title={What Questions Do Programmers Ask about Configuration as Code?}, 
  year={2018},
  volume={},
  number={},
  pages={16-22},
  abstract={Configuration as code (CaC) tools, such as Ansible and Puppet, help software teams to implement continuous deployment and deploy software changes rapidly. CaC tools are growing in popularity, yet what challenges programmers encounter about CaC tools, have not been characterized. A systematic investigation on what questions are asked by programmers, can help us identify potential technical challenges about CaC, and can aid in successful use of CaC tools. The goal of this paper is to help current and potential configuration as code (CaC) adoptees in identifying the challenges related to CaC through an analysis of questions asked by programmers on a major question and answer website. We extract 2,758 Puppet-related questions asked by programmers from January 2010 to December 2016, posted on Stack Overflow. We apply qualitative analysis to identify the questions programmers ask about Puppet. We also investigate the trends in questions with unsatisfactory answers, and changes in question categories over time. From our empirical study, we synthesize 16 major categories of questions. The three most common question categories are: (i) syntax errors, (ii) provisioning instances; and (iii) assessing Puppet's feasibility to accomplish certain tasks. Three categories of questions that yield the most unsatisfactory answers are (i) installation, (ii) security, and (iii) data separation.},
  keywords={Tools;Sorting;Software engineering;Software;Market research;Mathematical model;Programming;challenge;configuration as code;continuous deployment;devops;infrastructure as code;programming;puppet;question;stack overflow},
  doi={},
  ISSN={},
  month={May},}@INPROCEEDINGS{9377755,
  author={Vuppalapati, Chandrasekar and Ilapakurti, Anitha and Chillara, Karthik and Kedari, Sharat and Mamidi, Vanaja},
  booktitle={2020 IEEE International Conference on Big Data (Big Data)}, 
  title={Automating Tiny ML Intelligent Sensors DevOPS Using Microsoft Azure}, 
  year={2020},
  volume={},
  number={},
  pages={2375-2384},
  abstract={Microsoft Azure DevOps is a robust ,cross platform and powerful automation engine for script-based automation tools. Azure DevOPS enables to build, test, and deploy Cloud Native and/or Non-Cloud Native applications. The core principle and chief advantage that Azure DevOps provide are the availability of automation techniques such as infrastructure as code and the seamless integration of verifiable frameworks such as Machine Learning Operations (MLOps) with the DevOps automated pipelines to provision and configure the infrastructure that applications need to run.With the increase in application complexity and with the infusion of Machine Learning (ML) and Artificial Intelligence (AI) techniques as part of the software development lifecycle, the Azure DevOps is the most important framework that many organizations are rapidly progressing to incorporate it in their business processes to reduce the cost of building product and improve customer success.As part of the paper, we would like to propose a novel DevOps framework for building intelligent Tiny ML dairy agriculture sensors and the advantages that DevOps provide to develop high quality product in the most cost-efficient manner and serve small scale farmers who are at the bottom economic pyramid.},
  keywords={Automation;Planets;Buildings;Machine learning;Tools;Big Data;Intelligent sensors;Azure;DevOps;Infrastructure as code;CI/CD},
  doi={10.1109/BigData50022.2020.9377755},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8326951,
  author={Sankaranarayanan, Sowmya and Vinod, Kulkarni Chaitali and Sreekumar, Aswanth and Laxminidhi, Tonse and Singhal, Vipul and Chauhan, Rajat},
  booktitle={2018 31st International Conference on VLSI Design and 2018 17th International Conference on Embedded Systems (VLSID)}, 
  title={Single Inductor Dual Output Buck Converter for Low Power Applications and Its Stability Analysis}, 
  year={2018},
  volume={},
  number={},
  pages={347-352},
  abstract={The applications like sensor nodes and wearables, which run on coin/button cell and/or harvested energy source need small form factor and very low power consumption. A single inductor multiple output (SIMO) converter provides saving on inductor count and hence becomes a right choice for such applications. This paper presents a single inductor dual output (SIDO) buck converter targeting light load applications. The architecture uses discontinuous conduction mode (DCM) with pulse frequency modulation (PFM) control and the switching scheme ensures almost zero cross-regulation. The proposed converter is simulated in 180 nm CMOS technology showing zero cross-regulation. An efficiency of above 88% is achieved considering inductor and package losses in load range of micro-amperes to a few milli-amperes. This paper also presents a detailed stability analysis and model for the selected SIMO architecture along with some interesting observations and inferences derived from this analysis.},
  keywords={Buck converters;Inductors;Stability analysis;Computer architecture;Switches;Load modeling;Clocks;Low power;DC-DC converter;buck;SIMO;stability;DCM;PFM;IAC},
  doi={10.1109/VLSID.2018.88},
  ISSN={2380-6923},
  month={Jan},}@INPROCEEDINGS{5970350,
  author={Doshkov, Dimitar and Kaprykowsky, Hagen and Ndjiki-Nya, Patrick},
  booktitle={2011 IEEE 10th IVMSP Workshop: Perception and Visual Signal Analysis}, 
  title={Identification and discussion of open issues in perceptual video coding based on image analysis and completion}, 
  year={2011},
  volume={},
  number={},
  pages={30-35},
  abstract={Perceptual video coding (VC) based on image analysis and completion (IAC) has enjoyed increasing awareness during the past few years. Many related approaches have been proposed that follow diverging strategies: from full compatibility to hybrid block transform coding to alternative codec design. Hence, in this paper, the most significant issues in IAC coding will be identified and their relevance for the IAC VC design highlighted. It will be analyzed where the most promising pathways lie and justified why others may be limited in their potentialities. Discussions will be substantiated using new methods developed by the authors for block-based and region-based IAC coding additionally to the state-of-the-art approaches.},
  keywords={Video coding;Distortion measurement;Image coding;Decoding;Encoding;Visualization;Algorithm design and analysis;Video coding;image analysis and completion;texture analysis and synthesis;perceptual quality assessment},
  doi={10.1109/IVMSPW.2011.5970350},
  ISSN={},
  month={June},}@INPROCEEDINGS{11155568,
  author={Darom, Sovannareach and Horn, Daneth and Prum, Sophea},
  booktitle={2025 International Conference on Software, Knowledge, Information Management & Applications (SKIMA)}, 
  title={Workflow Optimization Using Hybrid Methodologies for Mitigating Overtasking}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Overtasking, characterized by excessive workload and task accumulation, is a significant challenge that impacts productivity, diminishes work quality, and contributes to employee burnout. In today’s dynamic and fast-paced work environments, addressing overtasking requires a strategic and systematic approach to workflow optimization. This paper explores key strategies, including conducting comprehensive workflow audits, prioritizing tasks, leveraging automation tools, improving communication, ensuring equitable resource allocation, and fostering a culture of feedback. It emphasizes the importance of continuous evaluation and adaptive workflow practices to maintain long-term efficiency and employee well-being. By implementing these approaches, organizations can streamline processes, enhance operational efficiency, and create a sustainable work environment that balances productivity with employee satisfaction. The findings highlight that a proactive and holistic approach to workflow optimization is essential for mitigating overtasking and achieving long-term organizational success.},
  keywords={Productivity;Root cause analysis;Visualization;Automation;Systematics;Organizations;Planning;Continuous improvement;Resource management;Optimization;WorkFlow Audits;Prioritizing Tasks;Leveraging Automation Tools;Improving Communication;Resource Allocation;Culture Of Feedback;DevOps;Agile Methodology;Kaizen Mindset;Kaikaku;Daily Standups;Retrospectives;Radical Changes;Kanban Board;One-on-One Process;Scrum Master;Slack;Jira;Confluence;Feedback Framework;GitLab;Ansible;Root Cause Analysis (RCA);Overtime Reduction Rate (O.R.R);Current Overall Hours (C.O.H);Previous Overall Hours (P.O.H);Task Completion Rate (T.C.R);Number of Tasks Completed on Time (N.T.C);Total Number of Tasks (T.N.T);Continuous Integration and Continuous Delivery (CI/CD);Infrastructure as Code (IaC)},
  doi={10.1109/SKIMA66621.2025.11155568},
  ISSN={},
  month={June},}@INPROCEEDINGS{11025635,
  author={Sobhani, Ghazal and Haque, Israat and Sharma, Tushar},
  booktitle={2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR)}, 
  title={It Works (only) on My Machine: A Study on Reproducibility Smells in Ansible Scripts}, 
  year={2025},
  volume={},
  number={},
  pages={384-395},
  abstract={Infrastructure as Code (IaC) automates the creation, configuration, management, and monitoring of computing infrastructure through code. One of the key principles that IaC promises is repeatability and reproducibility. However, certain programming practices in IaC platforms, especially those that allow imperative configuration, such as Ansible, hinder reproducibility in IaC scripts. This study, first, identifies such programming practices that we refer to as reproducibility smells by conducting a comprehensive multi-vocal literature review and propose a first-ever validated catalog of reproducibility smells for IaC scripts. We implement a tool viz. Reduse to identify reproducibility smells in Ansible scripts. Furthermore, we conduct an empirical study to reveal the proliferation of reproducibility smells in open-source projects and explore correlation and fine-grained co-occurrence relationships among them. We observe that broken dependency chain smell occurs the most in approximately $71 \%$ tasks that we analyzed. Our analysis uncovers significant positive correlations between specific reproducibility smells, implying that repositories with one such smell tend to exhibit others. Moreover, the co-occurrence analysis reveals smell pairs that show a high tendency of co-occurrence at the task granularity. With the developed tool Reduse, DevOps engineers can identify and rectify reproducibility issues before becoming part of the production system. Software engineering researchers can use the smells catalog proposed first in this study and can utilize Reduse in empirical studies exploring various facets of reproducibility.},
  keywords={Production systems;Correlation;DevOps;Programming;Reproducibility of results;Software;Data mining;Monitoring;Systematic literature review;Software engineering;Infrastructure as Code;Ansible;Reproducibility;Reproducibility smells},
  doi={10.1109/MSR66628.2025.00069},
  ISSN={2574-3864},
  month={April},}@INPROCEEDINGS{7905759,
  author={Roslina and Zarlis, Muhammad and Yanto, Iwan Tri Riyadi and Hartama, Dedy},
  booktitle={2016 International Conference on Informatics and Computing (ICIC)}, 
  title={A framework of training ANFIS using Chicken Swarm Optimization for solving classification problems}, 
  year={2016},
  volume={},
  number={},
  pages={437-441},
  abstract={The result of training parameters described Adaptive Neuro-Fuzzy Inference System (ANFIS) performance. The speed and reliability of training effect depend on the training mechanism. There have been many methods used to train the parameters of ANFIS as using GD, metaheuristic techniques, and LSE. But there are still many methods developed to achieve efficiently. One of the proposed algorithm to improve the performance of ANFIS is Chicken swarm optimization (CSO) algorithm. The experimental results of training ANFIS network for classification problems show that ANFIS-CSO algorithm achieved better accuracy.},
  keywords={Training;Particle swarm optimization;Algorithm design and analysis;Adaptation models;Inference algorithms;Fuzzy logic;Testing;Classification;ANFIS;Chicken Swarm Optimization},
  doi={10.1109/IAC.2016.7905759},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9541798,
  author={Hausen, J. and Javaloyes, J. and Gurevich, S. V. and Lüdge, K.},
  booktitle={2021 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC)}, 
  title={Phase-incoherent photonic molecules in V-shaped mode-locked VECSELs}, 
  year={2021},
  volume={},
  number={},
  pages={1-1},
  abstract={Passively mode-locked semiconductor VECSELs realized in a V-shaped cavity configuration ( Fig. 1a ) have proven to provide strong performance figures and are thus promising candidates for photonic applications. Furthermore, these lasers can also be a source of interesting pulsed dynamics, as the double gain pass within one round-trip in the external cavity favors the emergence of pulse clusters over harmonic mode-locking [1] . Here, we investigate this cavity effect in the regime of temporally localized states where the gain relaxation time has to be much shorter than the cavity length.},
  keywords={Semiconductor lasers;Laser mode locking;Europe;Harmonic analysis;Photonics},
  doi={10.1109/CLEO/Europe-EQEC52157.2021.9541798},
  ISSN={},
  month={June},}@INPROCEEDINGS{8737637,
  author={Alhanahnah, Mohannad and Yan, Qiben and Bagheri, Hamid and Zhou, Hao and Tsutano, Yutaka and Srisa-an, Witawas and Luo, Xiapu},
  booktitle={IEEE INFOCOM 2019 - IEEE Conference on Computer Communications}, 
  title={Detecting Vulnerable Android Inter-App Communication in Dynamically Loaded Code}, 
  year={2019},
  volume={},
  number={},
  pages={550-558},
  abstract={Java reflection and dynamic class loading (DCL) are effective features for enhancing the functionalities of Android apps. However, these features can be abused by sophisticated malware to bypass detection schemes. Advanced malware can utilize reflection and DCL in conjunction with Android Inter-App Communication (IAC) to launch collusion attacks using two or more apps. Such dynamically revealed malicious behaviors enable a new type of stealthy, collusive attacks, bypassing all existing detection mechanisms. In this paper, we present DINA, a novel hybrid analysis approach for identifying malicious IAC behaviors concealed within dynamically loaded code through reflective/DCL calls. DINA continuously appends reflection and DCL invocations to control-flow graphs; it then performs incremental dynamic analysis on such augmented graphs to detect the misuse of reflection and DCL that may lead to malicious, yet concealed, IAC activities. Our extensive evaluation on 3,000 real-world Android apps and 14,000 malicious apps corroborates the prevalent usage of reflection and DCL, and reveals previously unknown and potentially harmful, hidden IAC behaviors in real-world apps.},
  keywords={Security;Runtime;Malware;Static analysis;Tools;Loading;Real-time systems;Mobile security;inter-app communication;reflection;dynamically loaded code},
  doi={10.1109/INFOCOM.2019.8737637},
  ISSN={2641-9874},
  month={April},}@INPROCEEDINGS{10314322,
  author={Song, Jia and Shang, Weize and Wu, Boxuan and Ai, Shaojie},
  booktitle={2023 10th International Conference on Dependable Systems and Their Applications (DSA)}, 
  title={Fault location and separation method of Distributed Inertial Measurement Units based on IAC}, 
  year={2023},
  volume={},
  number={},
  pages={896-904},
  abstract={With the development of unmanned technology, Distributed Inertial Measurement Units (DIMU) play an increasingly important role in Unmanned Aerial Vehicles (UAV). The large number of sensors and high data redundancy of DIMU bring huge challenges to its fault location and separation. However, the fault calculation complexity of the conventional methods increases with the number of sensors. Existing intelligent fault diagnosis methods usually determine the fault type for a single Inertial Measurement Units (IMU), and there are relatively few studies on fault location for DIMU. In this paper, we propose a DIMU fault location and separation method based on Improved Attention-CNN (IAC). First, we extract temporal and spatial nonlinear features of all sensor-measured data by the IAC encoder. Then, we complete the location and separation of fault sensor in DIMU by decoding the extracted fault features. We can better extract the spatio-temporal correlation features of data between sensors in DIMU to improve the accuracy of fault location and separation by the attention mechanism in IAC. IAC is not limited by the number of sensors because it is a data-driven fault diagnosis method. IAC fills the research gap of DIMU fault location and fault separation. The IAC can be used to identify the location number and fault type of the faulty IMU in the DIMU. Through simulation experiments, the fault location accuracy rate of our proposed IAC method reaches 95% and the fault separation accuracy rate after a fault occurs reaches 99%.},
  keywords={Measurement units;Redundancy;Inertial navigation;Fault location;Sensor phenomena and characterization;Sensor fusion;Feature extraction;Distributed sensor;Fault location;Fault separation;Inertial Measurement Unit;Attention},
  doi={10.1109/DSA59317.2023.00126},
  ISSN={2767-6684},
  month={Aug},}@ARTICLE{10103554,
  author={Wang, Bin and Yang, Chao and Ma, Jianfeng},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={IAFDroid: Demystifying Collusion Attacks in Android Ecosystem via Precise Inter-App Analysis}, 
  year={2023},
  volume={18},
  number={},
  pages={2883-2898},
  abstract={Inter-app communication mechanism allows app developers to improve Android apps’ usability and provide users with rich functions via interacting with exposed components or performing data sharing. However, this mechanism may be leveraged by malicious developers or unintentionally misused by inexperienced developers. For end users, this type of attack may cause privacy breaches or remote controls of personal phone, which have a great threat of the user’s data security. The key to analyzing whether there is a collusion attack is to analyze the existence of communication channels between apps. The existing static analysis tools have done some work in this area, but the comprehensiveness of the analysis is insufficient, and such research lacks a unified test standard. In this paper, we present collusion attacks using more concealed inter-app communication channels, which can bypass existing security detection mechanisms. To defend against the new attacks, we design IAFDroid, an analysis framework that combines static and taint analysis. By examining 20K real-world apps, IAFDroid found that 94.4% of the most exposed components of Android may be leveraged to perform collusion attacks. Furthermore, the evaluation showed that the feature set extracted by IAFDroid could be used to promote the accuracy of Android malware detection. We contribute a more comprehensive benchmark for IAC analysis, IACBench, which includes the new attacks we propose. To facilitate follow-up studies, we open-sourced IAFDroid and IACBench based on the GPL agreement.},
  keywords={Static analysis;Benchmark testing;Behavioral sciences;Smart phones;Receivers;Analytical models;Standards;Android application;inter-app communication;static analysis;collusion;information leakage;security vetting},
  doi={10.1109/TIFS.2023.3267666},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{11111216,
  author={Seidel, T. and Bartelo, A. and Garnache, A. and Giudici, M. and Marconi, M. and Gurevich, S. V. and Javaloyes, J.},
  booktitle={2025 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC)}, 
  title={Coherent Pulse Interactions in Mode-Locked Semiconductor Lasers}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Passive mode-locking (PML) is a well established technique to obtain short optical pulses with high repetition rates. A pulsating laser can operate in the harmonic mode-locked $(\text{HML}_{N})$ regime, where the laser cavity supports a train of several equidistant pulses within one round-trip. However, even in this ordered state, each pulse possesses its own phase within the cavity round-trip. In the long cavity limit the situation becomes even more intricate as pulses become temporal localized structures that can be configured in arbitrary patterns in terms of relative positions and phases, cf. orange and blue arrows in Fig. 1. Note that these quantities are not necessarily independent as the pulses have several possibilities to interact with each other via carriers dynamics and/or their coherent overlapping due to e.g., optical feedback or tails interactions.},
  keywords={Semiconductor lasers;Laser mode locking;Optical feedback;Europe;Laser feedback;Harmonic analysis;Optical pulses},
  doi={10.1109/CLEO/Europe-EQEC65582.2025.11111216},
  ISSN={2833-1052},
  month={June},}@ARTICLE{9845680,
  author={Pires, Aécio dos Santos and Matos, Fernando Menezes and Santos, Aldri Luiz dos and Pessoa, Diego Ernesto Rosa and Maciel, Paulo Ditarso},
  journal={IEEE Transactions on Network and Service Management}, 
  title={PipeConf: An Integrated Architecture for the Automated Configuration of Network Assets}, 
  year={2022},
  volume={19},
  number={3},
  pages={3657-3669},
  abstract={The manual management of network assets is susceptible to configuration errors, lack of standardization, a large amount of repetitive work, and little or no traceability of changes over time. The Infrastructure as Code (IaC) approach makes it possible to automate the process of configuring resources such as operating systems, network services, containers, and applications, by treating them as software and allowing standardization and configuration rollback. This paper proposes an integrated architecture based on different software tools that use the IaC approach to automate the configuration of network assets, considering different models and manufacturers. A quantitative analysis shows the architecture’s efficiency in response time and scalability. The architecture has achieved a proportional gain of 83% in the average response time to manage 128 assets, with no significant increase in processing and memory usage.},
  keywords={Computer architecture;Codes;DSL;Security;Task analysis;Performance evaluation;Interoperability;Infrastructure as code;integrated architecture;network asset;configuration management},
  doi={10.1109/TNSM.2022.3195382},
  ISSN={1932-4537},
  month={Sep.},}@INPROCEEDINGS{7905733,
  author={Anggrawan, Anthony and Hidjah, Khasnur and Jihadil, Qudsi S.},
  booktitle={2016 International Conference on Informatics and Computing (ICIC)}, 
  title={Kidney failure diagnosis based on case-based reasoning (CBR) method and statistical analysis}, 
  year={2016},
  volume={},
  number={},
  pages={298-303},
  abstract={The kidney is one of the most important organs for human beings. It mainly functions to remove the waste products of the human body metabolism. 850.000 mortalities are caused by chronic kidney failure. According to the World Health Organization (WHO), chronic kidney failure was ranked as one of the top 12 causes of death in the world. For that reason, we need to develop CBR that can help in diagnosing kidney failure. CBR is a computer reasoning system which uses pre-existing cases and knowledge to solve new problems. CBR provides solutions to new cases by looking at the previous cases which are the most similar to new case. The patients' medical records on kidney failure are used as data. Calculation of similarity between the old and new cases was measured by using a simple matching coefficient. This study used a waterfall methodology begins with information system engineering, need analysis, design coding, and testing. For coding, authors used PHP programming language and MySQL data base. Having obtained the result of CBR statistics further tested whether CBR can be wholly accepted when there is a new case. The result of the CBR experiment showed that the system can diagnose kidney failure based on the experiment done by the experts with a 80% success rate and that rate has been tested by using a statistical Spearman rank test with a significant level of 5%, resulting there are 15 symptoms that can explain the stadium levels of the kidney failure patients.},
  keywords={Kidney;Diseases;Cognition;Medical diagnostic imaging;Informatics;Smart systems;Reliability;Indexing;Encoding;Data collection;Case-Based Reasoning;kidney failure disease;Statistical;simple matching coefficient},
  doi={10.1109/IAC.2016.7905733},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10062367,
  author={Amiri, Amirali and Zdun, Uwe and Plakidas, Konstantinos},
  booktitle={2022 IEEE 22nd International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={Stateful Depletion and Scheduling of Containers on Cloud Nodes for Efficient Resource Usage}, 
  year={2022},
  volume={},
  number={},
  pages={480-491},
  abstract={Container scheduling is a fundamental part of today’s service and cloud-based applications. Schedulers operate at different levels depending on how much control the system developers have. On the one hand, container orchestration managers such as Google Kubernetes manage the scheduling of containers to different nodes. On the other hand, serverless managers, such as Google Autopilot, take care of the underlying infrastructure automatically, and developers do not need to manage the nodes. However, when it comes to container depletion, i.e., removing the assigned cloud resources to an idle container, current scheduling technologies have limitations. In this paper, we propose our approach to managing cloud resource usage when containers are idle efficiently. For this purpose, we deplete idle containers statefully, i.e., propose a novel manager that monitors idle containers, saves their state, and efficiently depletes them. This manager reconstructs a depleted container using the saved state when reconstruction is needed. In our approach, we suggest an Infrastructure as Code component to automate the creation of new nodes if a depleted container cannot be scheduled on the same node, e.g., because of being overloaded. We provide an analytical model for the stateful depletion of containers and their rescheduling and empirically evaluate the accuracy of our model. For this purpose, we ran an experiment on a private cloud infrastructure and Google Cloud Platform. Our model has a low error rate of 4.28% averaged over public and private clouds.},
  keywords={Cloud computing;Analytical models;Codes;Error analysis;Software quality;Containers;Software reliability;Container Scheduling;Container Depletion;Cloud Resource Management;Infrastructure as Code amplifiers},
  doi={10.1109/QRS57517.2022.00056},
  ISSN={2693-9177},
  month={Dec},}@ARTICLE{9067838,
  author={Sridar, Saivimal and Poddar, Souvik and Tong, Yida and Polygerinos, Panagiotis and Zhang, Wenlong},
  journal={IEEE Robotics and Automation Letters}, 
  title={Towards Untethered Soft Pneumatic Exosuits Using Low-Volume Inflatable Actuator Composites and a Portable Pneumatic Source}, 
  year={2020},
  volume={5},
  number={3},
  pages={4062-4069},
  abstract={The application of pneumatic soft robots is limited by factors such as operational pressure and air flow rates. Pneumatic soft robots are typically tethered in nature due to the high energy costs for actuation as well as the lack of portable pneumatic sources capable of providing high pressures and air flow rates. This work presents a low-volume inflatable actuator composite (IAC) designed to reduce energy costs of actuation and a portable pneumatic source to overcome the aforementioned issues towards untethered applications. The pressure-deflection characteristics of the fabricated IAC are compared with those of a completely fabric-based beam using experimental results and finite element analysis. FEM models of IACs with varying volumes are generated and actuation speeds are measured using a pressure step response test. The force output and hysteresis of the actuator are studied. The developed portable pneumatic source is capable of generating a pressure and flow rates of 0.131 MPa and 21.45 standard litres per minute (SLPM), respectively. The IACs and portable pneumatic source are integrated with a soft exosuit to assist knee extension, and the integrated system is evaluated with three healthy participants for incline walking. A reduction of muscle activities in the Vastus Lateralis muscle group is observed for all the three participants when the exosuit is active.},
  keywords={Actuators;Fabrics;Soft robotics;Finite element analysis;Strain;Soft robotics;soft actuator;wearable robotics;pneumatic source;soft exosuit},
  doi={10.1109/LRA.2020.2986744},
  ISSN={2377-3766},
  month={July},}@INPROCEEDINGS{11052114,
  author={N, Senthamarai and M, Jeyaselvi and V, Hemamalini},
  booktitle={2025 International Conference on Intelligent and Cloud Computing (ICoICC)}, 
  title={Automatic Cloud Formation Using LLM}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Introduces a groundbreaking IAC Code Generator for automated Terraform script creation. Empowers developers by treating infrastructure as a versioned, programmable artifact. Enhances efficiency, reduces time-to-market, ensures consistency, and promotes collaboration between development and operations teams. Features an intuitive interface, customizable templates, and integrates industry best practices for accessible and accelerated development cycles.},
  keywords={Industries;Cloud computing;Codes;Automation;Collaboration;Manuals;Generators;Software reliability;Best practices;Software development management;IAC;Automation;Generation;Terraform;Template},
  doi={10.1109/ICoICC64033.2025.11052114},
  ISSN={},
  month={May},}@INPROCEEDINGS{8780491,
  author={Firdaus, Muhamad and Mastuki and Allan, Johanes Flady},
  booktitle={2018 Third International Conference on Informatics and Computing (ICIC)}, 
  title={The AlKesFar App, A Mobile Augmented Reality on Learning Media Tools for Indonesian Pharmacy School}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={In understanding the knowledge of pharmaceuticals, an understanding of medical equipment is essential. In fact, the medical equipment is not all can be seen in the learning process due to limited space and procurement for the tool due to the high price of medical equipment. To resolve this, effective and efficient learning media is required without the need for space and equipment procurement. In this research, we developed an application of AlkesFar based on andorid devices using Augmented Reality (AR) technology to introduce and give understanding about medical equipment. AlKesFar combines AR technology directly on images of medical equipment. AlkesFar was tested on students of class XI SMK Pharmacy Kapasari Surabaya, Indonesia. From the testing results, respondents who answered strongly agree obtained 69%. From this result, AlKeFar application is ready to be applied as a learning media tools for Indonesian Pharmacy School.},
  keywords={Biomedical equipment;Augmented reality;Media;Three-dimensional displays;Tools;Presses;Testing;medical equipment;Augmented Reality;learning media},
  doi={10.1109/IAC.2018.8780491},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{5727695,
  author={Xucheng Luo, Xucheng Luo and Zhiguang Qin, Zhiguang Qin and Ji Geng, Ji Geng and Jiaqing Luo, Jiaqing Luo},
  booktitle={2006 Semantics, Knowledge and Grid, Second International Conference on}, 
  title={IAC: Interest-Aware Caching for Unstructured P2P}, 
  year={2006},
  volume={},
  number={},
  pages={58-58},
  abstract={The simplicity and robustness of unstructured P2P system make it a preferable architecture for constructing real large scale file sharing system. Most of the existing paradigms require more overhead. The trace data analysis shows that the workloads among peers are correlated. The bigger the intersection of workloads, the higher the probability that they share other files is. By exploiting such principle, we propose IAC, an interest-aware resource advertisement caching paradigm for unstructured p2p system. Each peer advertises its resource list. If a peer is interested in the resource advertisement received, it then caches the advertisement. Through local cache search, usually the peer gets more than 50% success rate. If local cache search is failed, the random walk-based search is used. The simulations show that as to the same hit rate, the maintenance and search overheads are low and the search delay is very low.},
  keywords={},
  doi={10.1109/SKG.2006.54},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9796178,
  author={Opdebeeck, Ruben and Zerouali, Ahmed and De Roover, Coen},
  booktitle={2022 IEEE/ACM 19th International Conference on Mining Software Repositories (MSR)}, 
  title={Smelly Variables in Ansible Infrastructure Code: Detection, Prevalence, and Lifetime}, 
  year={2022},
  volume={},
  number={},
  pages={61-72},
  abstract={Infrastructure as Code is the practice of automating the provisioning, configuration, and orchestration of network nodes using code in which variable values such as configuration parameters, node hostnames, etc. play a central role. Mistakes in these values are an important cause of infrastructure defects and corresponding outages. Ansible, a popular IaC language, nonetheless features semantics which can cause confusion about the value of variables. In this paper, we identify six novel code smells related to Ansible's intricate variable precedence rules and lazy-evaluated template expressions. Their detection requires an accurate representation of control and data flow, for which we transpose the program dependence graph to Ansible. We use the resulting detector to empirically investigate the prevalence of these variable smells in 21,931 open-source Ansible roles, uncovering 31,334 unique smell instances across 4,260 roles. We observe an upward trend in the number of variable smells over time, that it may take a long time before they are fixed, and that code changes more often introduce new smells than fix existing ones. Our results are a call to arms for more in-depth quality checkers for IaC code, and highlight the importance of transcending syntax in IaC research.},
  keywords={Codes;Semantics;Detectors;Syntactics;Maintenance engineering;Market research;Software reliability;Infrastructure as Code;Ansible;code smells;program dependence graphs;empirical study;software quality},
  doi={10.1145/3524842.3527964},
  ISSN={2574-3864},
  month={May},}@ARTICLE{9017933,
  author={Alhanahnah, Mohannad and Yan, Qiben and Bagheri, Hamid and Zhou, Hao and Tsutano, Yutaka and Srisa-An, Witawas and Luo, Xiapu},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={DINA: Detecting Hidden Android Inter-App Communication in Dynamic Loaded Code}, 
  year={2020},
  volume={15},
  number={},
  pages={2782-2797},
  abstract={Android inter-app communication (IAC) allows apps to request functionalities from other apps, which has been extensively used to provide a better user experience. However, IAC has also become an enticing target by attackers to launch malicious activities. Dynamic class loading (DCL) and reflection are effective features to enhance the functionality of the apps. In this paper, we expose a new attack that leverages these features in conjunction with inter-app communication to conceal malicious attacks with the ability to bypass existing security mechanisms. To counteract such attack, we present DINA, a novel hybrid analysis approach for identifying malicious IAC behaviors concealed within dynamically loaded code through reflective/DCL calls. DINA appends reflection and DCL invocations to control-flow graphs and continuously performs incremental dynamic analysis to detect the misuse of reflection and DCL that obfuscates malicious Intent communications. DINA utilizes string analysis and inter-procedural analysis to resolve hidden IAC and achieves superior detection performance. Our extensive evaluation on 49,000 real-world apps corroborates the prevalent usage of reflection and DCL, and reveals previously unknown and potentially harmful, hidden IAC behaviors in real-world apps.},
  keywords={Runtime;Androids;Humanoid robots;Security;Malware;Java;Tools;Mobile security;inter-app communication;reflection;dynamically loaded code},
  doi={10.1109/TIFS.2020.2976556},
  ISSN={1556-6021},
  month={},}@ARTICLE{9584276,
  author={Guidi, F and Rubiño-Martín, J A and Pelaez-Santos, A E and Génova-Santos, R T and Ashdown, M and Barreiro, R B and Bilbao-Ahedo, J D and Harper, S E and Watson, R A},
  journal={Monthly Notices of the Royal Astronomical Society}, 
  title={The picasso map-making code: application to a simulation of the QUIJOTE northern sky survey}, 
  year={2021},
  volume={507},
  number={1},
  pages={3707-3725},
  abstract={Map-making is an important step for the data analysis of cosmic microwave background (CMB) experiments. It consists of converting the data, which are typically a long, complex, and noisy collection of measurements, into a map, which is an image of the observed sky. We present in this paper a new map-making code named picasso (Polarization and Intensity CArtographer for Scanned Sky Observations), which was implemented to construct intensity and polarization maps from the Multi Frequency Instrument (MFI) of the QUIJOTE (Q-U-I Joint TEnerife) CMB polarization experiment. picasso is based on the destriping algorithm, and is suited to address specific issues of ground-based microwave observations, with a technique that allows the fit of a template function in the time domain, during the map-making step. This paper describes the picasso code, validating it with simulations and assessing its performance. For this purpose, we produced realistic simulations of the QUIJOTE-MFI survey of the northern sky (approximately ∼20 000 deg2), and analysed the reconstructed maps with picasso, using real and harmonic space statistics. We show that, for this sky area, picasso is able to reconstruct, with high fidelity, the injected signal, recovering all the scales with ℓ > 10 in TT, EE, and BB. The signal error is better than 0.001 per cent at 20 < ℓ < 200. Finally, we validated some of the methods that will be applied to the real wide-survey data, like the detection of the CMB anisotropies via cross-correlation analyses. Despite that the implementation of picasso is specific for QUIJOTE-MFI data, it could be adapted to other experiments.},
  keywords={methods: data analysis;cosmic background radiation;cosmology: observations;diffuse radiation},
  doi={10.1093/mnras/stab2422},
  ISSN={1365-2966},
  month={Jul},}@INPROCEEDINGS{7905742,
  author={Alam, Sayed Mahmudul and Islam, Nahid and Hosain, Md. Shazzad},
  booktitle={2016 International Conference on Informatics and Computing (ICIC)}, 
  title={Detecting most central actors of an unknown network using friendship paradox}, 
  year={2016},
  volume={},
  number={},
  pages={343-348},
  abstract={Most central people have more influence on business communication, knowledge diffusion, viral marketing and some other fields over other persons in a social network. Networks for which digital information is available such as email communication, phone call etc., one can easily find central actors using social network analysis tools. But for networks where no such information is available, for example farmers in a remote village, secret networks of a criminal organization etc., finding central actors is challenging. We call such network as unknown network. In this research, we have propose a method based on the idea of friendship paradox (FP) to find the most prominent actors from an unknown network. Extensive simulation results demonstrate that our method finds the most centrals by exploring only a small population of an unknown social network with a high accuracy.},
  keywords={Social network services;Sociology;Statistics;Immune system;Electronic mail;Informatics;Computers;Social network analysis;centrality or popularity;social influence;friendship paradox},
  doi={10.1109/IAC.2016.7905742},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8780469,
  author={Rahmat, Romi Fadillah and Ramadhani, Tri and Gunawan, Dani and Faza, Sharfina and Budiarto, Rahmat},
  booktitle={2018 Third International Conference on Informatics and Computing (ICIC)}, 
  title={Mel-frequency Cepstral Coefficient-Vector Quantization Implementation for Voice Detection of Rice-Eating Birds in The Rice Fields}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={The losses suffered by the farmers due to bird attack could reach of 15 - 50 percent of harvest yield. The peasants use conventional pesticides and this still conducted manually which is very inefficient. Therefore, this study has the purpose of developing an application of rice-eating bird voice detector. This application can automatically detect the sounds of birds that are eating the rice to facilitate the farmers to monitor and repel the birds' presence in the paddy to reduce losses during harvest seasons. Mel Frequency Cepstral Coefficients-Vector Quantization (MFCC-VQ) was used as the method for bird's voice recognition. The feature of voice signals captured via microphone will be extracted using the Mel Frequency Cepstral Coefficients (MFCC) algorithm. The extracted audio signal is then identified whether the sound is a bird or not using the Vector Quantization (VQ) algorithm. The identification result will generate the output of a firing sound as an action to cast out and scare the birds away from the fields. The result of this study is that the sound of birds was detected depending on the arrival of birds in the field such as during the morning, afternoon and evening. The result also showed that the further the distance of the microphone from the sound source, the smaller the intensity of the voice and the noisy the state of the environment on the detection process, the smaller the accuracy percentage.},
  keywords={Birds;Mel frequency cepstral coefficient;Training data;Feature extraction;Classification algorithms;Testing;voice recognition;Mel-Frequency Cepstral Coefficients;vector quantization;bird voice;rice field},
  doi={10.1109/IAC.2018.8780469},
  ISSN={},
  month={Oct},}@ARTICLE{9014526,
  author={Hui, Hongxun and Ding, Yi and Chen, Tao and Rahman, Saifur and Song, Yonghua},
  journal={IEEE Transactions on Industrial Electronics}, 
  title={Dynamic and Stability Analysis of the Power System With the Control Loop of Inverter Air Conditioners}, 
  year={2021},
  volume={68},
  number={3},
  pages={2725-2736},
  abstract={The power consumption of inverter air conditioners (IACs) can be regulated flexibly by adjusting the compressor's operating frequency, which has been proven suitable for providing regulation capacities to power systems. Considering the rapid phasing out of traditional generating units, massive IACs create huge alternative regulation potential. However, the impact of IACs on the power system's stability is rarely studied. To address this issue, this article proposes the modeling and control methods of IACs to provide regulation capacities to power systems. On this basis, a novel power system model with the control loop of large-scale IACs is developed, where the communication latency during the control signal transfer process is also considered. Then, the dynamic performance and steady-state errors of the novel power system are evaluated, showing that IACs can quickly participate in and smoothly withdraw from the regulation process. Furthermore, the stabilities and sensitivities of power systems with and without IACs are compared, in order to illustrate that both the stability margin and robustness of the power system can be increased via the control loop of IACs. Finally, the effectiveness of the proposed models and methods are verified by numerical studies.},
  keywords={Power system stability;Stability analysis;Cooling;Power demand;Frequency control;Thermal stability;Power system dynamics;Dynamic performance;inverter air conditioner (IAC);sensitivity analysis;stability analysis},
  doi={10.1109/TIE.2020.2975465},
  ISSN={1557-9948},
  month={March},}@INPROCEEDINGS{10173942,
  author={Zerouali, Ahmed and Opdebeeck, Ruben and De Roover, Coen},
  booktitle={2023 IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)}, 
  title={Helm Charts for Kubernetes Applications: Evolution, Outdatedness and Security Risks}, 
  year={2023},
  volume={},
  number={},
  pages={523-533},
  abstract={Using Kubernetes for the deployment, management and scaling of containerized applications has become a common practice. To facilitate the installation and management of these applications, practitioners can use the Helm package manager to assemble their configuration files into charts. The latter are reusable packages of pre-configured Kubernetes resources that can be deployed as a unit. In this paper, we aim to support chart developers and users by carrying out a comprehensive study on publicly available charts. For 9,482 charts that are distributed via the Artifact Hub repository, we mine and collect the list of their metadata, versions, dependencies, maintainers and container images. Then, we carry out an empirical analysis to assess the state and evolution of charts, as well as the outdatedness and security risks of their images. We found that the ecosystem forming around Helm charts is growing fast. However, most of the charts are not official with no popularity and no license. We also observed that charts tend to release multiple versions, but around half of them are still in the initial development phase. When looking at the container images used in charts, we found that around half of them are outdated and 88.1% of them are exposed to vulnerabilities, jeopardizing 93.7% of the charts.},
  keywords={Ecosystems;Containers;Licenses;Metadata;Software;Security;Data mining;Kubernetes;Helm;Software Ecosystem;Infrastructure-as-code;Evolution;Security},
  doi={10.1109/MSR59073.2023.00078},
  ISSN={2574-3864},
  month={May},}@ARTICLE{5985466,
  author={Ndjiki-Nya, P. and Doshkov, D. and Kaprykowsky, H. and Zhang, F. and Bull, D. and Wiegand, T.},
  journal={IEEE Journal of Selected Topics in Signal Processing}, 
  title={Perception-oriented Video Coding based on Image Analysis and Completion: A Review}, 
  year={2011},
  volume={},
  number={},
  pages={1-1},
  abstract={Perception-oriented video coding based on image analysis and completion (IAC) has received increasing attention over recent years. Several approaches have been proposed that follow diverging strategies: from full compatibility to hybrid block transform coding to alternative codec designs. In this paper, we review the most significant issues in IAC coding and their relevance for future codec designs. The most promising pathways will be analyzed along with limitations and open issues. The challenges in IACbased video coding will be summarized using methods developed by the authors and others for block-based and region-based IAC coding.},
  keywords={Video coding;Image coding;Bit rate;Encoding;Codecs;Transform coding;Decoding;Image analysis;image completion;texture analysis;texture synthesis;quality assessment;rate-distortion optimization;parametric video compression;next generation video coding},
  doi={10.1109/JSTSP.2011.2165049},
  ISSN={1941-0484},
  month={},}@INPROCEEDINGS{11109523,
  author={Seidel, T. and Javaloyes, J. and Gurevich, S. V.},
  booktitle={2025 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC)}, 
  title={Normal Dispersion Kerr Cavity Solitons: Beyond the Mean Field Limit}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Optical frequency comb generation using Kerr resonators has attracted a lot of interest in recent years. In the regime where the intracavity power is relatively low and the overall cavity detuning remains small during propagation, the mean field approximation can be employed and the formation of OFCs in Kerr resonators is well-described by the Lugiato-Lefever Equation (LLE). However, mean field models are not always able to account for the complete range of complex dynamics observed and alternative approaches based on e.g., extended LLE equations or Ikeda map models are used. Recently, an alternative method for the generation of phase-locked OFCs in optically-injected vertical-emission Kerr Gires-Tournois Interferometers (KGTI) was proposed. This setup consist in a micro-cavity containing a Kerr medium coupled to a long external cavity of size $\tau$ which is closed by a feedback mirror and which is subject to injection using a continuous wave laser of amplitude $Y_{0}$ and frequency ωo (cf. Fig. (1)). While it was demonstrated that in the weakly dissipative limit, the KGTI can successfully be modeled by the LLE [1], in general, the model can be used to study the dynamics beyond these limitations which is the subject of this contribution [2]. We demonstrate the existence of a novel type of temporal localized structure (TLS). These bright pulses exist in the normal dispersion regime, yet they do not correspond to the usual scenario of domain wall locking that induces complex shape multi-stability, weak stability as well as a reduced domain of existence. Their shape is uniquely defined, with peak intensities beyond that of the upper steady state, and they are stable over a broad range of the injection field, highlighting their potential for optical frequency comb generation. The underlying model is derived from first principles and relies on delay algebraic equations (DAEs). That is, the slowly evolving micro-cavity field $E$ is governed by an ordinary differential equation while the external cavity field $Y$ needs to fulfill a delay algebraic constraint:},
  keywords={Shape;Semiconductor lasers;Ordinary differential equations;Mathematical models;Optical harmonic generation;Stability analysis;Delays;Steady-state;Resonators;Dispersion},
  doi={10.1109/CLEO/Europe-EQEC65582.2025.11109523},
  ISSN={2833-1052},
  month={June},}@INPROCEEDINGS{8780461,
  author={Panie, Gregorio Imanuel Efraim and Mutiara, Achmad Benny},
  booktitle={2018 Third International Conference on Informatics and Computing (ICIC)}, 
  title={Development of Robotic Arm for Color Based Goods Sorter in Factory Using TCS3200 Sensor with a Web-Based Monitoring System}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={This system was made due to frequent errors in performing calculation of goods manufactured manually. The issues can be solved by using a TCS3200 sensor that can identifies the color of goods based on the color that has adjusted. The use of this sensor can be a solution that will help increase the productivity of companies. In this paper, it is described the development of color sensor that is used to sort items by color in the industrial world. Technology of this control system assist in making the Internet of Things products, as well as the mechanical systems in the form of a robot arm which consists of four micro servos are designed to pick up and put stuff in the container. The result of the arithmetic processing of goods displayed through a Web page that has been designed. The achievement is using a micro controller NodeMCU in programming sensor to sort items and adjust into the container. It is also included a solution to the color sensor to recognize colors using search algorithms.},
  keywords={Image color analysis;Robot sensing systems;Color;Servomotors;Pins;Manipulators;Color Sensor;Internet of Things;micro servo;NodeMCU},
  doi={10.1109/IAC.2018.8780461},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8280651,
  author={Yushendri, Jefri and Hanif, Alvian Rahman and Siswadi, Anneke Annassia Putri and Musa, Purnawarman and Kusuma, Tubagus Maulana and Wibowo, Eri Prasetyo},
  booktitle={2017 Second International Conference on Informatics and Computing (ICIC)}, 
  title={A speech intelligence conversation bot for interactive media information}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={The customer service is needed in not only companies but also in a university. The university usually have the customer service by phone number, such as Gunadarma University that gives the Media Information Centre's phone number to do the customer service task. The growth technologies encourage the customer service to have the improvement. This research is developing the speech intelligence conversation bot as an interactive media information, a customer service improvement. This speech intelligence conversation bot is not only having the ability to listen the user's question but also has the intelligence to understand the user's question and gives the right information related to that question. The ability to listen and speak with the user is implemented using speech recognition by Sphinx-4 while the ability to understand and find the related information is implemented by using the chatbot system with the modificated MegaHal style for developing it. The accuracy each ability of this speech intelligence conversation bot are intelligence conversation bot are 80,0% for speech recognition, 89,3% for chatbot system, and 100% for response generation. The average accuracy fot the whole system is 89.7% However, it needs more improvement in both speech recognition ability and chatbot system ability, especially for speech recognition since it has the lowest accuracy number among the other abilities.},
  keywords={Speech;Speech recognition;Customer services;Markov processes;Task analysis;Speech processing;Acoustics;customer service;speech recognition;chatbot;MegaHal},
  doi={10.1109/IAC.2017.8280651},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{8780543,
  author={Pambudi, Doni Setio and Handayani, Ruktin and Hidayah, Lailatul},
  booktitle={2018 Third International Conference on Informatics and Computing (ICIC)}, 
  title={Template Matching Algorithm For Noise Detection in Cargo Container}, 
  year={2018},
  volume={},
  number={},
  pages={1-9},
  abstract={A seaport terminal providing services for inbound and outbound flow of cargo container often has issues with the handling of container. In some cases, the port is sued for damaged container which in fact has not been taken care properly before arriving in the port. Hence an automatic detection system for damaged container is needed. In this research, an algorithm to identify objects in a side-view of a cargo container is proposed. The objects include but not limited to company name of the cargo container, logo, identification code, signs, labels, and damages. By utilizing template matching algorithm, an algorithm to identify objects in container images has been developed. The achieved visual result was satisfactory as well as the computational aspect.},
  keywords={Containers;Image color analysis;Colored noise;Image edge detection;Informatics;Object recognition;Seaports;Image Processing;Ship to Shore Crane;camera;container;damage;Template Matching;object detection},
  doi={10.1109/IAC.2018.8780543},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10560195,
  author={Neeraj and Yadav, Prerna and Yadav, Anshul and Yadav, Hemant Kumar and Harish, V. S. K. V},
  booktitle={2024 1st International Conference on Innovative Sustainable Technologies for Energy, Mechatronics, and Smart Systems (ISTEMS)}, 
  title={Impact of Thermostatically Controlled Loads and Non-Linearities on Frequency Regulation of Power-Grid}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This research investigates the impact of thermostatically controlled loads (TCLs) on frequency regulation within power-grids, crucial for sustainable energy management. With the transition to renewable energy sources (RES), maintaining frequency stability becomes challenging due to their inherent variability. Power-grids, incorporating various energy sources and loads, offer a solution, but efficient load distribution is vital. The study focuses on sensitivity analysis, exploring how varying generator inertia affects the response of a system with the different load sharing between Power-grid and TCL with GDB (Governor dead band) and GRC (Generation rate constraint) with effect of non-linearity. Through innovative modeling, including dynamic representations of inverter air conditioners (IAC), the study enhances understanding of TCL interaction with power-grid dynamics. The research conducts load sharing experiments and sensitivity analysis, revealing insights into frequency regulation.},
  keywords={Adaptation models;Renewable energy sources;Mechatronics;Sensitivity analysis;Generators;Stability analysis;Inverters;Automatic Generation Control;Generator Rate Constraint;Governor Dead Band;Load Sharing;Power-grid;Proportional-Integral Controller;Sensitivity Analysis;Thermostatically Controlled Loads},
  doi={10.1109/ISTEMS60181.2024.10560195},
  ISSN={},
  month={April},}@INPROCEEDINGS{10919315,
  author={Zhang, Yang and Zhang, LI and Zhu, Jinzhong},
  booktitle={2024 International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)}, 
  title={Research and Design of in-situ Test Method for Active Phased Array Radar}, 
  year={2024},
  volume={},
  number={},
  pages={813-818},
  abstract={The airborne active phased array radar has become the typical symbol of the fourth generation fighter, and is one of the most important weapons and equipment in the information war. With its large number of armed forces, the problem of falling performance index has gradually aroused the attention of equipment maintenance support personnel, and phased array radar has the characteristics of high equipment value, difficulty in disassembly and maintenance, and high use intensity, so it is necessary to study the in-situ test and maintenance method. In this paper, an active phased array radar in-situ testing method is presented, which can be used to test the performance of the transmitting channel, receiving channel and direction map of airborne active phased array radar, and the maintenance suggestions are put forward. The application shows that this method can effectively improve the detection efficiency of radar. Enhance the maintenance support capability of the user unit.},
  keywords={Phased arrays;Weapons;Airborne radar;Radar;Maintenance engineering;Radar equipment;Radar antennas;Maintenance;Arrays;Testing;Phased array;Radar;In-situ;Test},
  doi={10.1109/CSIS-IAC63491.2024.10919315},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{4126319,
  author={Nicholls, David},
  booktitle={2007 Annual Reliability and Maintainability Symposium}, 
  title={What is 217Plus/sup TM/ and Where Did It Come From?}, 
  year={2007},
  volume={},
  number={},
  pages={22-27},
  abstract={In June, 2005 the DoD contract for the Reliability Information Analysis Center (RIAC), formerly known as the Reliability Analysis Center (RAC), was awarded to a five member team comprised of Wyle Laboratories, Quanterion Solutions, the Center for Risk and Reliability at the University of Maryland, the Penn State University Applied Research Laboratory (ARL), and the State University of New York Institute of Technology (SUNY-IT). While the Center name and contractor change have been confusing to the R&M community-at-large, even more confusing has been the introduction of the DoD-funded 217Plustrade methodology and reliability prediction software tool by the RIAC to replace the DoD-funded PRISMreg tool introduced under the "old" RAC. In July 2006, RIAC released 217Plustrade as the successor to the DoD-funded, Defense Technical Information Center (DTIC)-sponsored Version 1.5 of the PRISMreg software tool. The RIAC release of 217Plustrade supplemented the six original component models with six new component models connectors, inductors, optoelectronic devices, relays, switches and transformers. Also, for the first time, the 217Plustrade models and methodology were published in the RIAC's "Handbook of 217Plus Reliability Prediction Models". The handbook, in a MIL-HDBK-217 style format, details the 217Plustrade methodology and models as a more current replacement for the early-90's vintage MIL-HDBK-217. The RIAC charter as a DTIC-sponsored Information Analysis Center (IAC) ensures that DoD funding will continue to support the data collection/analysis and modeling activities that are planned for future 217Plustrade releases and enhancements. This paper describes the evolution, and some of the technical detail, behind the RIAC's 217Plustrade methodology.},
  keywords={US Department of Defense;Reliability engineering;Information analysis},
  doi={10.1109/RAMS.2007.328101},
  ISSN={0149-144X},
  month={Jan},}@INPROCEEDINGS{10427797,
  author={Chua, Jonathan and Jiang, Xunfei},
  booktitle={2024 IEEE 14th Annual Computing and Communication Workshop and Conference (CCWC)}, 
  title={Building a Cloud Infrastructure for Virtual Machine Scheduling in Datacenters}, 
  year={2024},
  volume={},
  number={},
  pages={0105-0110},
  abstract={While CloudSim and other simulation tools are widely used for algorithmic validation of workload scheduling algorithms in academic research, they often fall short in accurately replicating the complexities and dynamics of real-world cloud environments. In this paper, we propose a cloud infrastructure to provide a more substantial environment than traditional simulation-based approaches for testing and validating theoretical scheduling algorithms. The core of the platform is built using Ansible, an open-source tool known for its efficiency in automation and configuration management. Ansible is used to provision and configure a cloud infrastructure environment, laying the groundwork for a scalable and reproducible research test bed. Zabbix, a robust monitoring solution, is integrated across the infrastructure to gather detailed server and virtual machine metric data, providing critical insights for the heuristics used in various scheduling algorithms. The design and implementation of this platform is presented, while highlighting the practical challenges and solutions encountered. We demonstrate how Ansible, in conjunction with Zabbix, can be effectively used to create a cloud infrastructure capable of executing and evaluating scheduling algorithms, offering a closer approximation to real-world conditions compared to traditional simulations. The research platform developed in this paper addresses the limitation of simulators by leveraging bare-metal resources, offering a more realistic and tangible testing ground.},
  keywords={Measurement;Cloud computing;Scheduling algorithms;Heuristic algorithms;Virtual machining;Monitoring;Testing;cloud infrastructure;Infrastructure-as-Code;automation;resource-management;scheduling},
  doi={10.1109/CCWC60891.2024.10427797},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{8280657,
  author={Supriyono, Heru and Hadi, Ahmad Nur},
  booktitle={2017 Second International Conference on Informatics and Computing (ICIC)}, 
  title={Designing a wheeled robot model for flammable gas leakage tracking}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={Gas pipeline tracking to find flammable gas leakage could be done manually by human worker. The activity are including walking from the start point along the way gas pipeline and record the condition. If the worker detects the presence of flammable gas, usually by its smell, and found the leakage point, he or she will stop and raise a concern for surrounding people or report to the office for further actions. This activities could harm the worker especially there will risk of fire and probably endangered life. The main objective of the research was to provide a model of intelligent gas pipeline tracking and to know its performance. The result of the research is a wheeled robot model developed based on the Arduino microprocessor equipped with gas sensor MQ2, LED and buzzer alarm for alert people and data logger in microSD memory card. The test results showed that wheeled robot able to sense the presence of flammable gas, tracking the gas pipeline using line follower principle, found the leakage point and stop instantly around 5.87 cm from the leakage point, as well as record the data in the form of file namely DATA.txt which can be used for further analysis.},
  keywords={Robot sensing systems;Mobile robots;Pipelines;Gas detectors;Light emitting diodes;Liquid crystal displays;wheeled robot model;gas leakage detection;gas pipeline tracking;gas detection systems},
  doi={10.1109/IAC.2017.8280657},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10040356,
  author={Pushpaleela, R.Christy and Sankar, S. and Viswanathan, K. and Kumar, S. Aathithya},
  booktitle={2022 1st International Conference on Computational Science and Technology (ICCST)}, 
  title={Application Modernization Strategies for AWS Cloud}, 
  year={2022},
  volume={},
  number={},
  pages={108-110},
  abstract={In the IT business, cloud computing has recently gained a lot of attention. II businesses are considering embracing the cloud since it offers a simple, affordable method of hosting apps and dynamically scaling them. The purpose of this research paper is to study and discuss about Modernization strategies for the digital transformation of on prime applications to transfer to the AWS cloud for Application with include data base migration with AWS cloud automation deployment using DevOps tools. The modernization strategy will include numerous stages. The stages are Analysis & Planning, Data Migration, Extraction &Transform, Quality Engineering and Go-Live/Deployment.},
  keywords={Cloud computing;Automation;Web services;Scientific computing;Digital transformation;Transforms;Containers;AWS(Amazon Web Service) Cloud;AWS Farget;Server less;CICD;Jenkins;Cloud Computing;Cloud Migration;Cloud Hosting;IaaS & PaaS;IaC;terraform;ECR (Elastic Container Service)},
  doi={10.1109/ICCST55948.2022.10040356},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10363944,
  author={Jin, Honglin and Cheng, Shi and Wang, Xueping and Liu, Yue and Shan, Yuyuan and Ran, Hao and Lu, Hui},
  booktitle={2023 International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)}, 
  title={A Neighborhood-Based Speciation Brain Storm Optimization with Evolution Strategy for Multimodal Optimization}, 
  year={2023},
  volume={},
  number={},
  pages={123-128},
  abstract={Finding multiple optimal solutions is challenging for solving multimodal optimization problems (MMOPs). In this paper, a neighborhood-based speciation brain storm optimization with evolution strategy (NS-BSO-ES) is proposed to solve MMOPs, which combines the advantages of better exploration of the neighborhood-based speciation brain storm optimization (NS-BSO) and more robust exploitation of the evolution strategy with covariance matrix adaptation (CMA-ES). In NS-BSO-ES, NS- BSO is used to generate candidate solutions to maintain the diversity of the population, CMA-ES is adopted to enhance the local search ability and locate optimal solutions accurately, and the archive is used to store inferior solutions to fully utilize the valuable information contained in these solutions as potential directions towards the optimal solution. To test the performance of NS-BSO-ES for solving MMOPs, compared with related algorithms on the 20 benchmark MMOPs in CEC-2013 Functions. Experimental results indicate NS-BSO-ES outperforms the other compared algorithms on most tested benchmark functions.},
  keywords={Adaptive systems;Heuristic algorithms;Sociology;Benchmark testing;Particle swarm optimization;Covariance matrices;Complex systems;brain storm optimization;evolution strategy with covariance matrix adaptation;multimodal optimization;neighborhood-based speciation},
  doi={10.1109/CSIS-IAC60628.2023.10363944},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10971458,
  author={Muthukrishnan, Harikrishnan and Viradia, Vijaykumar and Yadav, Deven},
  booktitle={SoutheastCon 2025}, 
  title={Unified AI and ML Framework in DevSecOps Practices, Solving Real-World Problems}, 
  year={2025},
  volume={},
  number={},
  pages={1250-1257},
  abstract={Artificial Intelligence (AI) and Machine Learning (ML) are evolving daily and advancing human progression in every field of endeavor like arts, science, and business. Information Technology (IT) is the field where this transformation is most accelerated due to its role in enabling digital transformation across other industries. DevSecOps is the standard set of practices that emerged as the ideal solution for managing the software development life cycle in this digital transformation journey. DevSecOps practices are also evolving along with the IT industry, and there are challenges and opportunities to improve continuously. This research paper introduces a conceptual framework for implementing a unified AI and ML solution to optimize the DevSecOps practice of any organization and constantly improve. This framework aims to solve some of the most challenging problems in DevSecOps practices by accelerating software development, reducing defects, increasing security scanning accuracy, enhancing automation, improving performance testing, and streamlining operations. Our solution accomplishes this using consolidated DevSecOps data-driven predictive analytics output from the Unified AI and ML model. By introducing this conceptual framework, the paper encourages more research and development in the core area of DevSecOps practices, which function as the cornerstone of digital transformation across all industries.},
  keywords={Industries;Root cause analysis;Codes;Digital transformation;Standards organizations;Transforms;Security;Monitoring;Anomaly detection;Testing;Artificial Intelligence;Machine Learning;IAC;GitOps;CI/CD;SDLC;MLOps;Platform Ops;Healthcare;DevOps},
  doi={10.1109/SoutheastCon56624.2025.10971458},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{10919435,
  author={Sha, Libo and Zi, Cheng and Wang, Huai and Yi, Haocheng and Duan, Qingna and Wang, Jiashou and Li, Minxian and Zhang, Zhuoyang and Li, Wenxiang},
  booktitle={2024 International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)}, 
  title={Optimization of the Structural Design of Glycerin Spraying Chamber of KDF-M NWT Filter Rod Making-machine Based on Flow Field Analysis in Confined Space}, 
  year={2024},
  volume={},
  number={},
  pages={599-604},
  abstract={This paper studies the fluid simulation in limit area using FLUENT with the goal of optimizing the structure of the confined space inside the glycerol triacetate spraying chamber in the slim-hollow rod making machine to reduce the incidence of defects and improve the quality of the finished product. First, three-dimensional models of the spraying chamber in each of the three volumetric configurations are created. Subsequently, the flow field zones with varied diameters and spraying pressure are extracted and replicated. At last, the machine experiments are conducted and the data are confirmed. The findings indicate that the ideal structure occurs when the spraying chamber's volume is medium-sized since this allows the particles to travel in all directions and have a more dispersed trajectory. Additionally, the filter rod has the fewest faults and the least variation in quality when the pressure is set at 10.3 bar.},
  keywords={Solid modeling;Fluids;Fluctuations;Spraying;Trajectory;Manufacturing;Complex systems;Optimization;Bars;filter rod making-machine;slim-hollow rod;spraying chamber;confined space;glycerol triacetate;fluid simulation},
  doi={10.1109/CSIS-IAC63491.2024.10919435},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11172968,
  author={Das, Sanjana and Lan, Ruiqing and Rinks, Caroline and Gokhale, Aniruddha and Essiari, Abdelilah and Kissel, Ezra and Yang, Xi and Ruth, Paul},
  booktitle={2025 28th International Symposium on Real-Time Distributed Computing (ISORC)}, 
  title={FEDS: An Intuitive Model-Driven Middleware for Automated Orchestration and Resource Configuration Across Federated Testbeds}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={As modern and responsive distributed systems grow in complexity, system designers and researchers face the challenge of testing these systems at scale under varied workload conditions to evaluate critical attributes such as performance, reliability, security, and maintainability. While numerous testbed platforms have emerged to facilitate large-scale experimentation, these platforms are designed primarily to study concepts such as virtualization, software-defined networking, and IoT in isolation, thereby leading to fragmented testbeds with limited interoperability. However, comprehensive evaluation of modern distributed systems demands validation across multiple testbeds at once, which is hindered by the lack of interoperability, steep learning curve, differing usage policies, and the complexity of resource reservations. Middleware holds the key to overcoming these challenges. In this paper, we introduce the Federated Experiments Design Studio (FEDS), a novel model-driven middleware ecosystem that simplifies the federation of disparate testbeds and automates experiment configuration. FEDS features a graphical front-end with a drag-and-drop interface, allowing users to intuitively design federated topologies, specify experiment properties, and generate the required orchestration artifacts, all within a single tool. This approach automates the entire workflow, from stitching testbeds together to configuring provisioned resources with the necessary packages and system settings. By streamlining the setup process, FEDS enables researchers to focus on generating valuable experimental insights rather than managing complex infrastructure.},
  keywords={Visualization;Complexity theory;Topology;Stakeholders;Security;Middleware;Virtualization;Software defined networking;Interoperability;Testing;Federating Testbeds;Model-Driven Engineering;Middleware;Automated Orchestration;Infrastructure-as-Code},
  doi={10.1109/ISORC65339.2025.00023},
  ISSN={2770-162X},
  month={May},}@INPROCEEDINGS{9240667,
  author={Openja, Moses and Adams, Bram and Khomh, Foutse},
  booktitle={2020 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Analysis of Modern Release Engineering Topics : – A Large-Scale Study using StackOverflow –}, 
  year={2020},
  volume={},
  number={},
  pages={104-114},
  abstract={Release engineers are continuously required to de-liver high-quality software products to the end-user. As a result, modern software companies are proposing new changes in their delivery process that adapt to new technologies such as continuous deployment and Infrastructure-as-Code. However, developers and release engineers still find these practices challenging, and resort to question and answer websites such as StackOverflow to find answers. This paper presents the results of our empirical study on release engineering questions in StackOverflow, to understand the modern release engineering topics of interest and their difficulty. Using topic modeling techniques, we find that (i) developers discuss on a broader range of 38 release engineering topics covering all the six phases of modern release engineering, (ii) the topics Merge Conflict, Branching & Remote Upstream are more popular, while topics Code review, Web deployment, MobileApp Debugging & Deployment, Continuous Deployment are less popular yet more complicated, (iii)-Particularly, the release engineering topic "security" is both popular and difficult according to data collected from StackOverflow.},
  keywords={Release engineering;Software maintenance;Conferences;Education;Debugging;Data models;Security;Modern Release Engineering;Topic Models;Empirical Study},
  doi={10.1109/ICSME46990.2020.00020},
  ISSN={2576-3148},
  month={Sep.},}@INPROCEEDINGS{11120590,
  author={Rafique, Ansar and Marsden, Brian D.},
  booktitle={2025 IEEE 18th International Conference on Cloud Computing (CLOUD)}, 
  title={Automated LLM Deployment and Evaluation: A Cloud-Native Approach Using LLM-as-a-Judge}, 
  year={2025},
  volume={},
  number={},
  pages={448-450},
  abstract={The rapid advancement of LLMs has led to widespread adoption across various domains, but it has also raised concerns about data security and privacy, particularly with publicly available and commercially operated platforms. Given their high computational demands, cloud environments are the obvious choice for deployment. As a result, organizations are increasingly deploying LLMs in confined cloud environments to protect sensitive data while leverazing scalable cloud resources. However, deploying LLMs in cloud environments remains a complex and time-consuming process that requires specialized skills and expertise in various areas, such as infrastructure management, resource allocation, and model setup. Testing and comparing LLMs to select the appropriate one is particularly challenging as different models are trained for different purposes, making the direct comparison nontrivial. Furthermore, differences in model architectures, training data, and fine-tuning strategies make objective evaluation difficult, limiting the effectiveness of traditional benchmarking approaches. To address these challenges, we present a cloud-native system that automates both the deployment and evaluation of LLMs. Our contributions are twofold: (i) we automate the provisioning and deployment of LLMs on various cloud platforms to stream-line infrastructure setup, and (ii) we develop a lightweight evaluation framework that leverages the LLM-as-a-Judge approach, where an independent LLM systematically assesses and compares different models based on predefined evaluation criteria. Our ongoing work aims to optimize LLM deployment by selecting cost-efficient cloud resources. We are also enhancing the evaluation framework with diverse prompts, broader metrics, and cross-model validation for fair, reproducible benchmarking.},
  keywords={Measurement;Cloud computing;Data privacy;Limiting;Data security;Training data;Organizations;Benchmark testing;Data models;Resource management;Cloud-Native LLM Deployment;Automated LLM Evaluation;IaC;LLM-as-a-Judge;LLM Benchmarking},
  doi={10.1109/CLOUD67622.2025.00053},
  ISSN={2159-6190},
  month={July},}@INPROCEEDINGS{10060017,
  author={Al Sadi, Amir and Berardi, Davide and Callegati, Franco and Melis, Andrea and Prandini, Marco and Tolomei, Luca},
  booktitle={2023 IEEE 20th Consumer Communications & Networking Conference (CCNC)}, 
  title={A Structured Approach to Insider Threat Monitoring for Offensive Security Teams}, 
  year={2023},
  volume={},
  number={},
  pages={628-631},
  abstract={In many countries, government agencies resort to third parties to acquire security services of many kinds, including Red Team operations to test the effectiveness of own defenses mechanisms. Absolute trust is a key requirement, lest a potentially devastating finding be exploited by a treacherous Red Team against the same entity which commissioned the operation, or sold to its adversaries. In our endeavour as a joint private-academic initiative to address this peculiar market, we observed that a structured approach to this issue is much less common than we would have expected. In this work, we outline the process we are devising to offer customers a verified environment, but integrating it with an evidence-based proof of their correct behavior during the operation, striving to solve the “Quis custodiet ipsos custodes” struggle in an offensive setting.},
  keywords={Operating systems;Government;Companies;Behavioral sciences;Security;Virtualization;Monitoring;Secure Infrastructure;Penetration Testing;Insider Threat;IaC},
  doi={10.1109/CCNC51644.2023.10060017},
  ISSN={2331-9860},
  month={Jan},}@INPROCEEDINGS{10363843,
  author={Zhang, Chan and Cang, Naimeng and Chen, Li and Jia, Zehua and Xue, Shan and Guo, Dongsheng},
  booktitle={2023 International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)}, 
  title={Improved Zeroing Neural Network for Solving Time-Variant Linear Equation with Harmonic Noise}, 
  year={2023},
  volume={},
  number={},
  pages={909-913},
  abstract={Time-variant linear equation (TVLE) is commonly involved in the science and engineering. Zeroing neural network (ZNN) and its variants have been developed and exhibited remarkable performance (e.g., noise rejection and finite-time convergence) on solving the TVLE. In this paper, we delve into a more in-depth investigation by enhancing the ZNN model for solving TVLE in the presence of harmonic noise. Such a model enables calculation error tend to zero, thereby facilitating the identification of the exact TVLE solution. To verify the supremacy of this enhanced ZNN model, we conduct a rigorous evaluation, assessing its properties such as convergence and robustness through various illustrative examples.},
  keywords={Simulation;Neural networks;Harmonic analysis;Mathematical models;Robustness;Complex systems;Convergence;Zeroing neural network (ZNN);harmonic noise;time-varying linear equation (TVLE);simulations},
  doi={10.1109/CSIS-IAC60628.2023.10363843},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10092653,
  author={Baresi, Luciano and Quattrocchi, Giovanni and Tamburri, Damian A.},
  booktitle={2023 IEEE 20th International Conference on Software Architecture Companion (ICSA-C)}, 
  title={2nd International Workshop on the Foundations of Infrastructure Specification and Testing : FIST 2023}, 
  year={2023},
  volume={},
  number={},
  pages={317-317},
  abstract={In today’s rapidly evolving IT market, organizations are facing the increasing pressure to deliver high-quality software quickly to meet the growing demands of consumers. This trend has given rise to the “need for speed” which has dominated the industry, and organizations are continuously seeking ways to improve their software development practices to achieve faster time-to-market. One of the key approaches used to meet this need for speed is the adoption of agile software architectures, such as microservices, which can shorten the software development cycle. These architectures break down large applications into smaller, more manageable services, which can be developed and deployed independently. This approach intermixes software development activities with IT operations, creating a paradigm known as DevOps. As part of the DevOps menu, many practices entail re-using standard tools from software development, such as code-versioning and coderevision management, to manage Infrastructure-as-Code (IaC).},
  keywords={Industries;Software architecture;Conferences;Standards organizations;Microservice architectures;Organizations;Computer architecture},
  doi={10.1109/ICSA-C57050.2023.00071},
  ISSN={2768-4288},
  month={March},}@INPROCEEDINGS{10537710,
  author={Dhanveer Prakash, M.P. and Sharma, Nidhi},
  booktitle={2023 Seventh International Conference on Image Information Processing (ICIIP)}, 
  title={The Convergence of DevOps and Cloud Computing: A Redefining Software Development}, 
  year={2023},
  volume={},
  number={},
  pages={800-805},
  abstract={In the current digital world, the combination of DevOps methods with cloud computing provides a better approach to software development, deployment, and administration. The findings investigate the pros and cons of using DevOps concepts and methodologies in the cloud environment. DevOps helps to upscale the speed, durability, and efficiency of software development by emphasizing collaboration, automation, and continuous improvement in the cloud. With the ability to scale and resource versatility, the cloud is a great platform for applying DevOps approaches. The CI/CD pipelines, infrastructure as code (IaC), containerization, orchestration, and automated testing play a major role in integrating DevOps in a cloud environment. In the end, the author has provided an overview of how DevOps and cloud integration may increase innovation, and efficiency to build a culture of cooperation. The continuous improvement provides significant insights for enterprises aiming to enhance their software development, and deployment processes in an increasingly cloud-centric environment by assessing the present status, and future development of DevOps methods in cloud computing.},
  keywords={Cloud computing;Technological innovation;DevOps;Scalability;Pipelines;Collaboration;Organizations;Containerization;version control;auto-scaling;Orchestration;cloud services;docker;CI/CD;Kubernetes},
  doi={10.1109/ICIIP61524.2023.10537710},
  ISSN={2640-074X},
  month={Nov},}@INPROCEEDINGS{11126141,
  author={Hossain, S M Mostaq and Altarawneh, Amani and Gupta, Maanak},
  booktitle={2025 IEEE International Conference on Service-Oriented System Engineering (SOSE)}, 
  title={Bridging Cloud Convenience and Protocol Transparency: A Hybrid Architecture for Ethereum Node Operations on Amazon Managed Blockchain}, 
  year={2025},
  volume={},
  number={},
  pages={129-139},
  abstract={As blockchain technologies are increasingly adopted in enterprise and research domains, the need for secure, scalable, and performance-transparent node infrastructure has become critical. While self-hosted Ethereum nodes offer operational control, they often lack elasticity and require complex maintenance. This paper presents a hybrid, service-oriented architecture for deploying and monitoring Ethereum full nodes using Amazon Managed Blockchain (AMB), integrated with EC2-based observability, IAM-enforced security policies, and reproducible automation via the AWS Cloud Development Kit. Our architecture supports end-to-end observability through custom EC2 scripts leveraging Web3.py and JSON-RPC, collecting over 1,000 real-time data points—including gas utilization, transaction inclusion latency, and mempool dynamics. These metrics are visualized and monitored through AWS CloudWatch, enabling service-level performance tracking and anomaly detection. This cloud-native framework restores low-level observability lost in managed environments while maintaining the operational simplicity of managed services. By bridging the simplicity of AMB with the transparency required for protocol research and enterprise monitoring, this work delivers one of the first reproducible, performance-instrumented Ethereum deployments on AMB. The proposed hybrid architecture enables secure, observable, and reproducible Ethereum node operations in cloud environments, suitable for both research and production use.},
  keywords={Measurement;Protocols;Service-oriented systems engineering;Real-time systems;Blockchains;Security;Telemetry;Observability;Monitoring;Anomaly detection;Amazon Managed Blockchain;Infrastructure-as-Code;Cloud-Native Deployment;Microservices;Observability;Ethereum Node Monitoring},
  doi={10.1109/SOSE67019.2025.00020},
  ISSN={2642-6587},
  month={July},}@INPROCEEDINGS{9282777,
  author={Kokuryo, Shoma and Kondo, Masanari and Mizuno, Osamu},
  booktitle={2020 IEEE 20th International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={An Empirical Study of Utilization of Imperative Modules in Ansible}, 
  year={2020},
  volume={},
  number={},
  pages={442-449},
  abstract={In recent years, a configuration management tool is adopted to manage complicated and huge systems such as bare-metal servers, cloud computing resources and our personal computers. Such a tool makes the operations to deploy services more efficient and eliminates dependencies on the specific system operators. The operations are required to be idempotent for reproducible deployment. However, the imperative modules whose operations may not be idempotent are used frequently to execute user-defined scripts on the target system; it is unclear why and how they are used, though using them frequently is believed to be a bad practice. In this paper, we studied why and how imperative modules are used in a configuration management tool, Ansible. We found that imperative modules are mainly used to perform operations that are not supported by Ansible, and about 45% of imperative modules are replaceable by other modules; the replaceable modules might be idempotent. We, therefore, recommend developers to look at replaceable modules before using imperative modules since replaceable modules might make their operations idempotent.},
  keywords={Configuration management;Software quality;Tools;Software reliability;Servers;Security;Task analysis;Ansible;idempotency;imperative modules;infrastructure as code;configuration management},
  doi={10.1109/QRS51102.2020.00063},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{1036145,
  author={Brotherton, T. and Grabill, P. and Wroblewski, D. and Friend, R. and Sotomayer, B. and Berry, J.},
  booktitle={Proceedings, IEEE Aerospace Conference}, 
  title={A testbed for data fusion for engine diagnostics and prognostics}, 
  year={2002},
  volume={6},
  number={},
  pages={6-6},
  abstract={A key to producing reliable engine diagnostics and prognostics resides in fusion of multisensor data. It is believed that faults will manifest effects in a variety of sensors. By 'integration' (fusion) of information across sensors detections can be made of faults that are undetectable on just a single sensor. Data to support development of prognostic techniques is very rare. The development requires continuous collection of significant amounts of data to capture not only "normal" data but also capture potential fault event data well before the fault is detected by existing techniques, as well as capture data related to rare events. The collected data can be analyzed to develop processing tailored to new events and to continuously update algorithms so as to improve detection and classification performance and reduce false alarms. IAC in collaboration with the Air Force and the Army is developing a testbed to perform data collection and to develop fusion techniques for gas turbine engine health monitoring. The testbed and examples of its operation are presented here.},
  keywords={Testing;Engines;Sensor fusion;Fault detection;Event detection;Data analysis;Performance analysis;Algorithm design and analysis;Collaboration;Performance evaluation},
  doi={10.1109/AERO.2002.1036145},
  ISSN={},
  month={March},}@INPROCEEDINGS{8780455,
  author={Ramadiani and Hatta, Heliza Rahmania and Novita, Nurlia and Azainil},
  booktitle={2018 Third International Conference on Informatics and Computing (ICIC)}, 
  title={Comparison of Two Methods Between TOPSIS and MAUT In Determining BIDIKMISI Scholarship}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Bidikmisi is one of the scholarships provided to students in universities, including Mulawarman University. To get the scholarship, students must meet the requirements and standards set by the government. The problem is the number of applicants who ask for Bidikmisi scholarship to make the decision maker must be fair, fast, transparent and objective in deciding who is eligible for a scholarship. There are two methods in this study to compare the accuracy of the decision of the scholarship recipient; namely TOPSIS method and MAUT method. In some studies, The Technique For Order Of Preference By Similarity To Ideal Solution (TOPSIS) method has been used in the case of Bidikmisi scholarship acceptance. While the method of Multi-Attribute Utility Theory (MAUT) is a new method and not many researchers are using it. Therefore, in this study conducted comparison method between TOPSIS and MAUT. The test data of Bidikmisi scholarship acceptance test using 150 students in 2017 with National Selection of State University Entrance (SNMPTN), 100 students accepted and 50 unaccepted students. The result of accuracy is done by comparing the original data with both methods so that the accuracy of TOPSIS method is 48% and MAUT method is 94,667%. Based on the analysis of the two methods, an application has been developed that compares MAUT method and TOPSIS method for Bidikmisi scholarship selection.},
  keywords={Scholarships;Mathematical model;Utility theory;Government;Decision support systems;Manuals;e-learning;Decision Support System;Scholarship;Bidikmisi;TOPSIS;MAUT},
  doi={10.1109/IAC.2018.8780455},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8780449,
  author={Suryono, Suryono and Khuriati, Ainie},
  booktitle={2018 Third International Conference on Informatics and Computing (ICIC)}, 
  title={Mobile Measurement System of Ozone Concentration in Urban Areas}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Ozone concentration significantly affects life quality of the people in an area. Ozone concentration that exceeds certain thresholds in heavily populated areas like most cities may be harmful for health and can even cause death. However, ozone monitoring has only so far been carried out at fixed sampling points using stationary instruments or conducted with manual recording instruments at certain sampling points. These types of measurements cannot represent the whole suburban areas that tend to be wide and populous. This paper proposes a mobile model of measuring ozone concentration with the integration of ozone sensors and Global Positioning System (GPS) sensor circuit. Measured data are acquired by the microprocessor, saved in a data base and analysis results are linked to a web mapping service. Measurements are carried out by encircling the intended urban areas. Results show that data from ozone sensors and measurement coordinates (latitude and longitude) can be stored in the data base and can visually be observed on the web mapping service in the form of spatial distribution of measurement points. Quantities of ozone concentration measurement results for a wide area can be seen on the data base. The system developed here is capable of monitoring environmental condition by acquiring ozone concentration distribution values.},
  keywords={Gases;Sensors;Global Positioning System;Area measurement;Coordinate measuring machines;Data acquisition;Instruments;concentration;measurement;mobile model;web mapping service;environment condition},
  doi={10.1109/IAC.2018.8780449},
  ISSN={},
  month={Oct},}@ARTICLE{9480419,
  author={Addison, Brett C and Wright, Duncan J and Nicholson, Belinda A and Cale, Bryson and Mocnik, Teo and Huber, Daniel and Plavchan, Peter and Wittenmyer, Robert A and Vanderburg, Andrew and Chaplin, William J and Chontos, Ashley and Clark, Jake T and Eastman, Jason D and Ziegler, Carl and Brahm, Rafael and Carter, Bradley D and Clerte, Mathieu and Espinoza, Néstor and Horner, Jonathan and Bentley, John and Jordán, Andrés and Kane, Stephen R and Kielkopf, John F and Laychock, Emilie and Mengel, Matthew W and Okumura, Jack and Stassun, Keivan G and Bedding, Timothy R and Bowler, Brendan P and Burnelis, Andrius and Blanco-Cuaresma, Sergi and Collins, Michaela and Crossfield, Ian and Davis, Allen B and Evensberget, Dag and Heitzmann, Alexis and Howell, Steve B and Law, Nicholas and Mann, Andrew W and Marsden, Stephen C and Matson, Rachel A and O'Connor, James H and Shporer, Avi and Stevens, Catherine and Tinney, C G and Tylor, Christopher and Wang, Songhu and Zhang, Hui and Henning, Thomas and Kossakowski, Diana and Ricker, George and Sarkis, Paula and Schlecker, Martin and Torres, Pascal and Vanderspek, Roland and Latham, David W and Seager, Sara and Winn, Joshua N and Jenkins, Jon M and Mireles, Ismael and Rowden, Pam and Pepper, Joshua and Daylan, Tansu and Schlieder, Joshua E and Collins, Karen A and Collins, Kevin I and Tan, Thiam-Guan and Ball, Warrick H and Basu, Sarbani and Buzasi, Derek L and Campante, Tiago L and Corsaro, Enrico and González-Cuesta, L and Davies, Guy R and de Almeida, Leandro and do Nascimento, Jose-Dias and García, Rafael A and Guo, Zhao and Handberg, Rasmus and Hekker, Saskia and Hey, Daniel R and Kallinger, Thomas and Kawaler, Steven D and Kayhan, Cenk and S. Kuszlewicz, James and Lund, Mikkel N and Lyttle, Alexander and Mathur, Savita and Miglio, Andrea and Mosser, Benoit and Nielsen, Martin B and Serenelli, Aldo M and Aguirre, Victor Silva and Themeßl, Nathalie},
  journal={Monthly Notices of the Royal Astronomical Society}, 
  title={TOI-257b (HD 19916b): a warm sub-saturn orbiting an evolved F-type star}, 
  year={2021},
  volume={502},
  number={3},
  pages={3704-3722},
  abstract={We report the discovery of a warm sub-Saturn, TOI-257b (HD 19916b), based on data from NASA's Transiting Exoplanet Survey Satellite (TESS). The transit signal was detected by TESS and confirmed to be of planetary origin based on radial velocity observations. An analysis of the TESS photometry, the Minerva-Australis, FEROS, and HARPS radial velocities, and the asteroseismic data of the stellar oscillations reveals that TOI-257b has a mass of MP = 0.138 ± 0.023 $\rm {M_J}$ (43.9 ± 7.3 $\, M_{\rm \oplus}$), a radius of RP = 0.639 ± 0.013 $\rm {R_J}$ (7.16 ± 0.15 $\, \mathrm{ R}_{\rm \oplus}$), bulk density of $0.65^{+0.12}_{-0.11}$ (cgs), and period $18.38818^{+0.00085}_{-0.00084}$ $\rm {days}$. TOI-257b orbits a bright (V = 7.612 mag) somewhat evolved late F-type star with M∗ = 1.390 ± 0.046 $\rm {M_{sun}}$, R∗ = 1.888 ± 0.033 $\rm {R_{sun}}$, Teff = 6075 ± 90 $\rm {K}$, and vsin i = 11.3 ± 0.5 km s−1. Additionally, we find hints for a second non-transiting sub-Saturn mass planet on a ∼71 day orbit using the radial velocity data. This system joins the ranks of a small number of exoplanet host stars (∼100) that have been characterized with asteroseismology. Warm sub-Saturns are rare in the known sample of exoplanets, and thus the discovery of TOI-257b is important in the context of future work studying the formation and migration history of similar planetary systems.},
  keywords={asteroseismology;techniques: photometric;techniques: radial velocities;techniques: spectroscopic;planetary systems;stars: individual (TIC 200723869/TOI-257)},
  doi={10.1093/mnras/staa3960},
  ISSN={1365-2966},
  month={Feb},}@INPROCEEDINGS{10301337,
  author={Lv, Yixiao and Yin, Jiaqi and Chen, Sini and Zhu, Huibiao},
  booktitle={2023 IEEE 34th International Symposium on Software Reliability Engineering Workshops (ISSREW)}, 
  title={Formalization and Verification of the ICC Mechanism in Android System Using CSP}, 
  year={2023},
  volume={},
  number={},
  pages={89-95},
  abstract={With the rapid development of mobile computing technology, Android System is widely used in smart devices, and the quantity of Android Apps continuously grows. The Inter-Component Communication (ICC) mechanism in the Android framework allows communication between components (inside the same App or on different Apps). However, some security issues are caused by this mechanism, especially in the case of Inter-App Communication (IAC). To ensure the security of the communication in Android System, we formally model the ICC mechanism using Communication Sequential Process (CSP). After that, we verify four properties of the model using the Process Analysis Toolkit (PAT) with the help of C#, including Deadlock Freedom, Data Reachability, Data Security, and Data Reliability.},
  keywords={Analytical models;Data security;Conferences;System recovery;Data models;C# languages;Software reliability;Android;Inter-Component Communication (ICC);Inter-App Communication (IAC);Communicating Sequential Process (CSP);PAT with C#},
  doi={10.1109/ISSREW60843.2023.00053},
  ISSN={},
  month={Oct},}@ARTICLE{10816445,
  author={Bolelli, Federico and Lumetti, Luca and Vinayahalingam, Shankeeth and Di Bartolomeo, Mattia and Pellacani, Arrigo and Marchesini, Kevin and van Nistelrooij, Niels and van Lierop, Pieter and Xi, Tong and Liu, Yusheng and Xin, Rui and Yang, Tao and Wang, Lisheng and Wang, Haoshen and Xu, Chenfan and Cui, Zhiming and Wodzinski, Marek and Müller, Henning and Kirchhoff, Yannick and Rokuss, Maximilian R. and Maier-Hein, Klaus and Han, Jaehwan and Kim, Wan and Ahn, Hong-Gi and Szczepański, Tomasz and Grzeszczyk, Michal K. and Korzeniowski, Przemyslaw and Caselles-Ballester, Vicent and Paolo Burgos-Artizzu, Xavier and Prados Carrasco, Ferran and Berge’, Stefaan and van Ginneken, Bram and Anesi, Alexandre and Grana, Costantino},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Segmenting the Inferior Alveolar Canal in CBCTs Volumes: The ToothFairy Challenge}, 
  year={2025},
  volume={44},
  number={4},
  pages={1890-1906},
  abstract={In recent years, several algorithms have been developed for the segmentation of the Inferior Alveolar Canal (IAC) in Cone-Beam Computed Tomography (CBCT) scans. However, the availability of public datasets in this domain is limited, resulting in a lack of comparative evaluation studies on a common benchmark. To address this scientific gap and encourage deep learning research in the field, the ToothFairy challenge was organized within the MICCAI 2023 conference. In this context, a public dataset was released to also serve as a benchmark for future research. The dataset comprises 443 CBCT scans, with voxel-level annotations of the IAC available for 153 of them, making it the largest publicly available dataset of its kind. The participants of the challenge were tasked with developing an algorithm to accurately identify the IAC using the 2D and 3D-annotated scans. This paper presents the details of the challenge and the contributions made by the most promising methods proposed by the participants. It represents the first comprehensive comparative evaluation of IAC segmentation methods on a common benchmark dataset, providing insights into the current state-of-the-art algorithms and outlining future research directions. Furthermore, to ensure reproducibility and promote future developments, an open-source repository that collects the implementations of the best submissions was released.},
  keywords={Three-dimensional displays;Irrigation;Annotations;Image segmentation;Training;Surgery;Deep learning;Benchmark testing;Teeth;Proposals;Segmentation;tooth;neural network;X-ray imaging;computed tomography},
  doi={10.1109/TMI.2024.3523096},
  ISSN={1558-254X},
  month={April},}@INPROCEEDINGS{10476527,
  author={Xiao, Chupeng and Xu, Jing and Xu, Chenguan and Zhu, Liangliang and Gui, Junping and Wang, Xi},
  booktitle={2023 6th International Conference on Intelligent Autonomous Systems (ICoIAS)}, 
  title={Distributed Fixed-Time Control of Inverter Air Conditioners Based on Consensus Strategy}, 
  year={2023},
  volume={},
  number={},
  pages={273-278},
  abstract={With the depletion of global resources, the regulation and control of power system has attached more and more importance. Besides, the demand for operating reserve to maintain the power system balance is increasing. With traditional generating units phasing out, it is concerned that they may become inadequate to meet the reserve requirement in the near future. Thus, the demand-side management is becoming increasingly important. Inverter air conditioners (IACs) account for a larger proportion in the power consumption. Nevertheless, the control and optimization of distributed IACs is complicated. To address the above-mentioned issues, this manuscript proposes a distributed control strategy for the regulation of IACs. Based on the consensus theory, the states convergence and the power regulation of IACs is realized within the settling time. By utilizing Lyapunov stability theorem and consensus theory, the convergence of control strategy is verified. Finally, the simulation results are given to demonstrate the effectiveness.},
  keywords={Power demand;Simulation;Decentralized control;Power system stability;Regulation;Inverters;Stability analysis;Distributed control;nonlinear consensus;inverter air conditioner (IAC);Lyapunov stability},
  doi={10.1109/ICoIAS61634.2023.00072},
  ISSN={2836-7642},
  month={Sep.},}@INPROCEEDINGS{10398978,
  author={Oh, Jieun and Piao, Zhe and Kim, Kyungsang and Cho, Hyun Jin and Kang, Min-Woong},
  booktitle={2022 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC)}, 
  title={CT-Based Invasiveness Analysis of Lung Pure Ground-Glass Nodules}, 
  year={2022},
  volume={},
  number={},
  pages={1-2},
  abstract={LUNG cancer remains the leading cause of cancer and cancer mortality worldwide. According to the International Association for the Study of Lung Cancer (IASLC), American Thoracic Society (ATS), and European Respiratory Society (ERS) classification, lung adenocarcinoma is categorized into three subtypes, pre-invasive lesions, minimally invasive adenocarcinoma (MIA), and invasive adenocarcinoma (IAC). Based on previous reports, experts from the core panel of IASLC/ATS/ERS suggest that pre-invasive lesions and MIA would show near 100% disease-free survival if complete resection with negative margins is performed [1] .},
  keywords={Minimally invasive surgery;Computed tomography;Lung cancer;Lung;Europe;Sensitivity and specificity;Lesions},
  doi={10.1109/NSS/MIC44845.2022.10398978},
  ISSN={2577-0829},
  month={Nov},}@INBOOK{9932306,
  author={Janca, Tanya},
  booktitle={Alice and Bob Learn Application Security}, 
  title={Securing Modern Applications and Systems}, 
  year={2021},
  volume={},
  number={},
  pages={167-191},
  abstract={This chapter provides high&#x2010;level explanations of security tactics for the following: Application programming interface (APIs) and microservices, online storage, containers and orchestration, cloud workflows, serverless, infrastructure as code, security as code, platform as a service, infrastructure as a service, CI/CD, DevSecOps, cloud and cloud workflows. It looks at modern and new application security tools, as well as modern and new tactics for AppSec. APIs are the code between two pieces of software that allows them to talk; it also defines the protocol. Containers are significantly smaller than virtual machines; instead of hosting an entire operating system, they only host the parts of the operating system that developers require in order to run their application. The chapter discusses new types of security tooling. There are several new types of security tools being developed or on the market, specifically and only, to work in CI/CD pipelines.},
  keywords={Microservice architectures;Codes;Security;Logic gates;Cloud computing;Organizations;Monitoring},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781119687399},
  url={https://ieeexplore.ieee.org/document/9932306},}@INPROCEEDINGS{10187247,
  author={Petrović, Nenad},
  booktitle={2023 58th International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST)}, 
  title={Chat GPT-Based Design-Time DevSecOps}, 
  year={2023},
  volume={},
  number={},
  pages={143-146},
  abstract={Adoption of DevOps-enabled software development has become one of constituent processes within the workflow behind competitive organizations in any area of industry. Its main purpose consists of automation when it comes to steps of development, testing and deployment, aiming to achieve continuous integration and delivery of products and services. On the other side, these highly automatized steps are prone to security flaws and various types of vulnerabilities, which could have fatal consequences, especially in critical domains of usage, such as sensitive usage scenarios related to public infrastructure and healthcare. For that reason, the so-called DevSecOps has emerged, whose main scope are security concerns in DevOps-based automated workflows. In this paper, Python API of novel ChatGPT conversational agent service is leveraged for static code analysis of Infrastructure as Code (IaC) scripts. Moreover, we perform aggregation and post-processing of results returned by ChatGPT, making them more useful when it comes to end-users, such as DevOps engineers and system administrators. When it comes to evaluation, we focus on Ansible and Terraform IaC script case studies.},
  keywords={Industries;Codes;Public infrastructure;Organizations;Medical services;Chatbots;Software;Ansible;ChatGPT;DevSecOps;Python;Terraform},
  doi={10.1109/ICEST58410.2023.10187247},
  ISSN={},
  month={June},}@INPROCEEDINGS{6577251,
  author={Cernigliaro, Alice and Valloreia, Stefano and Galleani, Lorenzo and Tavella, Patrizia},
  booktitle={2013 International Conference on Localization and GNSS (ICL-GNSS)}, 
  title={GNSS space clocks: Performance analysis}, 
  year={2013},
  volume={},
  number={},
  pages={1-5},
  abstract={Atomic clocks are fundamental elements of a Global Navigation Satellite System (GNSS). Currently, several GNSSs are operational and the different clock technologies employed onboard their satellites benefit from the technological improvements achieved during the last decades. To ensure the timing capabilities needed for correct positioning, the analysis of GNSS clock performances is essential. We have recently started a performance analysis for GPS and GLONASS clocks, by using the satellite clock estimates produced by the Information-Analytical Centre (IAC) of the Russian Federal Space Agency. In this paper we discuss a few preliminary results of this analysis. We analyze the time deviation, frequency deviation, and frequency stability of the Cesium and Rubidium clocks onboard three GPS and GLONASS satellites. The obtained results highlight the presence of two common space clock anomalies, namely, deterministic oscillations and frequency jumps. Our final goal is to build a detailed statistics of the clock anomalies for all GNSSs.},
  keywords={Global Positioning System;Satellites;Satellite broadcasting;Global Navigation Satellite Systems;Atomic clocks;Time-frequency analysis;GNSS timing;atomic clocks;clock characterization;clock anomalies;frequency jumps},
  doi={10.1109/ICL-GNSS.2013.6577251},
  ISSN={2325-0771},
  month={June},}@INPROCEEDINGS{7052510,
  author={Parry, David and Houliston, Bryan and Foy, John},
  booktitle={2014 IEEE International Conference on Healthcare Informatics}, 
  title={RFID Tracking to Study Clinical Activity in the Operating Room}, 
  year={2014},
  volume={},
  number={},
  pages={349-354},
  abstract={Measuring activity in the operating theatre is a difficult but important task. Using ultra wideband active RFID tags (UWB) we were able to track an anesthetist and anesthetic technician during a simulated operation. A number of parameters were calculated including gaze direction, distance travelled and separation were calculated. Some characteristic movements were identified, including head and torso rotation. Ultra wideband RFID may form part of a suite of sensors that can begin to identify activity during operations.},
  keywords={Radiofrequency identification;Vectors;Surgery;Torso;Drugs;Monitoring;Anesthesia;Activity Analysis;RFID},
  doi={10.1109/ICHI.2014.55},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{5735370,
  author={Joseph, Justin and Madhukumar, S.},
  booktitle={2010 International Conference on Systems in Medicine and Biology}, 
  title={A novel approach to Data Driven Preventive Maintenance Scheduling of medical instruments}, 
  year={2010},
  volume={},
  number={},
  pages={193-197},
  abstract={The objective of this endeavor has been to develop a Preventive Maintenance Index (PMI) for each instrument in the clinical engineering inventory to assign a preventive maintenance interval (PMInterval), in what the safety tests most be applied as well as to prioritize the PM procedure. This numerical index has been synthesized based on Risk Level Coefficient (RLC) of the instrument. The equipment inventory has been categorized as per the recommendations of International Electro safety Commission (IEC), Federal Drug Agency (FDA) and Hill into various risk groups as Type C, B, H, Class I, II, III, General, Susceptible, Critical and so on. Relevance factor has been imposed to each aspect analyzed. Static Risk of specific medical equipment is assessed through the factors Physical Risk (PR), Equipment Function (EF), and Hazard Potential (HP).The Hazard Potential of each equipment is extracted from the outcome of a pilot survey conducted at national level, so as the system to be evidence based. The Risk Level Coefficient of equipments are derived by statistically integrating individual relevance coefficients and static risk (SR). A standard audit interval is inadequate; hence PMInterval is designed to be adaptive based on the Interval Adaptation Coefficient (IAC) which in turn points Failure / accident history of the equipment. An attempt to incooperate the PM Due Factor (DF), Age Ratio (AR) and Usability Ratting (UR) also has been made. The proposed `Data Driven Preventive Maintenance Scheduling', is in par and comply with, ISO 14971, IEC 60601 Series and JCAHO regulations.},
  keywords={Biomedical equipment;Preventive maintenance;Hazards;Indexes;Instruments;Risk Level Coefficient;Static Risk Factor;Hazard Potential;Interval adaptation Coefficient},
  doi={10.1109/ICSMB.2010.5735370},
  ISSN={},
  month={Dec},}@ARTICLE{10376418,
  author={Kwon, Sunjae and Lee, Sungu and Kim, Taehyoun and Ryu, Duksan and Baik, Jongmoon},
  journal={Journal of Web Engineering}, 
  title={Exploring LLM-Based Automated Repairing of Ansible Script in Edge-Cloud Infrastructures}, 
  year={2023},
  volume={22},
  number={6},
  pages={889-912},
  abstract={Edge-Cloud system requires massive infrastructures located in closer to the user to minimize latencies in handling Big data. Ansible is one of the most popular Infrastructure as Code (IaC) tools crucial for deploying these infrastructures of the Edge-cloud system. However, Ansible also consists of code, and its code quality is critical in ensuring the delivery of high-quality services within the Edge-Cloud system. On the other hand, the Large Langue Model (LLM) has performed remarkably on various Software Engineering (SE) tasks in recent years. One such task is Automated Program Repairing (APR), where LLMs assist developers in proposing code fixes for identified bugs. Nevertheless, prior studies in LLM-based APR have predominantly concentrated on widely used programming languages (PL), such as Java and C, and there has yet to be an attempt to apply it to Ansible. Hence, we explore the applicability of LLM-based APR on Ansible. We assess LLMs' performance (ChatGPT and Bard) on 58 Ansible script revision cases from Open Source Software (OSS). Our findings reveal promising prospects, with LLMs generating helpful responses in 70% of the sampled cases. Nonetheless, further research is necessary to harness this approach's potential fully.},
  keywords={Java;Computer languages;Codes;Computer bugs;Big Data;Chatbots;Task analysis;Edge-cloud;Ansible;Bard;large langue model;automated program repairing},
  doi={10.13052/jwe1540-9589.2263},
  ISSN={1544-5976},
  month={Sep.},}@INPROCEEDINGS{5910600,
  author={Chae, Yongwook and Jo, Sungho and Jeong, Jaeseung},
  booktitle={2011 5th International IEEE/EMBS Conference on Neural Engineering}, 
  title={Brain-actuated humanoid robot navigation control using asynchronous Brain-Computer Interface}, 
  year={2011},
  volume={},
  number={},
  pages={519-524},
  abstract={Brain-actuated robotic systems have been proposed as a new control interface to translate different human intentions into appropriate motion commands for robotic applications. This study proposes a brain-actuated humanoid robot navigation system that uses an EEG-BCI. The experimental procedures consisted of offline training sessions, online feedback test sessions, and real-time control sessions. During the offline training sessions, amplitude features from the EEGs were extracted using band power analysis, and the informative feature components were selected using the Fisher ratio and the linear discriminant analysis (LDA) distance metric. The Intentional Activity Classifier (IAC) and the Motor Direction Classifier (MDC) were hierarchically structured and trained to build an asynchronous BCI system. During the navigation experiments, the subject controlled the humanoid robot in an indoor maze using the BCI system with real-time images from the camera on the robot's head. The results showed that three subjects successfully navigated the indoor maze using the proposed brain-actuated humanoid robot navigation system.},
  keywords={Humanoid robots;Training;Navigation;Feature extraction;Foot;Head},
  doi={10.1109/NER.2011.5910600},
  ISSN={1948-3554},
  month={April},}@ARTICLE{10918668,
  author={Bortoluzzi, Fabricio and Irwin, Barry and Westphall, Carla Merkle},
  journal={IEEE Access}, 
  title={Cloud Telescope: An Ephemeral, Distributed, and Cloud-Native Architecture for Collecting Internet Background Radiation}, 
  year={2025},
  volume={13},
  number={},
  pages={45682-45714},
  abstract={For two decades, cyber security researchers have been looking to answer one major question: what threats affect the Internet at large? In addition, what malicious traffic patterns would emerge if we could sample the unsolicited traffic - termed Internet Background Radiation (IBR) - arriving at devices directly connected to the Internet? The standard approach to collecting malicious traffic is the Network Telescope: a computer device assigned with a public IP address range, configured to passively listen to incoming packets. The deployment of Network Telescopes has helped to detect and quantify major cyberspace outbreaks, from the rise of the Conficker malware, to uncovering massive botnet propagation activity, such as performed by Mirai and its variants, against the Internet-of-Things. This paper introduces the Cloud Telescope: an ephemeral, cloud-native architecture, described as Infrastructure-as-Code, enabling for geographically distributed capture of the IBR, along with a discussion of a 5-month-long validation experiment, in which a sensor fleet comprising 130 cloud instances was launched across twenty-six regions of the world. The result is a quantitative and qualitative analysis of 530 million captured packets. This includes traffic breakdown by protocol: TCP (80%), UDP (3%), ICMP (17%), and by source country. We also discuss traffic aggregation by destination country and by affected cloud region, enabling novel forms of geopolitical influence analysis.},
  keywords={Telescopes;Internet;Cloud computing;IP networks;Botnet;Standards;Protocols;Malware;Hardware;Backscatter;Cloud telescope;cloud computing;network telescopes;cyber threat intelligence;internet background noise;internet background radiation;darknet traffic analysis},
  doi={10.1109/ACCESS.2025.3549623},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10919298,
  author={Huang, Zhanjun and Shang, Wenzhuo and Wang, Yiming and Zhang, An},
  booktitle={2024 International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)}, 
  title={A Design Method of Civil Aircraft Warning System Based on MBSE}, 
  year={2024},
  volume={},
  number={},
  pages={930-935},
  abstract={Currently, the design approach for aircraft warning systems is predominantly reliant on documents, which is in contrast to the utilization of model system engineering being rel-atively limited. However, these techniques give rise to challenges such as insufficient design precision, poor model reusability, and complex structural design, which ultimately impact the quality and efficiency of aircraft research and development. To address these challenges, this paper proposes an aircraft warning system design method based on MBSE (Model-Based Systems Engineering). The method's core framework is built upon the Harmony SE approach, combined with the unique characteristics of the aircraft warning system. The design process involves three stages: “requirement analysis - functional logic analysis - architecture design”. In each stage, the method incorporates enterprise architect and SysML (Systems Modeling Language) to perform instance modeling and verify its effectiveness. Compared to traditional warning system design methods, this approach takes into consideration the specific characteristics of civilian aircraft warning systems, effectively mitigating common issues in the warning system design process while enhancing the efficiency of alarm system develonment.},
  keywords={Accuracy;Atmospheric modeling;Design methodology;Alarm systems;Systems Modeling Language;Logic;Aircraft;Aircraft propulsion;Complex systems;Research and development;MBSE;Warning system;Harmony-SE},
  doi={10.1109/CSIS-IAC63491.2024.10919298},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10232579,
  author={Seidel, T. and Javaloyes, J. and Gurevich, S. V.},
  booktitle={2023 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC)}, 
  title={A Normal form for Frequency Combs and Localized States in Time-Delayed Kerr-Gires-Tournois Interferometers}, 
  year={2023},
  volume={},
  number={},
  pages={1-1},
  abstract={Recently, an alternative method for the generation of phase-locked optical frequency combs (OFCs) with tunable repetition rate that maintain the high optical power levels characteristic of VECSELs was proposed using a first principle model relying on delay algebraic equations (DAEs) [1], [2]. A schematic setup of the system is presented in Fig. 1(a). It is composed of a disk-shaped monomode micro-cavity similar to a VCSEL structure but that contains a nonlinear Kerr medium. The micro-cavity is closed by two distributed Bragg mirrors with reflectivities $r_{1,2}$, whereas the long external cavity with round-trip time $\tau\gg\tau_{c}$ is closed by a feedback mirror with reflectivity $\eta$ and the feedback phase $\phi$.},
  keywords={Reflectivity;Time-frequency analysis;Optical interferometry;Optical feedback;Mathematical models;Optical harmonic generation;Mirrors},
  doi={10.1109/CLEO/Europe-EQEC57999.2023.10232579},
  ISSN={2833-1052},
  month={June},}@INPROCEEDINGS{10232554,
  author={Seidel, T. and Gurevich, S. V. and Javaloyes, J.},
  booktitle={2023 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC)}, 
  title={From coherence to incoherence in harmonic mode-locked lasers}, 
  year={2023},
  volume={},
  number={},
  pages={1-1},
  abstract={Passive mode-locking is a well established technique to obtain short optical pulses with high repetition rates. In these devices, the combined dynamics of a gain and a saturable absorber promotes the pulsed emission over the continuous wave regime. Beyond the fundamental mode-locked (FML) solution, where a single pulse is present in the cavity, multi-pulse solutions are possible, the so-called harmonic mode-locked solutions (HML). In this contribution we want to answer a seemingly obvious question: Are the pulses in an harmonic state coherent?},
  keywords={Laser mode locking;Europe;Coherence;Harmonic analysis;Optical pulses},
  doi={10.1109/CLEO/Europe-EQEC57999.2023.10232554},
  ISSN={2833-1052},
  month={June},}@INPROCEEDINGS{7543779,
  author={Daojuan Zhang and Rui Wang and Zimin Lin and Dianjie Guo and Xiaochun Cao},
  booktitle={2016 IEEE Symposium on Computers and Communication (ISCC)}, 
  title={IacDroid: Preventing Inter-App Communication capability leaks in Android}, 
  year={2016},
  volume={},
  number={},
  pages={443-449},
  abstract={Inter-App Communication (IAC) plays an important role in Android platform to share data and services among applications. However, the existence of IAC capability leaks could lead to the unauthorized privileged operations. In this paper, we first investigate the usage of IAC in Android applications to show the prevalence of IAC in the Android development model. To mitigate the threat caused by IAC capability leaks in Android, we develop a real-time monitoring and control system, called IacDroid, which distinguishes and prevents the IAC capability leak accurately in both third-party and in-rom applications at runtime. IacDroid extends the Binder IPC mechanism and the system service to construct context-based component call chains between multiple applications. By leveraging the call chains, the permission system is extended to detect and prevent the IAC capability leaks. IacDroid also presents an intuitive client-side solution to help users control the IAC capability leaks. We implement the prototype in Android 4.3, and present a comprehensive assessment with 500 Google Play applications and 36 malicious applications. The experimental results demonstrate that IacDroid can effectively prevent the IAC capability leaks with a negligible performance overhead.},
  keywords={Androids;Humanoid robots;Smart phones;Runtime;Computers;Security;Real-time systems},
  doi={10.1109/ISCC.2016.7543779},
  ISSN={},
  month={June},}@INPROCEEDINGS{8634843,
  author={Gogoberidze, G. and Rumiantceva, E. and Danilov, A. and Zhigulsky, V. and Zhigulskaya, D. and Shuisky, V. and Maksimova, E.},
  booktitle={2018 IEEE/OES Baltic International Symposium (BALTIC)}, 
  title={Analysis of scientific researches in Russian Arctic}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper analyzes data on major Russian projects in the Arctic theme. It is shown that the average volume of one Arctic project in 2017 showed a 10% reduction relative to 2016. The main source of financing is the Russian Federal budget, which contributes a little less than 80% in funding for all Arctic projects. The scientific direction "Development of science and technologies of development of the Arctic" leads on the subject of Arctic projects. Considering the distribution of scientific research on the development of innovative technologies, the largest amounts of total Arctic project financing for the period under review are associated with three groups of technologies: "Technologies for monitoring and forecasting of the environment, preventing and eliminating of pollution", "Technologies for prospecting, exploration and development of mineral deposits and their extraction" and "Technologies of information, control and navigation systems". In general, in 2017 the financing of Arctic-related projects is less than 1.9% of the total financing of the research work of the Russian Federation. Creation and activity of the coordinating consulting body in the form of Information-Analytical Center of the Murmansk Arctic State University (MASU) in partnership with the Federal Research Center "Kola Science Center of the Russian Academy of Sciences" (IAC MASU-KSC) will allow to coordinate and direct activity of the scientific organizations and considerably to increase efficiency of scientific researches in the conditions of limited financing. The successful work of the IAC MASU-KSC will stimulate the development and implementation of innovative products and technologies in the field of ensuring comfortable human habitation in Arctic and the preservation of Arctic ecosystems.},
  keywords={Arctic;Organizations;Antarctica;Monitoring;Safety;Economics;Geology},
  doi={10.1109/BALTIC.2018.8634843},
  ISSN={2150-6035},
  month={June},}@ARTICLE{9521094,
  author={Borsato, L and Piotto, G and Gandolfi, D and Nascimbeni, V and Lacedelli, G and Marzari, F and Billot, N and Maxted, P F L and Sousa, S and Cameron, A C and Bonfanti, A and Wilson, T G and Serrano, L M and Garai, Z and Alibert, Y and Alonso, R and Asquier, J and Bárczy, T and Bandy, T and Barrado, D and Barros, S C C and Baumjohann, W and Beck, M and Beck, T and Benz, W and Bonfils, X and Brandeker, A and Broeg, C and Cabrera, J and Charnoz, S and Csizmadia, S and Davies, M B and Deleuil, M and Delrez, L and Demangeon, O and Demory, B-O and des Etangs, A L and Ehrenreich, D and Erikson, A and Escudé, G A and Fortier, A and Fossati, L and Fridlund, M and Gillon, M and Guedel, M and Hasiba, J and Heng, K and Hoyer, S and Isaak, K G and Kiss, L and Kopp, E and Laskar, J and Lendl, M and Lovis, C and Magrin, D and Munari, M and Olofsson, G and Ottensamer, R and Pagano, I and Pallé, E and Peter, G and Pollacco, D and Queloz, D and Ragazzoni, R and Rando, N and Rauer, H and Ribas, I and Ségransan, D and Santos, N C and Scandariato, G and Simon, A and Smith, A M S and Steller, M and Szabó, G and Thomas, N and Udry, S and Van Grootel, V and Walton, N},
  journal={Monthly Notices of the Royal Astronomical Society}, 
  title={Exploiting timing capabilities of the CHEOPS mission with warm-Jupiter planets}, 
  year={2021},
  volume={506},
  number={2},
  pages={3810-3830},
  abstract={We present 17 transit light curves of seven known warm-Jupiters observed with the CHaracterising ExOPlanet Satellite (CHEOPS). The light curves have been collected as part of the CHEOPS Guaranteed Time Observation (GTO) program that searches for transit-timing variation (TTV) of warm-Jupiters induced by a possible external perturber to shed light on the evolution path of such planetary systems. We describe the CHEOPS observation process, from the planning to the data analysis. In this work, we focused on the timing performance of CHEOPS, the impact of the sampling of the transit phases, and the improvement we can obtain by combining multiple transits together. We reached the highest precision on the transit time of about 13–16 s for the brightest target (WASP-38, G = 9.2) in our sample. From the combined analysis of multiple transits of fainter targets with G ≥ 11, we obtained a timing precision of ∼2 min. Additional observations with CHEOPS, covering a longer temporal baseline, will further improve the precision on the transit times and will allow us to detect possible TTV signals induced by an external perturber.},
  keywords={techniques: photometric;planets and satellites: individual: HAT-P-17 b, KELT-6 b, WASP-8 b, WASP-38 b, WASP-106 b, WASP-130 b, K2-287 b},
  doi={10.1093/mnras/stab1782},
  ISSN={1365-2966},
  month={July},}@INPROCEEDINGS{10363992,
  author={Hu, Jingyao and Li, Chao and Yang, Qinmin},
  booktitle={2023 International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)}, 
  title={Spare Parts Inventory Optimization for Wind Farms}, 
  year={2023},
  volume={},
  number={},
  pages={859-864},
  abstract={The wind power industry has received a lot of attention in recent years due to its environmental friendliness. Spare parts management is an important part of wind power industry, it is crucial due to the ability to establish a balance between system uptime and maintenance costs, thereby affecting the overall performance of a wind farm. Adopting an optimal policy for a single component in a system with multiple components cannot ensure that the income will be maximized. Therefore, we establish an optimization model to maximize the wind farm's availability within a budgetary constraint. We propose employing a convex optimization strategy by carefully analyzing and transforming the system model. The methodology utilizes the barrier interior point method. Comparative analysis with Matlab-implemented PSO demonstrates that our proposed method achieves an improved inventory strategy in less time.},
  keywords={Industries;Costs;Wind speed;Wind farms;Wind power generation;Convex functions;Mathematical models;Inventory strategy;Wind farm spare parts;Convex optimization;Barrier interior point method},
  doi={10.1109/CSIS-IAC60628.2023.10363992},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10795910,
  author={Maturana-Candelas, Aarón and Rodríguez-González, Víctor and Gijón-Ortego, Jorge and Iglesias-Parro, Sergio and Ibóñez-Molina, Antonio J. and Gómez, Carlos and Poza, Jesús},
  booktitle={2024 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={Analysis of the Neural Networks Dynamics Associated to Resting-State Electroencephalographic Activity in Schizophrenia Patients}, 
  year={2024},
  volume={},
  number={},
  pages={266-270},
  abstract={The objective of this study is to characterize the dynamic changes in the global node strength of the neuronal network in patients with schizophrenia (SZ) during the resting-state. Previous studies suggest that cognitive impairments associated with SZ could be linked to functional alterations in neuronal networks, leading to a “disconnection syndrome”. Therefore, electroencephalographic (EEG) activity was recorded from 11 SZ patients and 20 control subjects. Time-varying functional connectivity was estimated using the instantaneous amplitude correlation (IAC) derived from EEG data in the conventional EEG frequency bands. Subsequently, using the time-resolved adjacency matrices in each frequency band, the distribution of global node strength was computed to analyze the alterations that SZ elicits in the properties of IAC fluctuations. To ascertain differences in global node strength between control subjects and SZ patients, we computed the mean, standard deviation, skewness, and kurtosis from the distribution of these values along time. All four cumulants showed statistically significant differences in the gamma frequency band (p-values < 0.05). In addition, beta-1 and beta-2 bands showed statistically significant differences in skewness and kurtosis (p-values < 0.05). These findings suggest that the dynamical organization of the functional network during the resting-state in SZ patients is altered, which can be observed in changes in the fluctuations of global connectivity patterns in fast frequency bands. These results provide valuable insights into understanding of the disruptions of brain functional networks in SZ patients.},
  keywords={Time-frequency analysis;Fluctuations;Standards organizations;Neural engineering;Organizations;Schizophrenia;Metrology;Kurtosis;Electroencephalography;Biological neural networks;Schizophrenia;resting-state activity;electroencephalogram;instantaneous connectivity;brain dynamics},
  doi={10.1109/MetroXRAINE62247.2024.10795910},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11161667,
  author={Yao, Haiyan and Guo, Qiang and Lu, Bin and Zhang, Xufeng and Miao, Yufeng and Jin, Lingzhu and Lou, Yujing and Yuan, Jiahao},
  booktitle={2025 IEEE International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)}, 
  title={Research on Gas Leakage Source Location Method on Assisted Population-Decision Disturbance Grey Wolf Optimizer}, 
  year={2025},
  volume={},
  number={},
  pages={61-68},
  abstract={For the Grey Wolf Optimizer, it has the disadvantages of easy premature convergence and low optimization accuracy for complex problems, this article proposes an assisted population and decision disturbance grey wolf optimizer(ApD_GWO)to improve the optimized performance by adding assisted population strategy and decision perturbation strategy in the Grey Wolf Optimizer(GWO) and thus realize the optimal search of the global solution. Through simulation experiments on nine benchmark functions, it is verified that the searchability and convergence speed of the ApD_GWO are improved. The algorithm was applied to the research of Gas leakage source location and experimental verification was carried out. The experimental results show the ApD_GWO can effectively improve the positioning accuracy compared with algorithms such as Particle Swarm Optimization(PSO).},
  keywords={Accuracy;Perturbation methods;Measurement uncertainty;Position measurement;Benchmark testing;Search problems;Linear programming;Particle swarm optimization;Optimization;Convergence;Leak source location;grey wolf optimizer;assisted population strategy;disturbance strategy},
  doi={10.1109/CSIS-IAC65538.2025.11161667},
  ISSN={},
  month={May},}@ARTICLE{9032343,
  author={Wei, Qinglai and Liao, Zehua and Song, Ruizhuo and Zhang, Pinjia and Wang, Zhuo and Xiao, Jun},
  journal={IEEE Transactions on Industrial Electronics}, 
  title={Self-Learning Optimal Control for Ice-Storage Air Conditioning Systems via Data-Based Adaptive Dynamic Programming}, 
  year={2021},
  volume={68},
  number={4},
  pages={3599-3608},
  abstract={In this article, the optimal control scheme for ice-storage air conditioning (IAC) system is solved via a data-based adaptive dynamic programming (ADP) method. It is the first time that ADP is employed to design a self-learning scheme, which obtains the optimal control policy of IAC system. First, based on the data of the temperature, irradiance, and cooling load in an actual project, a prediction model of cooling load is built by a three-layer neural network with the performance verification. Second, the operation of the IAC system is analyzed. Third, a data-based ADP method is designed to realize a self-learning optimal control for the IAC system. Then, numerical results show that using the data-based optimal control method can reduce the operation costs. Finally, the comparison results show that the developed ADP method improves the system efficiency, minimizing the overall cost. Thus, the superiority of the developed algorithm is verified.},
  keywords={Optimal control;Air conditioning;Load modeling;Neural networks;Dynamic programming;Predictive models;Adaptive dynamic programming (ADP);cooling load prediction;ice-storage air conditioning (IAC);neural network;optimal control},
  doi={10.1109/TIE.2020.2978699},
  ISSN={1557-9948},
  month={April},}@ARTICLE{11050425,
  author={Ramos, Roberto Carlos Bautista and Yoo, Sang Guun},
  journal={IEEE Access}, 
  title={Cybersecurity in DevOps Environments: A Systematic Literature Review}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={This systematic literature review provides a comprehensive analysis of the most critical cybersecurity challenges in DevOps environments. Through a rigorous examination of 62 peer-reviewed articles published between 2016 and 2025, we identified recurring threats, active attack vectors, structural vulnerabilities, mitigation strategies, and their technical impact on system performance and operational resilience. The analysis revealed that the most significant threats are related to uncontrolled automation, exposure of sensitive secrets in CI/CD pipelines, lack of mutual authentication between distributed services, supply chain attacks, and the use of unauthorized tools (Shadow IT). These threats simultaneously compromise core security principles, including integrity, confidentiality, and traceability. The most frequent attack vectors include code injection in CI/CD pipelines, unrestricted access to public repositories, remote execution via default configurations, and lateral movement in flat architectures. We identified 27 recurrent vulnerabilities throughout the DevOps lifecycle. The most critical include the absence of automated security testing, poor management of secrets, and reliance on unverified third-party components. More than 30 technical and organizational countermeasures were documented, such as SAST/DAST/IAST scans, infrastructure-as-code validation, secure credential storage via vaults, and integrated practices like DevSecOps and compliance-as-code. When properly implemented, these strategies do not degrade system performance and may even enhance resilience and stability. Nonetheless, a lack of comparative empirical validation in most reviewed studies limits the generalizability of proposed solutions. These findings establish a foundation for future research in emerging domains, such as the Internet of Things, where continuous, adaptive, and verifiable security is paramount for automated and dynamic environments.},
  keywords={DevOps;Security;Computer security;Protocols;Systematic literature review;Vectors;Prevention and mitigation;Pipelines;Libraries;Codes;DevOps;Cybersecurity;Threats;Vulnerabilities;Attack Vectors;Mitigation;Systematic Literature Review},
  doi={10.1109/ACCESS.2025.3582892},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9959335,
  author={Wen, Zhang and Tian, Jiachen and Wang, Feng and Zhuo, Fang and Shi, Shuhuai},
  booktitle={2022 IEEE International Power Electronics and Application Conference and Exposition (PEAC)}, 
  title={A transient performance improved strategy based on virtual inertia and its allocation for PV-storage DC Microgrid}, 
  year={2022},
  volume={},
  number={},
  pages={133-138},
  abstract={Owing to the wide-scale application of renewable energy generation, DC microgrid (DCMG) is regarded as an indispensable part in the future energy landscape. However, DCMG is featured with low inertia as it is highly penetrated with power electronic converters. In order to increase the system inertia and decrease the transient voltage drop of the system, this paper first proposes a virtual inertial control method, i.e., analogous virtual synchronous generator (AVSG) and analyze it from three aspects: initial dynamic response, stability and parameter sensitivity. Further, on the basis of the proposed VIC method, an inertia allocation control (IAC) method was presented to improve the transient characteristics of each energy storage unit (ESU) in the distributed energy storage system (DESS), the maximum output power of ESU and system’s requirement for the virtual inertia are two principles of IAC. Finally, the result of simulations verifies the effectiveness of the proposed control strategy.},
  keywords={Simulation;Microgrids;Power electronics;Synchronous generators;Stability analysis;Steady-state;Resource management;virtual inertia control;DC microgrid;distributed energy storage system;inertia allocation},
  doi={10.1109/PEAC56338.2022.9959335},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9962411,
  author={Wolfschwenger, Patrick and Sabitzer, Barbara and Lavicza, Zsolt},
  booktitle={2022 IEEE Frontiers in Education Conference (FIE)}, 
  title={Design and Evaluation of an Agile Framework for Continuous Education in Software Engineering}, 
  year={2022},
  volume={},
  number={},
  pages={1-9},
  abstract={This Research-To-Practice Full Paper presents an agile framework that was created and evaluated in the context of a continuous professional training and development program in the IT industry. It was designed with the values and principles of Agile Software Development in mind and provides a learning concept to become acquainted with DevOps and Cloud Computing practices. While DevOps promises to build, test and release software faster and more reliably through methods like continuous integration, continuous deployment/delivery, automated testing and infrastructure-as-code, the integration of Cloud Computing services empowers each step of the agile life cycle through ubiquitous access to computing resources that can be provisioned with minimal effort. The paper describes the experiences of creating and applying the didactic concept as well as observations of conducted work, learning progress, motivation and achievements.},
  keywords={Training;Industries;Cloud computing;Buildings;Agile software development;Companies;Software systems;Lifelong Learning;Continuing Professional Training and Development;Agile Software Development;Cloud Computing;DevOps;Project-Based Learning},
  doi={10.1109/FIE56618.2022.9962411},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10415972,
  author={Al-Shalah, Muhanned and Aziz, Salman and Ayasun, Saffet},
  booktitle={2023 14th International Conference on Electrical and Electronics Engineering (ELECO)}, 
  title={Delay-Dependent Stability Analysis of Single-Area Load Frequency Control System with Aggregated Inverter Air Conditioners}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Smart grids incorporate many inverter air conditioners (IACs) that can be used to regulate the frequency under disturbances. However, employing IACs in smart grids requires a communication network to send and receive control and measurement signals. Depending on the network type and load, such open communication networks will introduce time delays that adversely affect the system dynamics and even lead to instability if the delay exceeds an upper bound known as stability delay margin (SDM). This paper aims to identify SDMs of a single-area load frequency control (LFC) system-based IAC. An analytical method based on eliminating exponential terms in the closed loop characteristic equation is used to obtain accurate SDMs. The effect of proportional-integral (PI) controller gains and the number of IACs on SDMs are investigated. The theoretical values of SDMs are verified by using time simulations and quasi-polynomial mapping-based root finder (QPmR) algorithm.},
  keywords={PI control;Power system stability;Stability analysis;Mathematical models;Inverters;Delays;Smart grids},
  doi={10.1109/ELECO60389.2023.10415972},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11025789,
  author={Ksontini, Emna and Mastouri, Meriem and Khalsi, Rania and Kessentini, Wael},
  booktitle={2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR)}, 
  title={Refactoring for Dockerfile Quality: A Dive into Developer Practices and Automation Potential}, 
  year={2025},
  volume={},
  number={},
  pages={788-800},
  abstract={Docker, the industry standard for packaging and deploying applications, leverages Infrastructure as Code (IaC) principles to facilitate the creation of images through Dockerfiles. However, maintaining Dockerfiles presents significant challenges. Refactoring, in particular, is often a manual and complex process. This paper explores the utility and practicality of automating Dockerfile refactoring using 600 Dockerfiles from 358 opensource projects. Our study reveals that Dockerfile image size and build duration tend to increase as projects evolve, with developers often postponing refactoring efforts until later stages in the development cycle. This trend motivates the automation of refactoring. To achieve this, we leverage In Context Learning (ICL) along with a score-based demonstration selection strategy. Our approach leads to an average reduction of 32% in image size and a 6% decrease in build duration, with improvements in understandability and maintainability observed in 77% and 91% of cases, respectively. Additionally, our analysis shows that automated refactoring reduces Dockerfile image size by 2x compared to manual refactoring and 10x compared to smellfixing tools like PARFUM. This work establishes a foundation for automating Dockerfile refactoring, indicating that such automation could become a standard practice within CI/CD pipelines to enhance Dockerfile quality throughout every step of the software development lifecycle.},
  keywords={Automation;Pipelines;Manuals;Streaming media;Packaging;Software;Standards;Optimization;Software engineering;Software development management;Refactoring;In-Context Learning;Software Engineering;LLM;Docker Refactoring;IaC},
  doi={10.1109/MSR66628.2025.00116},
  ISSN={2574-3864},
  month={April},}@INPROCEEDINGS{4696896,
  author={Abbod, M.F. and Shieh, J. and Yeh, J. and Cheng, K. and Huang, S.J. and Han, Y.Y.},
  booktitle={2008 IEEE Biomedical Circuits and Systems Conference}, 
  title={Intelligent systems for the prediction of Brain Death Index}, 
  year={2008},
  volume={},
  number={},
  pages={149-152},
  abstract={New techniques to enable the prediction of a reliable brain death index (BDI) measures are needed to improve patient care in the intensive care unit (ICU). The utilization of robust indicators combined with improved methods of data analysis and modeling is likely to deliver this facility. Like many forms of indicators, a combination of different measurement types can always improve the assessment accuracy. Doctors can manage by a combination of local indicators and signal of heart rhythm to decide the BDI of neurosurgical and traumatized patients. New techniques for the prediction are needed as statistical analysis has a poor accuracy and is not applicable to the individual. artificial intelligence (AI) may provide these suitable methods. Artificial neural networks (ANN), the best-studied form of AI, has been used successfully, and can be used to model the patient BDI based on multi-input measurements from the patient. A multi-layer perception (MLP) and ensembled neural networks are chosen to be the network type of BDI model. This model can provide medical staffs a reference index to evaluate the status of IAC and brain death patients.},
  keywords={Intelligent systems;Artificial intelligence;Artificial neural networks;Robustness;Data analysis;Heart;Rhythm;Neurosurgery;Statistical analysis;Biological neural networks},
  doi={10.1109/BIOCAS.2008.4696896},
  ISSN={2163-4025},
  month={Nov},}@INPROCEEDINGS{7555870,
  author={Parise, Luigi and Parise, Giuseppe and Berenato, Ennio},
  booktitle={2016 IEEE 16th International Conference on Environment and Electrical Engineering (EEEIC)}, 
  title={Arc flash: Prevention measures in IEC/EN protection approach}, 
  year={2016},
  volume={},
  number={},
  pages={1-5},
  abstract={All the safety standards, also if implemented with different philosophies and perspectives, highlight a program to protect against electric shocks, arc flashes and blasts. The European EN 50110 standard emphasizes equipment integrity “giving collective protective measures priority over individual protective measures” that remain such as additional means (Directive 89/391/EEC - OSH). Focusing on the specific hazard of arc flash, many prevention measures are available in the IEC approach of protection program. The main measures, essentially passive, are: the IP code; safety procedures for dead working; MV isolator switches that allow grounding of the working zone without the need of a manual equipment; the tested effectiveness of the switchboard design in protecting persons in case of an internal arc (internal arc class IAC); forms of separation for low voltage switchgear; the standardized method to calculate the minimum value of short-circuits. All these measures assist the risk reduction of the arc flash in the IEC/EN safety approach.},
  keywords={Standards;Europe;Hazards;Arc discharges;Grounding;Electric shock;electrical safety;Personal Protective Equipment PPE;flash hazard analysis;electric live working},
  doi={10.1109/EEEIC.2016.7555870},
  ISSN={},
  month={June},}@INPROCEEDINGS{10564044,
  author={Suhas, M.V and Mariyappa, N. and H, Anitha and Sinha, Sanjib and M, Ravindranadh Chowdary and K, Raghavendra and Asranna, Ajay and Viswanathan, L.G},
  booktitle={2024 Tenth International Conference on Bio Signals, Images, and Instrumentation (ICBSII)}, 
  title={Dynamic Connectivity Patterns in Resting State and Task-Based MEG: An Instantaneous Amplitude Correlation Approach}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Understanding dynamic functional connectivity is pivotal in unraveling the intricate dynamics of neural activity. This research leverages Magnetoencephalography (MEG) and Instantaneous Amplitude Correlation (IAC) to explore the evolving patterns of dynamic functional connectivity in the human brain. The study meticulously compares IAC outcomes during resting state and task-based MEG, offering insights into the adaptability of brain connectivity. A comprehensive literature review contextualizes the study within existing research, highlighting the relevance of dynamic functional connectivity analysis. The MEG data preprocessing employs advanced techniques, including artifact reduction and source estimation. The IAC analysis, featuring tensor factorization and k-means clustering, reveals distinctive connectivity patterns in various frequency bands. Results demonstrate pronounced transitions between connectivity states, particularly in the beta frequency bands during resting state MEG. This comparative analysis enriches our understanding of neural dynamics and connectivity fluctuations, paving the way for potential clinical applications. The study underscores the need for broader validation through expanded datasets, emphasizing the implications for cognitive neuroscience and clinical practices.},
  keywords={Correlation;Tensors;Cognitive neuroscience;Magnetic resonance imaging;Instruments;Neural networks;Neural activity;magnetoencephalography;dynamic functional connectivity;instantaneous amplitude correlation;resting state;task-based;brain frequency bands},
  doi={10.1109/ICBSII61384.2024.10564044},
  ISSN={2768-6450},
  month={March},}@ARTICLE{10746353,
  author={Huang, Yipo and Li, Leida and Chen, Pengfei and Wu, Haoning and Lin, Weisi and Shi, Guangming},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Multi-Modality Multi-Attribute Contrastive Pre-Training for Image Aesthetics Computing}, 
  year={2025},
  volume={47},
  number={2},
  pages={1205-1218},
  abstract={In the Image Aesthetics Computing (IAC) field, most prior methods leveraged the off-the-shelf backbones pre-trained on the large-scale ImageNet database. While these pre-trained backbones have achieved notable success, they often overemphasize object-level semantics and fail to capture the high-level concepts of image aesthetics, which may only achieve suboptimal performances. To tackle this long-neglected problem, we propose a multi-modality multi-attribute contrastive pre-training framework, targeting at constructing an alternative to ImageNet-based pre-training for IAC. Specifically, the proposed framework consists of two main aspects. 1) We build a multi-attribute image description database with human feedback, leveraging the competent image understanding capability of the multi-modality large language model to generate rich aesthetic descriptions. 2) To better adapt models to aesthetic computing tasks, we integrate the image-based visual features with the attribute-based text features, and map the integrated features into different embedding spaces, based on which the multi-attribute contrastive learning is proposed for obtaining more comprehensive aesthetic representation. To alleviate the distribution shift encountered when transitioning from the general visual domain to the aesthetic domain, we further propose a semantic affinity loss to restrain the content information and enhance model generalization. Extensive experiments demonstrate that the proposed framework sets new state-of-the-arts for IAC tasks.},
  keywords={Computational modeling;Databases;Image color analysis;Lighting;Contrastive learning;Visualization;Semantics;Reviews;Predictive models;Layout;Image aesthetics computing;contrastive pre-training;multi-attribute description;aesthetic representation},
  doi={10.1109/TPAMI.2024.3492259},
  ISSN={1939-3539},
  month={Feb},}@ARTICLE{1104962,
  author={Bossi, J. and Price, G. and Winkleblack, S.},
  journal={IEEE Control Systems Magazine}, 
  title={Control design for flexible spacecraft using the integrated analysis capability}, 
  year={1985},
  volume={5},
  number={4},
  pages={9-15},
  abstract={Dynamic analysis and controls design for flexible spacecraft involves high-order dynamic systems with multiple inputs and outputs. Computer tools are essential for such analysis. This paper describes the controls/structures interaction analysis capability of an interdisciplinary computer software system, called the Integrated Analysis Capability (IAC), that is being developed by Boeing Aerospace Company for NASA/Goddard Space Flight Center. An overview of IAC components and procedures is presented, and an example of a preliminary space station controls design is shown.},
  keywords={Control design;Space vehicles;Aerospace control;NASA;Aerodynamics;Control systems;Software systems;Space stations;Packaging;Aerospace engineering},
  doi={10.1109/MCS.1985.1104962},
  ISSN={2374-9385},
  month={November},}@ARTICLE{9119828,
  author={Wang, Ding and Ha, Mingming and Qiao, Junfei},
  journal={IEEE Transactions on Industrial Electronics}, 
  title={Data-Driven Iterative Adaptive Critic Control Toward an Urban Wastewater Treatment Plant}, 
  year={2021},
  volume={68},
  number={8},
  pages={7362-7369},
  abstract={The wastewater treatment is an important avenue of resources cyclic utilization when coping with the modern urban diseases. However, there always exist obvious nonlinearities and uncertainties within wastewater treatment systems, such that it is difficult to accomplish proper optimization objectives toward these complex unknown platforms. In this article, a data-driven iterative adaptive critic (IAC) strategy is developed to address the nonlinear optimal control problem. The iterative algorithm is constructed with a general framework, followed by convergence analysis and neural network implementation. Remarkably, the derived IAC control policy with an additional steady control input is also applied to a typical wastewater treatment plant, rendering that the dissolved oxygen concentration and the nitrate level are maintained at desired setting points. When compared with the incremental proportional-integral-derivative method, it is found that faster response and less oscillation can be obtained during the IAC control process.},
  keywords={Wastewater treatment;Optimal control;Cost function;Iterative methods;Adaptive systems;Wastewater;Recycling;Data-driven control;iterative adaptive critic (IAC);learning systems;optimal regulation;wastewater treatment},
  doi={10.1109/TIE.2020.3001840},
  ISSN={1557-9948},
  month={Aug},}@INPROCEEDINGS{11160833,
  author={Wan, Jiayu and Zhou, Yixuan and Niu, Yubao and Wu, Chengze and Yu, Fan and Lin, Qiao},
  booktitle={2025 IEEE International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)}, 
  title={Swarm Intelligence-Based Auxiliary Diagnosis System}, 
  year={2025},
  volume={},
  number={},
  pages={95-101},
  abstract={Urban areas often benefit from modern hospitals, advanced medical equipment, and highly trained healthcare professionals, while rural areas usually suffer from a shortage of experienced medical experts and antiquated facilities. This discrepancy leads to lower-quality treatments, higher misdiagnosis rates, and delayed diagnoses in rural areas. To address this issue, this paper proposes a novel swarm intelligence-based auxiliary medical system to mitigate the imbalance in medical resources and improve the accuracy of lung disease diagnosis. Quantitative and qualitative analyses are conducted in this study. Data is gathered through questionnaires given to patients and healthcare providers. The proposed system integrates AI-driven diagnostics with the expertise of real doctors to enhance treatment outcomes. It is structured into four main layers: the front-end layer, back-end layer, database layer, and AI integration layer, each serving distinct functions to achieve the system's objectives. By addressing resource disparities and improving diagnostic accuracy, this innovative medical system offers a comprehensive solution to contemporary healthcare challenges, particularly in underserved regions.},
  keywords={Accuracy;Hospitals;Databases;Urban areas;Medical services;Transforms;Artificial intelligence;Particle swarm optimization;Usability;Medical diagnostic imaging;Healthcare;diagnosis system;swarm intelligence;artificial intelligence},
  doi={10.1109/CSIS-IAC65538.2025.11160833},
  ISSN={},
  month={May},}@ARTICLE{10756789,
  author={Chanyoung Chung, Calvin and Finazzi, Andrea and Seong, Hyunki and Lee, Daegyu and Lee, Seungwook and Kim, Bosung and Gang, Gyuri and Hyunchul Shim, David},
  journal={IEEE Transactions on Field Robotics}, 
  title={Autonomous System for Head-to-Head Race: Design, Implementation, and Analysis; Team KAIST at the Indy Autonomous Challenge}, 
  year={2025},
  volume={2},
  number={},
  pages={574-600},
  abstract={Autonomous racing has emerged as a promising field of research, attracting growing interest. In racing, vehicles operate at the limits of perception, planning, and control, raising unique research and engineering challenges. This article presents an overview ofthe autonomous racing system developed by team KAIST for the Indy Autonomous Challenge (IAC), as shownin Fig. 1. The KAIST racing stack features multimodal perception modules, a high-speed overtaking planner, a resilient control system, and a system monitoring framework. We provide detailed insights into each component, including the algorithms, implementation, and evaluation results. Furthermore, the article presents design principles shaped by three years of high-speed autonomous racing experience, offering insights applicable to other safety-critical, high-risk robotics domains. Our autonomous system was integrated into a full-scale race car (Dallara AV-21) and extensively field-tested. As a result, team KAIST was one of only three teams to qualify for and compete in the official IAC races without incident. Our system successfully fulfilled all race objectives, including overtaking at speeds of up to 220 km/h in the IAC@CES2022, the world’s first autonomous head-to-head race.},
  keywords={Autonomous vehicles;Trajectory;Safety;Planning;Vehicle dynamics;Testing;Optimization;Autonomous systems;Autonomous robots;Real-time systems;Resilience;Sports;Collision avoidance;Vehicle safety;Autonomous racing;autonomous systems;field-harden;real-time computation;resilience system},
  doi={10.1109/TFR.2024.3497922},
  ISSN={2997-1101},
  month={},}@INPROCEEDINGS{10919273,
  author={Wang, Yongjin and Chen, Pengkai and Wu, Yifan and Geng, Shuang and Niu, Ben},
  booktitle={2024 International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)}, 
  title={Hybrid Algorithm Based on Comprehensive Learning Particle Swarm Optimisation with Local Search and Firefly Algorithm for UAV Path Planning}, 
  year={2024},
  volume={},
  number={},
  pages={75-81},
  abstract={Unmanned Aerial Vehicles (UAVs) have been widely used in military and civilian fields because of their low operating cost, no risk of human casualties, and convenient use. Path planning is the key technology for UAV flights to complete tasks efficiently, stably, safely, and autonomously. This paper proposes a new hybrid algorithm (HFCLPSOLS) based on Comprehensive Learning Particle Swarm Optimisation with Local Search (CLPSOLS) and Firefly Algorithm (FA) for UAV path planning. The new algorithm establishes a temporary position set and incorporates the position attraction rule of FA into CLPSOLS to improve accuracy and convergence speed. In addition, we also introduce the concept of stability cost for UAVs, aiming to improve the flying quality. The performance of the proposed HFCLPSOLS is compared with other variants of PSO in four different environments. The experimental results show that HFCLPSOLS combines the strength of CLPSOLS and FA, improving the searching accuracy and speed in various situations.},
  keywords={Costs;Accuracy;Heuristic algorithms;Autonomous aerial vehicles;Path planning;Stability analysis;Particle swarm optimization;Optimization;Thermal stability;Convergence;unmanned aerial vehicles;hybrid algorithm;comprehensive learning particle swarm optimisation with local search;firefly algorithm;path planning},
  doi={10.1109/CSIS-IAC63491.2024.10919273},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10919366,
  author={Ran, Hao and Cheng, Shi and Sun, Yifei and Shan, Yuyuan and Jin, Honglin and Lu, Hui},
  booktitle={2024 International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)}, 
  title={Agile Earth Observation Satellite Mission Planning Based on an Improved Brain Storm Optimization in Objective Space Algorithm}, 
  year={2024},
  volume={},
  number={},
  pages={542-549},
  abstract={Traditional intelligent algorithms lack efficient utilization of knowledge of the agile earth observation satellite (AEOS) problem and the knowledge generated during the search process. To use the relevant knowledge and improve the algorithm-solving efficiency, this paper proposes an improved brain storm optimization in objective space (IBSOOS) algorithm based on knowledge strategy: 1) We use crossover and mutation strategies in the genetic algorithm (GA) to replace the original new solution generation strategy. This approach effectively handles non-continuous problems. 2) We introduce the worst solution updating strategy to enhance the algorithm's stability. During each iteration, this strategy adjusts the worst solution to learn from the target optimal solution. 3) We design a method for generating initial solutions, utilizing prior knowledge of the problem to pinpoint the range of candidate solutions swiftly. The experimental study compared the proposed algorithm with three other algorithms across four datasets. The results show that it significantly outperforms the others in solving AEOS mission planning problems.},
  keywords={Earth;Satellites;Heuristic algorithms;Space missions;Search problems;Stability analysis;Planning;Particle swarm optimization;Optimization;Genetic algorithms;Brain storm optimization in objective space;swarm intelligence;agile earth observation satellite mission planning;knowledge acquisition and utilization},
  doi={10.1109/CSIS-IAC63491.2024.10919366},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{1206523,
  author={Pressley, T.},
  booktitle={Proceedings. Eleventh International Conference on Computer Communications and Networks}, 
  title={A new paradigm for intrusion detection systems}, 
  year={2002},
  volume={},
  number={},
  pages={390-},
  abstract={Summary form only given. The US Army Research Laboratory through its Information Assurance Center (IAC) seeks to evolve and continuously develop an IA capability that sets the Army and DoD standard for protecting computing and communications infrastructure from unauthorized access, illicit exploitation, component damage, and denial of service to authorized users. The IAC has two components, an operational computer emergency response team that monitors a major Department of Defense research network on a 27 /spl times/ 7 basis, and a research component. Unlike many similar activities, the ARL computer emergency response team employs multiple network intrusion detection system tools to accomplish its mission, and serves as a testbed for IDS tools transitioning from universities and industry into the government and commercial sectors. The IAC's in-house research component is focused on architecture improvements to promote data fusion across sensors and time. Issues which the new architecture address include timeliness, archiving issues, and the incorporation of both signature and anomaly IDS tools into the architecture and the fusion of the information resulting from these different approaches. The IAC has a number of collaborations with industry and academia to promote IDS tools/methodologies focused on network surveillance, intrusion detection systems focused on advanced networking (OC12 and above), and the "insider threat".},
  keywords={Intrusion detection;Military computing;Computer networks;Communication standards;Standards development;Protection;Computer crime;Computer displays;System testing;Educational institutions},
  doi={10.1109/ICCCN.2002.1206523},
  ISSN={1095-2055},
  month={Oct},}@ARTICLE{7063918,
  author={Kuramoto, Naoki and Azuma, Yasushi and Inaba, Hajime and Hong, Feng-Lei and Fujii, Kenichi},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Improvements to the Volume Measurement of 28Si Spheres to Determine the Avogadro Constant}, 
  year={2015},
  volume={64},
  number={6},
  pages={1650-1656},
  abstract={In the determination of the Avogadro constant using the X-ray crystal density method with a 28Si-enriched crystal prepared by the International Avogadro Coordination (IAC) project, the volume measurement and surface analysis of 28Si spheres play a crucial role. For accurate volume determination, an optical interferometer has been improved taking account of the geometrical shape of the optical components. Furthermore, a new spectroscopic ellipsometer with a sphere rotation system has been developed for accurate surface analysis. The optical interferometer and the ellipsometer have been used for the volume determination and surface analysis of the 28Si spheres repolished by the IAC, respectively. On the basis of the preliminary uncertainty estimation, the relative standard uncertainty of the apparent volume measurement has been reduced from 4.4 $\times 10^{-8}$ to 2.7 $\times 10^{-8}$ by the improvement of the interferometer. The number of ellipsometric measurement points on the sphere surface has been increased from 20 to 7782 by the installation of the new ellipsometer, yielding more reliable information on the sphere surface. Details of the improvements and the preliminary results of the measurements of the 28Si spheres are given.},
  keywords={Uncertainty;Optical interferometry;Volume measurement;Measurement by laser beam;Standards;Optical variables measurement;Silicon;Avogadro constant;diameter measurement;optical interferometer;silicon crystal;spectroscopic ellipsometer;volume measurement.;Avogadro constant;diameter measurement;optical interferometer;silicon crystal;spectroscopic ellipsometer;volume measurement},
  doi={10.1109/TIM.2015.2401212},
  ISSN={1557-9662},
  month={June},}@INPROCEEDINGS{9172769,
  author={Krause, Stefan and Cain, Sebastian},
  booktitle={2020 IEEE Aerospace Conference}, 
  title={UAV Pre-Study for In-Air-Capturing Maneuver}, 
  year={2020},
  volume={},
  number={},
  pages={1-14},
  abstract={Implementation of reusable launch vehicle (RLV) missions is a major goal in current aerospace research. One conceptual idea to return a booster stage is the so-called “in-air capturing” (IAC), where a winged stage is captured by an aerial vehicle and towed back to the final destination. This approach has the advantage that a towed winged stage does not need a propulsion system or fuel reserves to arrive to a destination point, compared to alternative approaches as demonstrated by SpaceX. The concept of capturing the RLV in air is based on earlier IAC missions for satellite photo capsules and the probe-and-drogue refueling method. A key difference is that in an air-to-air-refueling procedure a highly dynamic fighter tries to connect to a trailing drogue or rigid boom from a sluggish tanker. Opposite to this procedure, it can be assumed that in IAC case two aerodynamically sluggish aircraft need to be coupled. The challenge is to build up a formation which enables a connection between a gliding RLV and a dynamic coupling device trailing from a large aircraft. To investigate this IAC approach, the German Aerospace Center (DLR) built a scaled demonstration system with smaller unmanned aerial vehicles (UAV) to research different aspects of IAC flight tests. Based on the assumption that at an IAC approach would involve two large aerodynamically sluggish systems, a third highly dynamic vehicle should be introduced to enable a safe and reliable connection. Therefore, the trailing system, which is known from the air-to-air refueling, was modified by DLR with aerodynamic control surfaces and an independent flight control system. This enables a dynamic and independent motion of the coupling device relative to the towing aircraft, as well as the RLV. This paper gives an overview about IAC investigations of DLR, which are validated in experimental flight test demonstrations with scaled unmanned systems. The focus of this work is on building up the formation, from the rough approach with GNSS up to the final approach, where the global, absolute localization is supported by an image based relative position estimation of the coupling device. A major aspect in the formation implementation is the active coupling device (ACD). Therefore, the paper will show the construction of the ACD, its functionality and operation during the formation flight and a validation of its behavior at the flight demonstration. The first flight test results show that our research is heading in the right direction and further tests are expected to provide comprehensive results for the validation of the IAC concept.},
  keywords={Couplings;Location awareness;Satellites;Propulsion;Aerodynamics;Autonomous aerial vehicles;Aircraft manufacture},
  doi={10.1109/AERO47225.2020.9172769},
  ISSN={1095-323X},
  month={March},}@ARTICLE{9383219,
  author={Eke, Christopher Ifeanyi and Norman, Azah Anir and Shuib, Liyana},
  journal={IEEE Access}, 
  title={Context-Based Feature Technique for Sarcasm Identification in Benchmark Datasets Using Deep Learning and BERT Model}, 
  year={2021},
  volume={9},
  number={},
  pages={48501-48518},
  abstract={Sarcasm is a complicated linguistic term commonly found in e-commerce and social media sites. Failure to identify sarcastic utterances in Natural Language Processing applications such as sentiment analysis and opinion mining will confuse classification algorithms and generate false results. Several studies on sarcasm detection have utilised different learning algorithms. However, most of these learning models have always focused on the contents of expression only, leaving the contextual information in isolation. As a result, they failed to capture the contextual information in the sarcastic expression. Secondly, many deep learning methods in NLP uses a word embedding learning algorithm as a standard approach for feature vector representation, which ignores the sentiment polarity of the words in the sarcastic expression. This study proposes a context-based feature technique for sarcasm Identification using the deep learning model, BERT model, and conventional machine learning to address the issues mentioned above. Two Twitter and Internet Argument Corpus, version two (IAC-v2) benchmark datasets were utilised for the classification using the three learning models. The first model uses embedding-based representation via deep learning model with bidirectional long short term memory (Bi-LSTM), a variant of Recurrent Neural Network (RNN), by applying Global Vector representation (GloVe) for the construction of word embedding and context learning. The second model is based on Transformer using a pre-trained Bidirectional Encoder representation and Transformer (BERT). In contrast, the third model is based on feature fusion that comprised BERT feature, sentiment related, syntactic, and GloVe embedding feature with conventional machine learning. The effectiveness of this technique is tested with various evaluation experiments. However, the technique's evaluation on two Twitter benchmark datasets attained 98.5% and 98.0% highest precision, respectively. The IAC-v2 dataset, on the other hand, achieved the highest precision of 81.2%, which shows the significance of the proposed technique over the baseline approaches for sarcasm analysis.},
  keywords={Feature extraction;Sentiment analysis;Deep learning;Context modeling;Semantics;Bit error rate;Social networking (online);Natural language processing;sarcasm identification;Bi-LSTM;GloVe embedding;BERT},
  doi={10.1109/ACCESS.2021.3068323},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11105683,
  author={Mevada, Chirag and Kattainen, Aapo and Parihar, Vijay Singh and Tewari, Amit and Keskinen, Jari and Mäntysalo, Matti},
  booktitle={2025 IEEE International Conference on Flexible and Printable Sensors and Systems (FLEPS)}, 
  title={Indigo-Functionalized Activated Carbon Electrode for Screen-Printed Eco-Friendly Supercapacitors}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={Employing indigo to functionalize commercial activated carbon (CAC) for screen-printed electrodes represents an innovative approach to enhance the electrochemical characteristics of CAC, making it suitable for applications in supercapacitors (SCs). The indigofunctionalized activated carbon (IAC) electrode material was successfully synthesized through a solvothermal method. Various material characterization techniques, such as X-ray diffraction, thermogravimetric analysis, BET surface area analysis and Raman spectroscopy confirmed the successful functionalization of indigo onto the CAC. Screen-printed SCs fabricated with aqueous electrolyte exhibit a specific capacitance of $32.7 \mathrm{F} \mathrm{g}^{-1}$ at a current density of $0.5 \mathrm{A} \mathrm{g}^{-1}$ which is higher than the CAC ($10.8 \mathrm{F} \mathrm{g}^{-1}$). This work presents a promising pathway for developing printed, sustainable, and non-toxic SCs for low power wireless sensors and IoT devices.},
  keywords={Electrodes;Wireless communication;Wireless sensor networks;Raman scattering;Supercapacitors;Capacitance;Sensor systems;Sensors;Internet of Things;Carbon;supercapacitor;screen printing;printed electronics;activated carbon;indigo;eco-friendly},
  doi={10.1109/FLEPS65444.2025.11105683},
  ISSN={2832-8256},
  month={June},}@INPROCEEDINGS{10254980,
  author={Amiri, Amirali and Zdun, Uwe},
  booktitle={2023 IEEE 16th International Conference on Cloud Computing (CLOUD)}, 
  title={Cost-Aware Multifaceted Reconfiguration of Service-and Cloud-Based Dynamic Routing Applications}, 
  year={2023},
  volume={},
  number={},
  pages={428-438},
  abstract={Dynamic reconfiguration is commonly used in service-and cloud-based applications. In combination with autoscalers, dynamic routers can adapt the system to the resource demands, e.g., in an e-commerce application offering discounts for services in a specific location. Without such measures, the quality-of-service measures are affected negatively, and a system overload can lead to an application being non-responsive. However, the cost of cloud resource usage must be considered when performing these reconfiguration steps to avoid adding high additional costs. This paper proposes a cost-aware multifaceted reconfiguration of dynamic routing applications. We study the depletion and rescheduling of idle components and use an infrastructure-as-code module to apply changes to the infrastructure. Moreover, when system components are in a steady state, our approach dynamically self-adapts between more central or distributed routing to optimize reliability and performance. This adaptation is calculated based on a system-wide optimization analysis. When components are overloaded, we perform a per-component optimization to autoscale components multidimensionally. Our extensive systematic evaluation shows significant improvements in quality trade-off adaptations and system overload prevention. We provide prototypical tool support to demonstrate our concepts with illustrative sample cases.},
  keywords={Cloud computing;Systematics;Costs;Computer architecture;Quality of service;Performance gain;Routing;Self-Adaptive Systems;Dynamic Routing;Reliability and Performance Trade-Offs;Prototypical Tool Support;System Overload;Cost-Awareness;Multidimensional Autoscaling},
  doi={10.1109/CLOUD60044.2023.00058},
  ISSN={2159-6190},
  month={July},}@ARTICLE{10505793,
  author={Yang, Jingkai and Ran, Qiwen and Ma, Jing},
  journal={IEEE Photonics Journal}, 
  title={Queuing Delay Analysis for Wavelength Routing Optical Satellite Networks Over Dual-Layer Constellation}, 
  year={2024},
  volume={16},
  number={3},
  pages={1-8},
  abstract={Optical satellite networks (OSN) utilizing wavelength division multiplexing (WDM) inter-satellite links (ISLs) and wavelength routing is becoming a new trend in constructing high-speed, large-capacity, and low-latency global network systems. Since the number of wavelength channels for the WDM ISLs is limited, the traffic requests might incur queuing delays due to the wavelength channel congestion. To evaluate the delay-tolerance characterization of dual-layer wavelength routing OSN (DWROSN), the ISLs arrival coefficient (IAC) is proposed to construct the queuing model. Simulation results are compared with theoretical results in terms of queuing length and queuing delays. The results show that the traffic intensity, number of wavelength channels, and node degree of the satellite have an impact on the queuing characterization of the DWROSN. The queuing model with the IAC can efficiently evaluate the queuing characterization of the DWROSN.},
  keywords={Topology;Satellites;Delays;Orbits;Satellite broadcasting;Wavelength routing;Queueing analysis;Free-space optical (FSO) communication;optical satellite networks (OSN);wavelength routing;queuing delay},
  doi={10.1109/JPHOT.2024.3391233},
  ISSN={1943-0655},
  month={June},}@INPROCEEDINGS{5936961,
  author={Hazel, Terence and Freeman, Peter},
  booktitle={Petroleum and Chemical Industry Conference Europe Electrical and Instrumentation Applications}, 
  title={IEC switchgear & controlgear - internal arc withstand a designer's and user's view}, 
  year={2011},
  volume={},
  number={},
  pages={1-12},
  abstract={The testing of both high-voltage (HV) switchgear and controlgear and low-voltage (LV) assemblies under conditions of arcing due to an internal fault has been included in IEC documents for many years. The publication in 2003 of IEC 62271-200 “AC metal-enclosed switchgear and controlgear for rated voltages above 1000V and up to and including 52kV” introduced the designation of Internal Arc Classified (IAC) equipment and specifies a type test for conditions of internal arcing. This type test has greatly facilitated the use of HV IAC classified switchgear and controlgear thus providing safer working conditions. IEC 62271-200 makes no distinction between HV equipment used primarily for the distribution of electrical energy (switchgear) and the supply of power to loads (controlgear). For this reason the expression “HV switchgear and controlgear” is used throughout IEC standards and also in this paper. For LV the term “assemblies” is used and includes all switchgear and controlgear circuits.IEC/TR 61641 "Enclosed low-voltage switchgear and controlgear assemblies guide for testing under conditions of arcing due to internal fault" Edition 2.0 was published in 2008 and introduced the designation of arc-proof assemblies. This Technical Report provides guidance for testing LV assemblies. Although the document is still a Technical Report and not an international standard, it contributes to enhancing safety. The specifying of IAC classified switchgear and controlgear and arc-proof LV assemblies must be considered as just one of the steps in providing safe working conditions in electrical installations. Many other issues must be considered as well. IEC has published ISO/IEC Guide 51 which deals with risk analysis. This document provides very useful guidelines to help engineers define the solution which best meets the requirements. As with any feature associated with any type of equipment or installation, it is essential to know the conditions under which the feature is considered to be implemented, and when it is not. Probably the most dangerous situations occur when people think that there is no risk associated with a particular activity. Reduction of risk requires a good understanding of what that risk is.},
  keywords={Switchgear;IEC standards;Assembly;Fault currents;Circuit faults;Switches;internal arc withstand;IEC standards;Safety},
  doi={},
  ISSN={2151-7665},
  month={June},}@INPROCEEDINGS{6581583,
  author={Picard, Hans and Verstraten, Jan and Luchtenberg, Rien},
  booktitle={PCIC Europe 2013}, 
  title={Practical approaches to mitigating arc flash exposure in Europe}, 
  year={2013},
  volume={},
  number={},
  pages={1-10},
  abstract={Increasing number of electrical system operators in Europe realize that the existing standards for built-in equipment safety are not enough to prevent arc flash hazards. The newest revisions of local standards for operating an electrical installation, such as the Dutch NEN 3140, (based on EN 50110) are starting to provide guidance to reduce arc flash hazards. Not all equipment in the field meets the latest standards, moreover Internal Arc Classification (IAC) does not consider risks associated with normal maintenance practices such as trouble shooting, testing and verification of de-energized state of the electrical equipment. Arc Flash Hazard calculations can conveniently quantify the potential risk and show that excessive high arc flash incident energy necessitates de-energizing of the equipment before maintenance can be performed. Yet, this is not always acceptable to plant operations. This paper will address various approaches to significantly lowering the probability of an arc flash incident and ways to limit the consequences by system design, equipment modifications and alternate protection settings and work methods. It will also discuss strategies to deal with personal protection equipment (PPE).},
  keywords={Arc discharges;Hazards;Fault currents;Standards;Circuit faults;Europe;Arc Flash Hazard Analysis;Incident energy;Flash Protection;Boundary;IEEE 1584;Personal Protective Equipment (PPE)},
  doi={},
  ISSN={2151-7665},
  month={May},}@INPROCEEDINGS{10363901,
  author={Xu, Zijun and Li, Yuxiang and Ye, Shuyuan and Liang, Jiayang and Long, Zhili},
  booktitle={2023 International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)}, 
  title={Classification for Ultrasound Welding Joints Based on PCA and Improved Adaptive PSO-SVM}, 
  year={2023},
  volume={},
  number={},
  pages={43-48},
  abstract={Ultrasonic welding is widely employed in joining metal material, where the quality of the welding joints directly affects the strength and durability of the components. We propose a visual classification method for classifying welding joints, enabling feedback control of ultrasonic welding parameters to improve joints quality. The Principal Component Analysis (PCA) is utilized to extract features from welding joints, followed by experimental testing to determine the optimal feature length for the classifier. Additionally, an adaptive particle swarm optimization (PSO) with a decay factor is used to optimize the support vector machine (SVM) for welding joints classification. Experimental results demonstrate that the Gaussian radial basis kernel function (RBF) reaches 86% accuracy on the training set and 85% accuracy on the test set, which achieves better classification performance compared to linear kernel function and Multi-Kernel Learning Method (MKL). Compared to the original SVM, our proposed method achieves superior classification accuracy and reduces computational time.},
  keywords={Support vector machines;Training;Visualization;Ultrasonic imaging;Welding;Feature extraction;Acoustics;Ultrasonic welding;visual classification;PCA;improved PSO-SVM},
  doi={10.1109/CSIS-IAC60628.2023.10363901},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{6702289,
  author={Cernigliaro, Alice and Valloreia, Stefano and Fantino, Gianluca and Galleani, Lorenzo and Tavella, Patrizia},
  booktitle={2013 Joint European Frequency and Time Forum & International Frequency Control Symposium (EFTF/IFC)}, 
  title={Analysis on GNSS space clocks performances}, 
  year={2013},
  volume={},
  number={},
  pages={835-837},
  abstract={In Global Navigation Satellite Systems (GNSS) the role of atomic clocks is essential for the determination of the user position. Nowadays, several satellite navigation systems are operating and different clock technologies have been employed on board satellites, taking benefit of the improvements reached during the last tens of years. The analysis of GNSS clock performance is thus crucial for ensuring the GNSS positioning and timing capabilities. We performed an analysis on the clock estimates generated by the Information-Analytical Centre [1] (IAC) of the Russian Federal Space Agency, which provides a service similar to the one of the International GNSS Service (IGS). Therefore, we collected and processed the RINEX for clock files containing satellite clock estimates for GPS and GLONASS constellations, from 2008 to 2013: with our statistical tools [2] we performed an analysis of the performances of the different space clock technologies employed on board different GNSSs. In particular, we focused the attention on the frequency behaviour and the frequency stability, evaluating also the stationarity of these characteristics, with the aim of classifying and analysing the clock anomalies. In this paper, the attention is mostly focused on the change in clock noise variance.},
  keywords={Global Positioning System;Satellites;Noise;Atomic clocks;Satellite broadcasting;Space vehicles;GNSS timing;atomic clocks;clock anomalies;change in noise variance},
  doi={10.1109/EFTF-IFC.2013.6702289},
  ISSN={},
  month={July},}@INPROCEEDINGS{10319498,
  author={Eltawil, Amr B. and Atef, Sara and Attia, Sabry and Kuwamori, Kohei and Megaed, Tamer},
  booktitle={2023 3rd International Conference on Electronic Engineering (ICEEM)}, 
  title={Energy Efficiency Comparative Analysis of Inverter-based and Traditional Air Conditioning Systems in Residential Buildings: A Case Study in Egypt}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={In residential buildings, accurate information about the end-user’s electricity consumption is essential regarding its important effect on the load curve in the utility grid. Air conditioning systems is one of the most important loads affecting the power grid which account for more than 40% of power consumption in modern cities. In contrast to Traditional Air Conditioners (TACs) that rely on a rapidly phasing-out technology, the Inverter-based Air Conditioners (IACs) provide more advanced regulation potential. However, the initial cost of the IAC remains an obstacle to the end consumer to buy not appreciating the long-term cost efficiency compared to cheaper TACs. Therefore, in this paper a detailed comparative analysis between the two systems in actual setting is presented. Field measurements were conducted over 12 months in two typical dwellings in Alexandria, Egypt, where each of them has a single IAC and TAC installed. Various systematic experiments have been executed simultaneously to obtain a reliable comparative study. The results significantly verify the superior performance of the IACs on saving the total consumed energy and the corresponding costs. The study also suggests a break-even point between the two systems.},
  keywords={Air conditioning;Costs;Power demand;Systematics;Buildings;Urban areas;Inverters;Electricity consumption;inverter-based air conditioners;power grid;residential buildings},
  doi={10.1109/ICEEM58740.2023.10319498},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9820166,
  author={Marques, Denis de Gois and Dallegrave, Tamara Larissa D. de A. and Barbosa, Luis E. Lima and Rodrigues, Cleyton M. de Oliveira and Santos, Wylliams Barbosa},
  booktitle={2022 17th Iberian Conference on Information Systems and Technologies (CISTI)}, 
  title={Industry-Academy Collaboration in Agile Methodology: a Systematic Literature Review}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Industry-Academy Collaborative Research (IAC) in Software Engineering is being applied and developed widely in practice. These collaborative, research practices help both academic and software industry environments. As a way of observing what is being developed in SE, the objective of this article is to present an exploratory and empirical study of IAC practices in the context of Agile Software Development (ASD), exploring and characterizing solutions and practices, the challenges encountered in the application of the IAC and in collaboration. A Systematic Literature Review (SLR) was carried out in the five main academic databases, and snowballing was applied, evaluating/analyzing 8.460 articles, totaling 21 articles approved following the proposed criteria. As a result of the data analysis, 76 good practices and 37 challenges in carrying out the IAC were described. As well, practical collaborative models for the application of the IAC were detailed.},
  keywords={Industries;Systematics;Bibliographies;Collaboration;Search engines;Ontologies;Software;Industry-Academia Collaboration;Agile Software Development;Systematic Literature Review;Software Engineering},
  doi={10.23919/CISTI54924.2022.9820166},
  ISSN={2166-0727},
  month={June},}@ARTICLE{10167689,
  author={Tan, Xuegang and He, Wangli and Cao, Jinde and Huang, Tingwen},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Stabilization and Synchronization of Neural Networks via Impulsive Adaptive Control}, 
  year={2024},
  volume={35},
  number={11},
  pages={15517-15527},
  abstract={This article addresses the stabilization and synchronization problems of coupled neural networks (NNs) via an impulsive adaptive control (IAC) strategy. Unlike the traditional fixed-gain-based impulsive methods, a novel discrete-time-based adaptive updating law for the impulsive gain is designed to maintain the stabilization and synchronization performance of the coupled NNs, where the adaptive generator only intermittently updates its data at the impulsive instants. Several stabilization and synchronization criteria for the coupled NNs are established based on the impulsive adaptive feedback protocols. Additionally, the corresponding convergence analysis are also provided. Finally, the effectiveness of the obtained theoretical results is illustrated using two comparison simulation examples.},
  keywords={Artificial neural networks;Synchronization;Adaptive control;Main-secondary;Neurons;Adaptation models;Stability criteria;Impulsive adaptive control (IAC);neural networks (NNs);stabilization;synchronization},
  doi={10.1109/TNNLS.2023.3287997},
  ISSN={2162-2388},
  month={Nov},}@INPROCEEDINGS{8812214,
  author={Caprolu, Maurantonio and Di Pietro, Roberto and Lombardi, Flavio and Raponi, Simone},
  booktitle={2019 IEEE International Conference on Edge Computing (EDGE)}, 
  title={Edge Computing Perspectives: Architectures, Technologies, and Open Security Issues}, 
  year={2019},
  volume={},
  number={},
  pages={116-123},
  abstract={Edge and Fog Computing will be increasingly pervasive in the years to come due to the benefits they bring in many specific use-case scenarios over traditional Cloud Computing. Nevertheless, the security concerns Fog and Edge Computing bring in have not been fully considered and addressed so far, especially when considering the underlying technologies (e.g. virtualization) instrumental to reap the benefits of the adoption of the Edge paradigm. In particular, these virtualization technologies (i.e. Containers, Real Time Operating Systems, and Unikernels), are far from being adequately resilient and secure. Aiming at shedding some light on current technology limitations, and providing hints on future research security issues and technology development, in this paper we introduce the main technologies supporting the Edge paradigm, survey existing issues, introduce relevant scenarios, and discusses benefits and caveats of the different existing solutions in the above introduced scenarios. Finally, we provide a discussion on the current security issues in the introduced context, and strive to outline future research directions in both security and technology development in a number of Edge/Fog scenarios.},
  keywords={Virtualization;Servers;Computer architecture;Edge computing;Cloud computing;Security;Containers;Edge Computing;Fog Computing;Containers;Unikernels;RTOS;Security},
  doi={10.1109/EDGE.2019.00035},
  ISSN={},
  month={July},}@INPROCEEDINGS{10453169,
  author={Armaghani, Saber and Moravej, Zahra},
  booktitle={2024 International Conference on Protection and Automation in Power Systems (IPAPS)}, 
  title={A Novel Current Based Protection Scheme for Internal/External Fault Detection in Islanded Two Interconnected AC Microgrid}, 
  year={2024},
  volume={},
  number={},
  pages={8-15},
  abstract={This paper proposes a novel current-based protection scheme for detecting and distinguishing internal from external faults in Interconnected AC Microgrids (IAC-MGs). The proposed protection scheme uses the time domain-based dq0 transformation due to the fault current level being low in islanded IAC-MGs, and a low sensitivity protection scheme to the fault current level is necessary for the protection of MG and IAC-MG. Numerical results in the two IAC-MG test case shows that the proposed protection scheme can detect and distinguish between internal and external faults. Also, the proposed protection scheme has low sensitivity to the fault current level and does not require the communication system for fault detection.},
  keywords={Sensitivity;Uncertainty;Fault detection;Microgrids;Electrical fault detection;Time-domain analysis;Fault currents;Current based protection;interconnected AC Microgrids;dq0 transformation;internal/external fault detection},
  doi={10.1109/IEEECONF62358.2024.10453169},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10919306,
  author={Li, Yixin and Zeng, Junpeng and Wu, Weijie and Zhou, Shucan and Zhang, Yining and Zuo, Zhengmin},
  booktitle={2024 International Annual Conference on Complex Systems and Intelligent Science (CSIS-IAC)}, 
  title={Collector Substations Location and Topology for Large Offshore Wind Farms Based on Wake Model}, 
  year={2024},
  volume={},
  number={},
  pages={399-406},
  abstract={Wind energy plays an increasingly pivotal role in the global energy landscape, serving as a key driver for energy transition and the pursuit of sustainable development. This paper innovatively introduces a dynamic K-means algorithm with particle swarm optimization(DKM-PSO) to autonomously determine the optimal number and locations of offshore substations (OSs) in large-scale offshore wind farms (LOWFs). Additionally, the paper use a binary particle swarm optimization(BPSO) technique to identify the most suitable cable routing topology. This approach considers the power flow direction and the spatial arrangement of the offshore wind farm, facilitating the effective transmission of electricity generated by the wind turbines(WTs) to the OS. The ultimate goal of this optimization is to enhance economic efficiency. The proposed design has been validated through testing on a large-scale offshore wind farm cluster model. The results indicate that the new method offers cost savings compared to previous approaches.},
  keywords={Substations;Wind energy;Heuristic algorithms;Wind farms;Wind power generation;Topology;Planning;Wind turbines;Particle swarm optimization;Optimization;Renewable energy;large-scale offshore wind farm planning;offshore substations siting;mixed-integer linear programming optimization},
  doi={10.1109/CSIS-IAC63491.2024.10919306},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{6175458,
  author={Nicholls, David},
  booktitle={2012 Proceedings Annual Reliability and Maintainability Symposium}, 
  title={An objective look at predictions — Ask questions, challenge answers}, 
  year={2012},
  volume={},
  number={},
  pages={1-6},
  abstract={For more than 25 years, there has been a passionate dialog throughout the reliability engineering community as to the appropriate use of empirical and physics-based reliability models, and their associated benefits, limitations and risks. The mission of the Reliability Information Analysis Center (RIAC), as an Information Analysis Center (IAC) sponsored by the DoD Defense Technical Information Center (DTIC) over the last 40 years, has been to participate in this discussion to promote an objective understanding of the issues from both perspectives. The purpose of this paper is to document and re-emphasize the appropriate circumstances for each model and prediction type, and to identify those relevant questions that need to be asked to ensure that all prediction approaches are objectively considered, appropriately applied, and their results correctly interpreted and communicated.},
  keywords={Reliability engineering;Predictive models;Data models;Stress;Analytical models;Complexity theory;Prediction;Empirical Model;Physics-based Model},
  doi={10.1109/RAMS.2012.6175458},
  ISSN={0149-144X},
  month={Jan},}@ARTICLE{10938001,
  author={Wu, Qilong and Yu, Zhuolin and Hu, Xiaoyu and Tang, Xiaodie and Zhou, Tong},
  journal={IEEE Sensors Journal}, 
  title={Analysis and Improvement of Adaptive Control Strategies for MEMS Vibratory Gyroscope Engineering Applications}, 
  year={2025},
  volume={25},
  number={9},
  pages={14810-14821},
  abstract={Traditional control methods for MEMS gyroscopes are unable to fully cope with short-term fluctuations and long-term drift caused by environmental factors. Adaptive control (AC) strategies as a novel operational mode of gyroscopes, known for their environmental robustness, have shown promising theoretical and simulation results. However, the challenges and potential in practical engineering implementation remain underexplored. Based on an analysis of key challenges in the engineering application process, an improved AC (IAC) method for MEMS vibratory gyroscopes is proposed. First, the impact of frequency difference fluctuations and phase errors on AC gyroscopes’ performance was analyzed through theoretical derivation and system simulation. To mitigate frequency difference fluctuations affecting long-term stability, a stiffness-adaptive electrostatic-tuning closed loop was incorporated into the traditional AC framework to track frequency drift accurately. Additionally, an automatic phase calibration algorithm, based on the bisection search, was developed to precisely identify and compensate for unknown phase errors, preventing control error divergence. Finally, the IAC framework was implemented on a field-programmable gate array (FPGA) platform to achieve AC of a MEMS quad-mass gyroscope (QMG). The experimental results indicate that automatic phase calibration is crucial for the proper operation of the IAC-based gyroscope, and the incorporation of the stiffness-adaptive closed-loop improved zero-bias stability by 40.1%, confirming the IAC method’s effectiveness and potential for similar engineering applications.},
  keywords={Gyroscopes;Micromechanical devices;Adaptive control;Sliding mode control;Sensors;Tuning;Fluctuations;Calibration;Robustness;Intelligent sensors;Adaptive control (AC);automatic phase calibration;MEMS gyroscope;stiffness-adaptive tuning},
  doi={10.1109/JSEN.2025.3551421},
  ISSN={1558-1748},
  month={May},}@INPROCEEDINGS{6580352,
  author={Bošković, Jovan D. and Mehra, Raman K.},
  booktitle={2013 American Control Conference}, 
  title={Performance analysis of a simple L1-adaptive controller}, 
  year={2013},
  volume={},
  number={},
  pages={3370-3375},
  abstract={In this note we compare the performance of a simple L1-adaptive controller with standard adaptive control strategies, i.e. Direct Adaptive Control (DAC) and Indirect Adaptive Control (IAC). Performance comparison is carried out with respect to several performance criteria. It is shown that, in this application, L1-controller is significantly outperformed by the IAC algorithm in the cases with and without time delay.},
  keywords={Adaptive control;Adaptation models;Delay effects;Monte Carlo methods;Oscillators;Time factors},
  doi={10.1109/ACC.2013.6580352},
  ISSN={2378-5861},
  month={June},}@INPROCEEDINGS{792100,
  author={Najarian, M.A. and Borowski, B.J. and Hryszko, M. and Lisowski, J.J. and Sene, D.E.},
  booktitle={1999 IEEE Aerospace Conference. Proceedings (Cat. No.99TH8403)}, 
  title={Impact of reduced spectral resolution on cloud detection and altitude estimation}, 
  year={1999},
  volume={4},
  number={},
  pages={319-331 vol.4},
  abstract={Atmospheric effects, especially the impact of clouds, have always played a major role in remote sensing applications. Advances in optic, sensor, micro-electronic, communication and processing technologies enable the development and deployment of versatile remote sensors. Nevertheless, deployed systems remain costly so tailoring them to specific missions continues to be a key element of design. Autonomous interpretation of the complex terrestrial environment becomes easier as spectral, spatial and temporal information is enhanced. By nature, cloud identification improves in value as larger areas are observed so spectral and spatial resolution trades with coverage area become important. An algorithm to autonomously identify cloud type from high spatial and moderate spectral resolution data was presented at the 1998 IEEE Aerospace Conference (IAC). The purpose of this paper is to evaluate the performance of the CLOUD Detection and Identification (CLOUDDI) algorithm in the presence of reduced spectral and spatial resolution. Results against both flight data and model predictions are considered.},
  keywords={Clouds;Spatial resolution;Layout;Predictive models;Spectroscopy;Data mining;Remote sensing;Optical sensors;Computer aided software engineering;Testing},
  doi={10.1109/AERO.1999.792100},
  ISSN={},
  month={March},}@INPROCEEDINGS{10073933,
  author={Myilvahanan, Karthick and B, Shashank and Raj, Tushar and Attanti, Chiraanth and Sahay, Shivam},
  booktitle={2023 Third International Conference on Artificial Intelligence and Smart Energy (ICAIS)}, 
  title={A Study on Deep Learning based Classification and Identification of offensive memes}, 
  year={2023},
  volume={},
  number={},
  pages={1552-1556},
  abstract={Sarcasm is a complicated language device that is regularly utilised on e-commerce and social media websites. Failure to recognise sarcastic statements would confuse classification algorithms and result in incorrect findings in Natural Language Processing applications like sentiment analysis and opinion mining. Studies on sarcasm detection have included a variety of learning techniques. However, the majority of these teaching strategies have always focused their attention entirely on the concepts that were communicated, ignoring the context. As They thereby missed the meaning and context of the sarcastic statement. Second, the emotional polarity of words is not taken into account when using the word embedding learning methodology, which is a common way for convolutional feature vector encoding in NLP deep learning approaches. To overcome the issues mentioned above,This research presents a context-based feature strategy for sarcasm detection that combines deep learning, BERT, and conventional machine learning. Two benchmark datasets from the Internet Argument Corpus (IAC-v2) and Twitter were used for the categorisation. Employed are all three learning models. Deep learning and embedding-based representation are both utilised by the initial model. Word embedding and context are being developed utilising global vector representation (GloVe) learning and Recurrent Neural Network (RNN) with a Bidirectional Long Short Term Memory (Bi-LSTM). A pre-trained Bidirectional Encoder representation (BERT) is used to build the second model, which is based on Transformer. In contrast, the third model is founded on the BERT feature’s feature fusion. a function that incorporates sentiment-related, syntactic, and GloVe embedding},
  keywords={Deep learning;Sentiment analysis;Recurrent neural networks;Social networking (online);Bit error rate;Syntactics;Transformers;Deep Learning;Classification;Bidirectional Long Short Term Memory (Bi-LSTM);Recurrent Neural Network (RNN)},
  doi={10.1109/ICAIS56108.2023.10073933},
  ISSN={},
  month={Feb},}@ARTICLE{556022,
  author={Wen-Shyong Yu and Te-Son Kuo},
  journal={IEEE Transactions on Control Systems Technology}, 
  title={Continuous-time indirect adaptive control of the electrohydraulic servo systems}, 
  year={1997},
  volume={5},
  number={2},
  pages={163-177},
  abstract={A continuous-time robust indirect adaptive control (IAC) algorithm with a self-excitation capability is proposed for position control of an electrohydraulic servo system subject to parametric uncertainties and load disturbances. In this algorithm, a gradient least squares dead zone estimation is used to identify the plant parameters and then a linear pole-placement controller is designed using the estimate. By a coprimeness verification procedure, the proposed algorithm facilitates the establishment of the adaptive pole-placement control of the closed-loop system by using an additional nonlinear feedback signal implemented for supplying the system with sufficiently rich signals. An analysis shows this algorithm can guarantee parameter estimation convergence and system stability based on the certainty equivalence principle. The performance of the proposed algorithm is evaluated through both the simulation results and the experimental studies. Simulations and experiments are conducted to see how well the proposed algorithm compares with two existing control schemes in controlling the same process. The results show that the IAC scheme confirms the analysis and has considerable robustness subject to parametric uncertainties and load disturbances and has better performance than the other two controllers.},
  keywords={Adaptive control;Electrohydraulics;Robust control;Uncertainty;Algorithm design and analysis;Position control;Servomechanisms;Least squares approximation;Programmable control;Nonlinear control systems},
  doi={10.1109/87.556022},
  ISSN={1558-0865},
  month={March},}@INPROCEEDINGS{9582608,
  author={Düllmann, Thomas F. and Kabierschke, Oliver and Hoorn, André van},
  booktitle={2021 47th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={StalkCD: A Model-Driven Framework for Interoperability and Analysis of CI/CD Pipelines}, 
  year={2021},
  volume={},
  number={},
  pages={214-223},
  abstract={Today, most Continuous Integration and Delivery (CI/CD) solutions use infrastructure as code to describe the pipeline-based build and deployment process. Each solution uses its own format to describe the CI/CD pipeline, which hinders the interoperability and the analysis of CI/CD pipelines. In this paper, we propose a model-driven DSL-based framework for CI/CD pipeline definition and analysis. It comprises (i) the analysis of the meta-model of the Jenkins pipeline definition language, (ii) the StalkCD domain-specific language providing a base for interoperability and transformation between different formats, and (iii) an extensible set of transformations between tool-specific CI/CD definitions and analysis tools. We demonstrate the specific support for Jenkins as a CI/CD tool and BPMN for exploiting analyses from the workflow domain and visualizing the results. We evaluate the DSL and the transformations empirically based on more than 1,000 publicly available Jenkinsfiles. The evaluation shows that our framework supports 70% of these files without information loss.},
  keywords={Analytical models;Visualization;Codes;Pipelines;Tools;DSL;Interoperability;model-driven framework;continuous integration;continuous delivery;DSL;build pipeline;BPMN;Jenkinsfile},
  doi={10.1109/SEAA53835.2021.00035},
  ISSN={},
  month={Sep.},}@ARTICLE{9644611,
  author={Zhao, Junhui and Yang, Lihua and Xia, Minghua and Motani, Mehul},
  journal={IEEE Internet of Things Journal}, 
  title={Unified Analysis of Coordinated Multipoint Transmissions in mmWave Cellular Networks}, 
  year={2022},
  volume={9},
  number={14},
  pages={12166-12180},
  abstract={This article performs a unified analysis of three coordinated multipoint (CoMP) transmission strategies in the downlink of mmWave cellular networks, including the fixed-number base station (BS) cooperation (FNC), the fixed-region BS cooperation (FRC), and the interference-aware BS cooperation (IAC). We first develop a comprehensive framework for CoMP operation in cellular networks, and investigate the network performance under a Poisson point process (PPP) model together with mmWave spectrum. To show what fraction of users in the network achieve target reliability for a given signal to interference-plus-noise ratio (SINR)/signal-to-interference ratio (SIR), we derive the SINR/SIR meta distributions, and further obtain the coverage probability as well as mean local delay for the three cooperation strategies. A pivotal intermediate step to compute the performance metrics is the derivation of joint distributions of distances between a typical user and cooperative BSs. Our analysis demonstrates that parameters of blockage have a significant influence on the network performance for the three CoMP schemes. We find that the FRC scheme makes more users achieve the given link reliability for the scenario with a low density of BSs, while the IAC scheme provides better performance for the network with a high density of BSs. Moreover, the optimal CoMP scheme can be approximately selected by considering the nearest distance from the serving BS to user and the radius of the approximate line-of-sight (LoS) region in the cellular networks.},
  keywords={Cellular networks;Reliability;Internet of Things;Geometry;Stochastic processes;Microwave antenna arrays;Downlink;Coordinated multipoint (CoMP) transmission;coverage probability;meta distribution;mmWave;stochastic geometry},
  doi={10.1109/JIOT.2021.3134017},
  ISSN={2327-4662},
  month={July},}@INPROCEEDINGS{10754567,
  author={Jonathan, Joyce and Knee, K. and Moretti, D. and Iannucci, M. and Morse, C. and Wengren, Micah and Snowden, D. and Vance, T.},
  booktitle={OCEANS 2024 - Halifax}, 
  title={Reaching for the Cloud: Architecting a Cloud-Native Service-Based Ecosystem for MetOcean Data Management}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={The NOAA Integrated Ocean Observing System (IOOS) National Data Management and Cyberinfrastructure (DMAC) system is tasked with providing public access to data and products generated through observation and modeling of the nation's oceans, coasts, and Great Lakes. The standards-based approach implemented by IOOS has been successfully implemented by IOOS partners and stakeholders and has provided a consistent framework for both submitting and accessing data. However, the esoteric nature of the data formats, tools, and services required presents a barrier for many users. Occurring at a rapid pace, advances in oceanographic and meteorological technologies offer new ways to lower this barrier and provide enhanced efficiencies and stability to DMAC users. The Reaching for the Cloud (RFC) initiative leveraged one such advancement, cloud computing, which provides a clear option to build upon current data management procedures and metadata standards with similar cloud-native frameworks that are increasingly accessible, approachable, and cost-effective. This work led to key recommendations and a roadmap outlining how IOOS and its Regional Associations (RAs) can transition towards a service-based cloud ecosystem that will increase the use of IOOS data and promote connection to other disciplines and stakeholders. Over the course of the three-year effort, we identified requirements for this transition, demonstrated its value with a series of functional prototypes, determined associated usage and cost metrics, and developed recommendations for governance and operations. Not only does this move the community towards ensuring data is more accessible, it also considers how to reduce costs, improve data discoverability, and, most importantly, allow the IOOS National DMAC system to keep pace with rapid advancements and evolutions in oceanographic technologies. Through stakeholder outreach efforts early in the project, we identified management of gridded numerical model data (oceanographic and meteorological) as a key research area to focus our efforts. Using the current workflow for management of model data, we defined a series of prototypes to demonstrate various elements of that workflow including data ingest, storage and discovery, processing and analysis, and presentation. Starting with data ingest, we looked at how to identify, store, and enrich the data so that it is more easily accessible and ultimately focused on using zarr/kerchunk for optimizing data storage on the cloud. Converging on a specific data format is fraught with challenges but we were able to find a middle-road with kerchunk, which indexes the native gridded data (NetCDF/GRIB) into the zarr specification for fast selection of specific byte ranges. We use a common notification/queueing pattern using SNS/SQS notifications from S3 data stores to perform the indexing as data is available. We also generate 30 day and model-run aggregations which provide a virtual view of the data as a single dataset although it may physically be composed of many different files. We then addressed common use-cases such as cloud-native scientific processing workflows and web-based visualization. The kerchunk process makes data access from the cloud more efficient but it still requires a lot of domain knowledge, dependencies, and engineering to use that data. Although model data is freely available on the cloud now, it's hard to claim that data is truly FAIR given inherent data challenges such as different projections, formats, and storage schemes; coupled with infrastructure challenges of scaling, distribution, and storage. To address those challenges, we are serving the data through a data broker layer named Xpublish. Xpublish is a modern, open-source software package for serving multidimensional array-oriented gridded scientific data. Xpublish is designed to be a self-serve data access point to greatly simplify the process of retrieving and processing data on the cloud. The complexity of cloud system design is encapsulated in Xpublish so that the users and operators have minimal technical complexity to manage. We have prototyped several applications of Xpublish such as map tiling and data sub-setting. We have tested these services on various cloud infrastructure platforms and explored the nuances of choices such as serverless vs managed and deploying infrastructure as code (IaC). This exploratory work has informed RPS and our clients of a clear path forward for working with scientific data in the cloud. The RFC initiative has resulted in the creation of several new open-source communities and tools to aid in the formatting and serving of multidimensional array-oriented gridded data. We will describe these new tools, where they fit in the ecosystem, and how they can be used to start serving data from the cloud.},
  keywords={Cloud computing;Costs;Oceans;Ecosystems;Prototypes;Numerical models;Complexity theory;Stakeholders;Arrays;System analysis and design},
  doi={10.1109/OCEANS55160.2024.10754567},
  ISSN={2996-1882},
  month={Sep.},}@INPROCEEDINGS{5486734,
  author={Peng Rui-hui and Wang Xiang-wei and Lü, Yong-sheng and Wang Shu-zong},
  booktitle={2010 2nd International Conference on Advanced Computer Control}, 
  title={SAR imagery segmentation based on integrated active contour}, 
  year={2010},
  volume={3},
  number={},
  pages={43-47},
  abstract={Image segmentation is an important problem on image processing technique. Based on active contour model, a novel integrated active contour (IAC) model for SAR imagery segmentation has been developed. In this model, the edge information is extracted by edge detection operators based on ratio of average framework, and the region statistical information is distilled by the maximization of likelihood function of different regions. And an unconditionally stable numerical scheme is used by means of additional operator splitting arithmetic. In the end, some segmentation tests have been done using MSTAR, Radarsat-2 and domestic spaceborne SAR images. Results show: proposed model has a good adaptability to complicated SAR images segmentation, and gives an accurate and fast partition for different regions in the images; implementing method is robust which is insensitive to parameters setting and initializations.},
  keywords={Image segmentation;Active contours;Image edge detection;Arithmetic;Weapons;Testing;Spaceborne radar;Robustness;Speckle;Image processing;synthetic aperture radar;image segmentation;edge detection;active contour},
  doi={10.1109/ICACC.2010.5486734},
  ISSN={},
  month={March},}@INPROCEEDINGS{7990844,
  author={Klein, Kirill and Hoene, Eckart and Lang, Klaus-Dieter},
  booktitle={PCIM Europe 2017; International Exhibition and Conference for Power Electronics, Intelligent Motion, Renewable Energy and Energy Management}, 
  title={Comprehensive AC Performance Analysis of Ceramic Capacitors for DC Link Usage}, 
  year={2017},
  volume={},
  number={},
  pages={1-7},
  abstract={The paper explains the needs for using of an additional DC link capacitor closely to fast switching semiconductor and derives design rules for it. Results of the shown study on X7R, X6S, X7T and CeraLink capacitors help to choose correct capacitor for DC link usage, to be able to design switching cell properly. Cs and ESR of capacitors were measured and compared to typical datasheet values, and completed with large amplitude measurements (iac=1A) for different DC-voltages, frequencies and higher temperatures (RT/80 deg C /125 deg C). Design rules are proved empirically implying corrected capacitance values of used capacitors.},
  keywords={},
  doi={},
  ISSN={},
  month={May},}@INPROCEEDINGS{1349170,
  author={Qingguo Lan and Shufen Liu and Lu Han and Ming Qu},
  booktitle={8th International Conference on Computer Supported Cooperative Work in Design}, 
  title={Study and realization of the inter-application communication methods}, 
  year={2004},
  volume={2},
  number={},
  pages={124-127 Vol.2},
  abstract={The inter-application communication (IAC) is the technology that allows different applications in a computer system to effectively exchange data and information, which is the base of realizing software cooperation and software system integration. According to the analysis of application requirements, the authors gave inter-application communication modes of the telecommunication network administration computer, studied inter-application communication methods, the types and structures of communication information and various propagation modes, security problems of inter-application communication. This work is applied in the network administration software developments of a well-known domestic telecommunication operator.},
  keywords={Application software;Telecommunication computing;Computer applications;Communication system software;Software systems;Information analysis;Computer networks;Communication system security;Computer security;Data security},
  doi={10.1109/CACWD.2004.1349170},
  ISSN={},
  month={May},}@ARTICLE{9187246,
  author={Jiang, Tingyu and Ju, Ping and Wang, Chong and Li, Hongyu and Liu, Jingzi},
  journal={IEEE Transactions on Smart Grid}, 
  title={Coordinated Control of Air-Conditioning Loads for System Frequency Regulation}, 
  year={2021},
  volume={12},
  number={1},
  pages={548-560},
  abstract={The increasing penetration of renewable generation presents challenges for system frequency regulation due to short-term power fluctuations and system inertia reductions. This article presents a coordinated control strategy for frequency regulation in which inverter air-conditioning (IAC) units are used to perform primary frequency regulation (PFR) and fixed frequency air-conditioning (FFAC) units are used to perform secondary frequency regulation (SFR). In PFR, the regulation power is provided by adjusting the setpoints of the IAC units. A random number generation method is proposed to stochastically trigger IAC units based on the frequency deviation in real time. Furthermore, a recovery method is presented to stably restore the IAC units to their initial operating states after regulation. In SFR, a constant equivalent duty ratio method is raised to keep the regulation power stable over a long instruction interval. Based on this, the transforming time interval method is presented to determine the ON/OFF status of FFAC units to provide the required regulation power. Additionally, a recovery method for FFAC units is proposed to mitigate the power rebound after regulation. The proposed control strategy achieves an improved frequency regulation effect with fewer communication demands. Dynamic simulations in a six-machine two-area system and an isolated microgrid with wind power verify the effectiveness of the proposed control strategy.},
  keywords={Frequency control;Atmospheric modeling;Switches;Inverters;Mathematical model;Random number generation;Time-frequency analysis;Coordinated control;demand response;fixed frequency air-conditioning;frequency regulation;inverter air-conditioning;load recovery},
  doi={10.1109/TSG.2020.3022010},
  ISSN={1949-3061},
  month={Jan},}@ARTICLE{499735,
  author={Ooishi, T. and Komiya, Y. and Hamade, K. and Asakura, M. and Yasuda, K. and Furutani, K. and Kato, T. and Hidaka, H. and Ozaki, H.},
  journal={IEEE Journal of Solid-State Circuits}, 
  title={A mixed-mode voltage down converter with impedance adjustment circuitry for low-voltage high-frequency memories}, 
  year={1996},
  volume={31},
  number={4},
  pages={575-585},
  abstract={This paper proposes a low voltage operation technique for a voltage down converter (VDC) using a mixed-mode VDC (MM-VDC), that combines an analog VDC and a digital VDC, and provides high frequency application using an impedance adjustment circuitry (IAC). The MM-VDC operates with a small response delay and a large supply current. Moreover, the IAC is adopted by the MM-VDC for wide range frequency operation under low voltage conditions. The IAC can change the supply current capability in accordance with the load operation frequency to avoid the overshoot and undershoot problems caused by the unmatched supply current. A 64 Mb-DRAM test device operated with the MM-VDC achieves well-controlled internal voltage (VCI) level and achieves high frequency operation. These systems, the MM-VDC and the IL-VDC, can be applicable for both low voltage and high frequency operation.},
  keywords={Impedance;Current supplies;Low voltage;Delay;Testing;Power dissipation;Power supplies;Frequency conversion;Circuit stability;Controllability},
  doi={10.1109/4.499735},
  ISSN={1558-173X},
  month={April},}@INPROCEEDINGS{7000676,
  author={Khalili, Azam and Rastegarnia, Amir and Bazzi, Wael},
  booktitle={7'th International Symposium on Telecommunications (IST'2014)}, 
  title={A collaborative adaptive algorithm for the filtering of noncircular complex signals}, 
  year={2014},
  volume={},
  number={},
  pages={96-99},
  abstract={In this paper we propose an adaptive estimation algorithm for in-network processing of complex signals. The proposed algorithm, which will be referred as the incremental augmented complex least mean square (IAC-LMS) algorithm, relies on the incremental collaboration among the nodes, and the LMS adaptive filtering. Spatial data mining is archived by the incremental collaboration; while with LMS learning rules to endow the network with adaptation. We derive the required conditions for mean stability of the proposed algorithm. We use real world noncircular wind data to evaluate the performance of the proposed algorithm. Our simulation results reveal that the IAC-LMS algorithm is able to estimate noncircular (improper) signals.},
  keywords={Vectors;Signal processing algorithms;Signal processing;Adaptive systems;Estimation;Algorithm design and analysis;Equations;Adaptive networks;incremental least mean square;complex signals},
  doi={10.1109/ISTEL.2014.7000676},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8760504,
  author={Sener, Melisa Idil and Ugur, Emre},
  booktitle={2018 Joint IEEE 8th International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob)}, 
  title={Partitioning Sensorimotor Space by Predictability Principle in Intrinsic Motivation Systems}, 
  year={2018},
  volume={},
  number={},
  pages={54-59},
  abstract={Inspired by infant development, intrinsic motivation (IM) guides the robot with intelligent exploration strategies, enabling efficient and effective learning in high-dimensional search spaces. A particular method in IM, namely Intelligent Adaptive Curiosity (IAC), adaptively partitions agents sensorimotor space (SM) into regions of exploration, and guides the agent to select the regions that are in the moderate level of difficulty, and learns separate experts for different regions. Therefore, the means of partitioning the SM and the mechanisms behind region generation is of utmost importance. In this study, we propose a method for partitioning the space that allows maximizing the performances of the experts that will be responsible for learning skills. In brief, for each potential partitioning, the error of the experts are calculated and the partitioning that would generate the minimal error in the future is selected. Our method is evaluated in a setting with a simulated robot that learns predicting the next state given the current state and the action taken in an environment composed of regions with different properties. We verified the proposed method, SM is partitioned into more semantically meaningful regions adapting environment dynamics, the exploration of the robot in these regions can better exploit IM mechanisms and the system learn more efficiently and effectively i.e. with higher performance in a shorter time, compared to a baseline method.},
  keywords={Robot sensing systems;Task analysis;Error analysis;Intelligent systems;Complexity theory;Reinforcement learning;intrinsic motivation;autonomous mental development;reinforcement learning;active learning;developmental robotics},
  doi={10.1109/DEVLRN.2018.8760504},
  ISSN={2161-9484},
  month={Sep.},}@INPROCEEDINGS{9805427,
  author={Faranda, Roberto Sebastiano and Fumagalli, Kim and Franzosi, Luca and Bellofatto, Luigi},
  booktitle={2021 Petroleum and Chemical Industry Conference Europe (PCIC Europe)}, 
  title={Innovative Strategies for Internal ARC-Flash Risk Mitigation in LV Switchgears}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={Internal Arc Classification (IAC) of Low Voltage switchgear according to IEC and IEEE standards is one of the most important requirements to guarantee personal safety in case of internal arc faults. One of the challenges is to find innovative strategies to reduce damages of arc triggering utilizing more specific solutions inside the switchgear. As known, there are three mains philosophies of Arc Fault Management: Active protection, based on monitoring of electrical devices; Passive protection, obtained using structural reinforcements and insulations, Avoidance philosophy, where the assembly guarantees a reduced risk of arc fault (e.g. the arc ignition protected zone).What this research is going to explore is the Passive protection and the Avoidance philosophy with the introduction of new approach for internal arc-flash risk mitigation. The paper presents an innovative validation procedure in order to improve the IAC.},
  keywords={Resistance;Philosophical considerations;Switchgear;Europe;Arc discharges;Ignition;Position measurement;Passive protection;Avoidance philosophy;Internal Arc;Arc Fault Management;Arc Fault protection},
  doi={10.23919/PCICEurope50407.2021.9805427},
  ISSN={2151-7665},
  month={June},}@ARTICLE{8224118,
  author={Gendre, B. and Klotz, A. and Palazzi, E. and Krühler, T. and Covino, S. and Afonso, P. and Antonelli, L. A. and Atteia, J. L. and D'Avanzo, P. and Boër, M. and Greiner, J. and Klose, S.},
  journal={Monthly Notices of the Royal Astronomical Society}, 
  title={Testing gamma-ray burst models with the afterglow of GRB 090102}, 
  year={2010},
  volume={405},
  number={4},
  pages={2372-2380},
  abstract={We present the observations of the afterglow of gamma-ray burst GRB 090102. Optical data taken by the Telescope a Action Rapide pour les Objets Transitoires (TAROT), Rapid Eye Mount (REM), Gamma-Ray burst Optical/Near-Infrared Detector (GROND), together with publicly available data from Palomar, Instituto de Astrofísica de Canarias (IAC) and Nordic Optical Telescope (NOT) telescopes, and X-ray data taken by the XRT instrument on board the Swift spacecraft were used. This event features an unusual light curve. In X-rays, it presents a constant decrease with no hint of temporal break from 0.005 to 6 d after the burst. In the optical, the light curve presents a flattening after 1 ks. Before this break, the optical light curve is steeper than that of the X-ray. In the optical, no further break is observed up to 10 d after the burst. We failed to explain these observations in light of the standard fireball model. Several other models, including the cannonball model were investigated. The explanation of the broad-band data by any model requires some fine-tuning when taking into account both optical and X-ray bands.},
  keywords={gamma-ray burst: individual: 090102},
  doi={10.1111/j.1365-2966.2010.16601.x},
  ISSN={1365-2966},
  month={July},}@INPROCEEDINGS{10211674,
  author={Dallegrave, Tamara and Santos, Wylliams Barbosa},
  booktitle={2023 18th Iberian Conference on Information Systems and Technologies (CISTI)}, 
  title={Action Research for Industry Academia Collaboration : A replication Study}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Collaboration between industry and academic communities requires considerable work but has the power to foster innovation. This relationship with joint trust promotes knowledge exchange that helps develop more qualified researchers and professionals. The Action Research (AR) method combines theory and practice, and studies involving industry-academia collaboration (IAC) have shown encouraging results. Nevertheless, further investigation is required to verify the effects of applying this method. This research investigates the perceptions of academic master’s and doctoral program students and professionals involved in projects that applied the AR method as a strategy to foster IAC. This article replicates a case study with different projects that conducted an AR in software companies. This study indicated high satisfaction among students (83%) when using action research in the course. All students considered the practical knowledge very relevant and would like to use the method again in other opportunities throughout their academic and professional life. This investigation showed that conducting IAC projects using the AR method within the industry in an educational context was challenging. That occurred due to the lack of experience in using empirical methods. Also, the professional’s unavailability delayed the results and, consequently, the activities in the project that already had a very tight schedule.},
  keywords={Industries;Technological innovation;Schedules;Collaboration;Medical services;Companies;Software;Industry-Academia Collaboration;Action Research;Collaborative Practice Research;Replication},
  doi={10.23919/CISTI58278.2023.10211674},
  ISSN={2166-0727},
  month={June},}@ARTICLE{10546255,
  author={Lumetti, Luca and Pipoli, Vittorio and Bolelli, Federico and Ficarra, Elisa and Grana, Costantino},
  journal={IEEE Access}, 
  title={Enhancing Patch-Based Learning for the Segmentation of the Mandibular Canal}, 
  year={2024},
  volume={12},
  number={},
  pages={79014-79024},
  abstract={Segmentation of the Inferior Alveolar Canal (IAC) is a critical aspect of dentistry and maxillofacial imaging, garnering considerable attention in recent research endeavors. Deep learning techniques have shown promising results in this domain, yet their efficacy is still significantly hindered by the limited availability of 3D maxillofacial datasets. An inherent challenge is posed by the size of input volumes, which necessitates a patch-based processing approach that compromises the neural network performance due to the absence of global contextual information. This study introduces a novel approach that harnesses the spatial information within the extracted patches and incorporates it into a Transformer architecture, thereby enhancing the segmentation process through the use of prior knowledge about the patch location. Our method significantly improves the Dice score by a factor of 4 points, with respect to the previous work proposed by Cipriano et al., while also reducing the training steps required by the entire pipeline. By integrating spatial information and leveraging the power of Transformer architectures, this research not only advances the accuracy of IAC segmentation, but also streamlines the training process, offering a promising direction for improving dental and maxillofacial image analysis.},
  keywords={Irrigation;Three-dimensional displays;Annotations;Transformers;Image segmentation;Training;Deep learning;CBCT;inferior alveolar canal;medical imaging;3D imaging;transformers;patch-based learning},
  doi={10.1109/ACCESS.2024.3408629},
  ISSN={2169-3536},
  month={},}@ARTICLE{9266050,
  author={Takagi, Atsushi and Li, Yanan and Burdet, Etienne},
  journal={IEEE Transactions on Haptics}, 
  title={Flexible Assimilation of Human's Target for Versatile Human-Robot Physical Interaction}, 
  year={2021},
  volume={14},
  number={2},
  pages={421-431},
  abstract={Recent studies on the physical interaction between humans have revealed their ability to read the partner's motion plan and use it to improve one's own control. Inspired by these results, we develop an intention assimilation controller (IAC) that enables a contact robot to estimate the human's virtual target from the interaction force, and combine it with its own target to plan motion. While the virtual target depends on the control gains assumed for the human, we show that this does not affect the stability of the human-robot system, and our novel scheme covers a continuum of interaction behaviours from cooperation to competition. Simulations and experiments illustrate how the IAC can assist the human or compete with them to prevent collisions. In this article, we demonstrate the IAC's advantages over related methods, such as faster convergence to a target, guidance with less force, safer obstacle avoidance and a wider range of interaction behaviours.},
  keywords={Robots;Robot kinematics;Task analysis;Trajectory;Robot sensing systems;Estimation;Collision avoidance;Intention assimilation;interaction control;physical human-robot interaction.},
  doi={10.1109/TOH.2020.3039725},
  ISSN={2329-4051},
  month={April},}@INPROCEEDINGS{10394354,
  author={Zhou, Lei and Liu, Yang and Li, Qiang},
  booktitle={2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Generalized Zero-Shot Learning via Implicit Attribute Composition}, 
  year={2023},
  volume={},
  number={},
  pages={384-389},
  abstract={Zero-shot learning (ZSL) is an important but challenging task in computer vision that aims to identify unseen classes without matching training samples. Current cutting-edge ZSL methods based on locality focus on acquiring the explicit locality of distinguishing characteristics, which could face a lack of adequate supervision at the class attribute level. This paper introduces a novel approach called IAC, which aims to learn Implicit Attribute Composition for ZSL. This method is more comprehensive compared to attribute localization that solely focuses on class-level attribute supervision. IAC utilizes subspace representations that efficiently capture the inherent structure of high-dimensional image features. Then, we learn implicit attribute composition through subspace representation learning. The superiority of the proposed IAC compared to the state-of-the-art is demonstrated through sufficient experiments conducted on three commonly used ZSL datasets, CUB, SUN, and AwA2.},
  keywords={Location awareness;Representation learning;Training;Zero-shot learning;Task analysis;Sun;Faces},
  doi={10.1109/SMC53992.2023.10394354},
  ISSN={2577-1655},
  month={Oct},}@INPROCEEDINGS{9281631,
  author={Le, Lingling and Fang, Jiakun and Ai, Xiaomeng and Wen, Jinyu and Zhang, Menglin and Zeng, Kaiwen},
  booktitle={2020 IEEE Power & Energy Society General Meeting (PESGM)}, 
  title={Continuous-Time optimization of Inverter Air Conditioning Demand Response for Ramping Flexibility Improvement}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  abstract={The increasing deployment of renewable energy sources into the power system is calling for more ramping flexibilities. Inverter air conditioning (IAC) has a huge potential for demand response due to its large proportion of electricity consumption and the thermal inertia. In this paper, the dynamic response model for IAC is deduced. With Hermite and Bernstein splines, the continuous-time (CT) model for IAC is built. The dynamic response capacity (DRC) method is proposed to schedule the IAC for demand response. Then the IAC demand response (IAC-DR) model is integrated with the DRC scheduling method for ramping flexibility improvement. Numerical results demonstrate that the proposed IAC-DR model is effective in reducing the operation cost for the power systems. Besides, detailed analysis of net load fluctuations and ramping requirements is illustrated.},
  keywords={Atmospheric modeling;Power system dynamics;Load management;Numerical models;Splines (mathematics);Optimization;Load modeling;Continuous Time;Inverter AC;Demand Response;Ramping Flexibility},
  doi={10.1109/PESGM41954.2020.9281631},
  ISSN={1944-9933},
  month={Aug},}@INPROCEEDINGS{6900493,
  author={Qian, Xiaohu and Huang, Min and Gao, Taiguang and Wang, Xingwei},
  booktitle={2014 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={An improved ant colony algorithm for winner determination in multi-attribute combinatorial reverse auction}, 
  year={2014},
  volume={},
  number={},
  pages={1917-1921},
  abstract={This paper considers the problem of one buyer procuring multi-items from multiple potential suppliers in the electronic reverse auction, where each supplier can bid on combinations of items. From the perspective of the buyer, by considering multi-attributes of each item, a winner determination problem (WDP) of multi-items single-unit combinatorial reverse auctions was described and a bi-objective programming model was established. According to the characteristics of the model, an equivalent single-objective programming model was obtained. As the problem is NP-hard, an improved ant colony (IAC) algorithm considering the dynamic transition strategy and the Max-Min pheromone strategy is proposed for the problem. Experimental results show the effectiveness of the improved algorithm.},
  keywords={Heuristic algorithms;Mathematical model;Approximation algorithms;Educational Activities Board;Algorithm design and analysis;Equations;Procurement;reverse auction;winner determination problem;ant colony algorithm;dynamic transition strategy;Max-Min pheromone strategy},
  doi={10.1109/CEC.2014.6900493},
  ISSN={},
  month={July},}@ARTICLE{9142241,
  author={Bai, Feifei and Yan, Ruifeng and Saha, Tapan Kumar and Cui, Yi and Pan, Zicheng},
  journal={IEEE Transactions on Smart Grid}, 
  title={Extraction of Dynamic Frequency Response Characteristics and Modelling of Modern Air Conditioners}, 
  year={2021},
  volume={12},
  number={1},
  pages={897-900},
  abstract={Modern inverter-based air-conditioners (IACs) are generally equipped with power-electronic components to achieve higher efficiency and more advanced controllability. Thus, their operating behaviours can be very different from the conventional air-conditioners with direct motor connections, and their new characteristics have not been adequately studied in the current literature. Thus, hardware experiments are conducted to extract the novel dynamic frequency response features of modern inverter-based air-conditioners under a range of different frequency disturbances. Then, a new IAC model with physical meanings is developed by accommodating the discovered new features such as time delays, load frequency relief and the minimum operating power limit. Further, this letter also demonstrates that the developed air-conditioner model can accurately represent the dynamics of the IACs under various frequency events. The extracted dynamic frequency response behaviours and the developed air-conditioner model will provide a solid foundation for the modern appliance modelling in a large scale and will assist to improve the accuracy of the inertia response representations of distribution network’s loads.},
  keywords={Load modeling;Atmospheric modeling;Time-frequency analysis;Induction motors;Voltage measurement;Home appliances;Air conditioner;dynamic response modelling;laboratory experiment;frequency dynamic response;load modelling;home appliance;load frequency relief (LFR)},
  doi={10.1109/TSG.2020.3009841},
  ISSN={1949-3061},
  month={Jan},}@INPROCEEDINGS{1529281,
  author={Mu-Tian Yan and Tun-Hua Cheng},
  booktitle={IEEE International Conference on Mechatronics, 2005. ICM '05.}, 
  title={High accuracy motion control of linear motor drive wire-EDM machines}, 
  year={2005},
  volume={},
  number={},
  pages={346-351},
  abstract={This paper is aim to develop and investigate a permanent magnet linear-motor-driven table system for a wire-EDM machine. Dynamic model and system identification of the linear motor system have been derived and analyzed. The linear motor drive system has nonlinear and time-varying behaviors because of the effect of irregular friction of the sliding surface and cogging force. Therefore, a conventional digital controller may not suffice to provide a high contouring accuracy as well as adequate disturbance rejection and parameter variation robustness. An indirect adaptive controller (IAC), combined with a neural network-based feedforward controller (NNBFC) is proposed to improve contouring performance of the linear motor system. Experimental results show that this control method achieves satisfactory contouring accuracy under the influence of friction and cogging force.},
  keywords={Motion control;Motor drives;Friction;Forging;Control systems;Permanent magnets;Nonlinear dynamical systems;System identification;Permanent magnet motors;Magnetic analysis},
  doi={10.1109/ICMECH.2005.1529281},
  ISSN={},
  month={July},}@INPROCEEDINGS{1230360,
  author={Oka, H. and Tokuta, H. and Namizaki, Y. and Chiba, S. and Sekino, N.},
  booktitle={2003 IEEE International Magnetics Conference (INTERMAG)}, 
  title={Humidity effect for the magnetic woody characteristics of powder type magnetic wood}, 
  year={2003},
  volume={},
  number={},
  pages={CP-10},
  abstract={In this paper, we focused on the relationship between humidity and magnetic characteristics of powder type magnetic wood. The magnetic powder ratio, wood powder density and magnetic binder density were all examined as parameters for AC permeability /spl mu//sub iac/. The experimental results demonstrated the humidity effect for magnetic characteristics of the powder type magnetic wood.},
  keywords={Humidity;Powders;Magnetic devices;Heating;Permeability;Resins;Magnetic analysis;Physics},
  doi={10.1109/INTMAG.2003.1230360},
  ISSN={},
  month={March},}@INPROCEEDINGS{6978467,
  author={Durocher, David B. and Loucks, David},
  booktitle={2014 IEEE Industry Application Society Annual Meeting}, 
  title={Infrared windows applied in switchgear assemblies: Taking another look}, 
  year={2014},
  volume={},
  number={},
  pages={1-6},
  abstract={Maintenance of electrical power distribution assemblies applied in industry has been critical in assuring facility uptime and reliability. One important metric in assuring reliability is electrical terminations of energized conductors. During normal energized service, terminations both at conductor bus joints and at cable terminations are subject over time to thermal expansion and contraction, ultimately resulting in loosened connections and excessive heat. Deteriorating terminations left unchecked will ultimately fail, resulting in electrical hazards for personnel and also costly loss of production. Infrared (IR) inspection has proved to be an excellent maintenance method used to identifying problems with loose electrical terminations. However, the design of Internal Arc Classified (IAC) switchgear assemblies to address arc-flash concerns has changed assembly designs that now limiting line of sight access necessary for IR inspection via windows. This paper will discuss global Standards, how they affect switchgear designs and application of IR windows, then present some alternative technologies that in some applications may be more suitable.},
  keywords={Power distribution;Switchgear;Temperature sensors;Conductors;Infrared detectors;Thermal analysis;Cameras;Thermal Imaging;Infrared Camera;IR Windows;Arc-Resistant Switchgear;Thermal Sensors},
  doi={10.1109/IAS.2014.6978467},
  ISSN={0197-2618},
  month={Oct},}@INPROCEEDINGS{1678262,
  author={Yuming Jiang and Nevin, A. and Emstad, P.J.},
  booktitle={2006 2nd Conference on Next Generation Internet Design and Engineering, 2006. NGI '06.}, 
  title={Implicit admission control for a differentiated services network}, 
  year={2006},
  volume={},
  number={},
  pages={8 pp.-365},
  abstract={Admission control is a crucial network element for providing quality of service (QoS) guarantees in the Internet. In this paper, we propose a novel framework approach, called implicit admission control (iAC), for admission control in a differentiated services (DiffServ) network. In the iAC approach, admission control is performed distributedly at routers. No signaling is needed for exchanging service and traffic information between flows and routers. The service requirement and some coarse traffic information of a flow are carried by packets of the flow. Specifically, the DiffServ field is utilized for this purpose. At each router, admission control for the flow is performed when its first packet is detected. The admission test is based on the service requirement and traffic information carried by the DiffServ field of the packet, as well as the local traffic and resource information. In addition, to simplify admission control, two flow aggregation methods are adopted at each router. One is link-based fair aggregation (LBFA) for the deterministic expedited forwarding (EF) service. The other is dynamic priority based flow aggregation (DPFA) for the statistical assured forwarding (AF) service. Analytical results show that with these flow aggregation approaches, a newly admitted flow does not adversely affect QoS guarantees of existing flows. Consequently, admission test is needed only for the new flow.},
  keywords={Admission control;Diffserv networks;Quality of service;Communication system traffic control;Protocols;Resource management;Testing;Intserv networks;Scalability;Bandwidth},
  doi={10.1109/NGI.2006.1678262},
  ISSN={},
  month={April},}@ARTICLE{10752334,
  author={Zhang, Jiahui and Wen, Qiuqiu},
  journal={Journal of Systems Engineering and Electronics}, 
  title={Closed-Form Guidance Law for Velocity Maximization with Impact Angle Constraint}, 
  year={2024},
  volume={35},
  number={5},
  pages={1295-1303},
  abstract={Final velocity and impact angle are critical to missile guidance. Computationally efficient guidance law with comprehensive consideration of the two performance merits is challenging yet remains less addressed. Therefore, this paper seeks to solve a type of optimal control problem that maximizes final velocity subject to equality point constraint of impact angle constraint. It is proved that the crude problem of maximizing final velocity is equivalent to minimizing a quadratic-form cost of curvature. The closed-form guidance law is henceforth derived using optimal control theory. The derived analytical guidance law coincides with the widely-used optimal guidance law with impact angle constraint (OGL-IAC) with a set of navigation parameters of two and six. On this basis, the optimal emission angle is determined to further increase the final velocity. The derived optimal value depends solely on the initial line-of-sight angle and impact angle constraint, and thus practical for real-world applications. The proposed guidance law is validated by numerical simulation. The results show that the OGL-IAC is superior to the benchmark guidance laws both in terms of final velocity and missing distance.},
  keywords={Costs;Navigation;Optimal control;Line-of-sight propagation;Benchmark testing;Numerical simulation;Systems engineering and theory;Real-time systems;Missile guidance;Computational efficiency;missile;guidance law;proportional-navigation guidance;impact angle},
  doi={10.23919/JSEE.2024.000078},
  ISSN={1004-4132},
  month={October},}@INPROCEEDINGS{8516578,
  author={Bacu, Victor and Sabou, Adrian and Stefanut, Teodor and Gorgan., Dorian and Vaduvescu, Ovidiu},
  booktitle={2018 IEEE 14th International Conference on Intelligent Computer Communication and Processing (ICCP)}, 
  title={NEARBY Platform for Detecting Asteroids in Astronomical Images Using Cloud-based Containerized Applications}, 
  year={2018},
  volume={},
  number={},
  pages={371-376},
  abstract={The continuing monitoring and surveying of the nearby space to detect Near Earth Objects (NEOs) and Near Earth Asteroids (NEAs) are essential because of the threats that this kind of objects impose on the future of our planet. We need more computational resources and advanced algorithms to deal with the exponential growth of the digital cameras' performances and to be able to process (in near real-time) data coming from large surveys. This paper presents a software platform called NEARBY that supports automated detection of moving sources (asteroids) among stars from astronomical images. The detection procedure is based on the classic “blink” detection and, after that, the system supports visual analysis techniques to validate the moving sources, assisted by static and dynamical presentations.},
  keywords={Telescopes;Databases;Pipelines;Trajectory;Earth;Charge coupled devices},
  doi={10.1109/ICCP.2018.8516578},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9825935,
  author={Kunz, Immanuel and Schneider, Angelika and Banse, Christian},
  booktitle={2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)}, 
  title={A Continuous Risk Assessment Methodology for Cloud Infrastructures}, 
  year={2022},
  volume={},
  number={},
  pages={1042-1051},
  abstract={Cloud systems are dynamic environments which make it difficult to keep track of security risks that resources are exposed to. Traditionally, risk assessment is conducted for individual assets to evaluate existing threats-their results, however, are quickly outdated in such a dynamic environment. In this paper, we propose an adaptation of the traditional risk assessment methodology for cloud infrastructures which loosely couples manual, in-depth analyses with continuous, automatic application of their results. These two parts are linked by a novel threat profile definition that allows to reusably describe configuration weaknesses based on properties that are common across assets and cloud providers. This way, threats can be identified automatically for all resources that exhibit the same properties, including new and modified ones. We also present a prototype implementation which automatically evaluates an infrastructure as code template of a cloud system against a set of threat profiles, and we evaluate its performance. Our methodology not only enables organizations to reuse their threat analysis results, but also to collaborate on their development, e.g. with the public community. To that end, we propose an initial open-source repository of threat profiles.},
  keywords={Cloud computing;Visualization;Codes;Prototypes;Collaboration;Organizations;Manuals;Semi-Automated Risk Assessment;Semi-Automated Threat Modeling;Cloud Discovery;Cloud Security;Risk Assessment Tool},
  doi={10.1109/CCGrid54584.2022.00127},
  ISSN={},
  month={May},}@ARTICLE{8858239,
  author={Molaeinezhad, A and Zhu, L and Falcón-Barroso, J and van de Ven, G and Méndez-Abreu, J and Balcells, M and Aguerri, J A L and Vazdekis, A and Khosroshahi, H G and Peletier, R F},
  journal={Monthly Notices of the Royal Astronomical Society}, 
  title={NGC 7457: evidence for merger-driven cylindrical rotation in disc galaxies}, 
  year={2019},
  volume={488},
  number={1},
  pages={1012-1025},
  abstract={We construct Schwarzschild orbit-based models of NGC 7457, known as a peculiar low-mass lenticular galaxy. Our best-fitting model successfully retrieves most of the unusual kinematics behaviours of this galaxy, in which, the orbital distribution of stars is dominated by warm and hot orbits. The reconstructed surface brightness of the hot component matches fairly well the photometric bulge and the reconstructed LOSVD map of this component shows clear rotation around the major photometric axis of the galaxy. In the absence of a dominant cold component, the outer part of our model is dominated by warm orbits, representing an exponential thick disc. Our orbital analysis also confirms the existence of a counter-rotating orbital substructure in the very centre, reported in previous observational studies. By comparing our model with a variety of simulation studies, and considering the stellar kinematics and populations properties of this galaxy, we suggest that the thick disc is most likely a dynamically heated structure, formed through the interactions and accretion of satellite(s) with near-polar initial inclination. We also suggest a merger-driven process as the most plausible scenario to explain the observed and dynamically modelled properties of the bulge of NGC 7457. We conclude that both the high level of cylindrical rotation and unusually low velocity dispersion reported for the NGC 7457 have most likely external origins. Therefore, NGC 7457 could be considered as a candidate for merger-driven cylindrical rotation in the absence of a strong bar in disc galaxies.},
  keywords={galaxies: abundances;galaxies: evolution;galaxies: formation;galaxies: individual: (NGC 7457);galaxies: kinematics and dynamics;galaxies: stellar content},
  doi={10.1093/mnras/stz1776},
  ISSN={1365-2966},
  month={June},}@INPROCEEDINGS{4449359,
  author={Fabre, J. Paquin and Dennis, Steven M.},
  booktitle={OCEANS 2007}, 
  title={Characterization of the Variability of the Ocean Acoustic Environment}, 
  year={2007},
  volume={},
  number={},
  pages={1-3},
  abstract={Great strides have been made in the ability to model and predict oceanography (temperature, salinity, currents, etc.) accurately and in a timely manner. There exists a need to characterize the variability of the ocean based on its acoustic propagation characteristics. That is, how and where does the evolution or variability of the environment significantly impact the acoustic propagation characteristics of an oceanographic waveguide? Due to the complexity of the acoustic propagation in a waveguide, variability in the oceanography is not always indicative of the variability in the acoustic propagation. For example, a significant change in temperature in an area may not significantly impact the acoustic propagation in the area. There is also a limit on the ability to sense the oceanography. Sensor availability and coverage, as well as time put constraints on efforts to measure a large ocean area. The work presented here shows that analysis of acoustic variability computed using predicted oceanography over an area provides a better insight into the oceanographic variability for the purposes of sensor placement. Acoustic coverage integrated over many source depths is a representation of how energy travels in a waveguide and can therefore provide a good estimate of the propagation properties of the environment over a large area. A method of estimating the acoustic variability over a period of time using this integrated acoustic coverage (IAC) computation, which is derived from estimated transmission loss is presented here. Two and three dimensional oceanographic model predictions of temperature and salinity (converted to sound velocity) over a time period are used as inputs to the acoustic model. The parabolic equation Range-dependent Acoustic Model (RAM, [Collins, M. D., "Applications and time-domain solution of higher-order parabolic equations in underwater acoustics," J. Acoust. Soc. Am, 86 (3), 1097-1102, 1989]) is used to compute the complex pressure and transmission loss (TL) for calculation of a range independent IAC. This quantity is computed for each time period and variability over time is computed for the ocean volume (longitude, latitude and depth). The RAM is then run for range dependent (RD) environments across user-selected, highly variable tracks for estimation of (range dependent) IAC variance. The acoustic computation is currently done over the whole area in a range independent mode to save computation time. The capability to compute along selected tracks adds a necessary RD evaluation of the areas with the most variability. Comparisons of the range independent (RI) IAC over the volume and RD over the highly variable track show that the use of the range independent IAC parameter is valid for acoustic variance estimation over an area. This work shows that the integrated range independent acoustic variability provides a better estimate of variability than does the oceanographic variability, for the purposes of sensor placement. As work continues, more capability can be added to include functionality such as range dependence.},
  keywords={Acoustic propagation;Predictive models;Ocean temperature;Acoustic waveguides;Acoustic sensors;Underwater acoustics;Propagation losses;Equations;Temperature sensors;Availability},
  doi={10.1109/OCEANS.2007.4449359},
  ISSN={0197-7385},
  month={Sep.},}@INPROCEEDINGS{5977739,
  author={Jiang, Z. and Petit, G. and Harmegnies, A. and Lewandowski, W. and Tisserand, L.},
  booktitle={2011 Joint Conference of the IEEE International Frequency Control and the European Frequency and Time Forum (FCS) Proceedings}, 
  title={Comparison of the GLONASS orbit products for UTC time transfer}, 
  year={2011},
  volume={},
  number={},
  pages={1-6},
  abstract={Accurate GNSS (Global Navigation Satellite System) time transfer needs accurate satellite orbit information. Since Nov. 2009, the GLONASS time transfer is introduced in UTC generation. The precise and timely GLONASS orbit information is indispensable for Circular T computation. In this paper, we compare the GLONASS orbits produced by different analysis centers. We study the differences of the products, their influences on the common view time transfers and the delays of the availability. The products to investigate are the rapid and final sp3 ephemeredes produced by ESA (Europe Space Agency) and IAC (Information-Analytical Center). IAC belongs to Russia Federal Space Agency. Its primary goal is to analyze the information on the satellite navigation based on the global systems, mainly the GLONASS. The delay of the IAC sp3 rapid products is 24–28 hours. This satisfies the rhythm of the BIPM monthly Circular T computation, of which the deadline of data collection is the 5th of every month. Since Nov. 2010, the BIPM started to use the IAC ephemeredes to compute the GLONASS satellite orbits for UTC time transfer. At present the IAC product is the most suitable for the UTC GLONASS time link computations.},
  keywords={Satellites;Clocks;Orbits;Global Positioning System;Delay;Global Navigation Satellite Systems;Noise},
  doi={10.1109/FCS.2011.5977739},
  ISSN={2327-1949},
  month={May},}@INPROCEEDINGS{10978928,
  author={Bucaioni, Alessio and Di Salle, Amleto and Iovino, Ludovico and Pelliccione, Patrizio and Raimondi, Franco},
  booktitle={2025 IEEE 22nd International Conference on Software Architecture (ICSA)}, 
  title={Architecture as Code}, 
  year={2025},
  volume={},
  number={},
  pages={187-198},
  abstract={After more than thirty-five years of research and development in software architecture, several fundamental challenges remain unsolved. First, despite the importance of having a well-defined architecture description aligned with the system, inconsistencies and misalignments are still prevalent. Second, although numerous languages exist to describe architectures, none have achieved widespread use or recognition as a de facto standard. Third, while architecture is dynamic and evolving, with architectural decisions often made by non-architect stakeholders, there are no universally accepted methodologies to capture emergent aspects and incorporate them into the architecture.In this paper, we explore the emerging concept of architecture as code. Inspired by the success of infrastructure as code, which enables infrastructure management in a codified, automated, and repeatable manner, architecture as code aims to bring similar benefits to software architecture. To the best of our knowledge, this is the first scientific paper to study this concept in depth within the context of software architecture, providing a comprehensive description and analysis of its characteristics. We also investigate how architecture as code is implemented and applied in practice.},
  keywords={Codes;Software architecture;Computer architecture;Stakeholders;Standards;Research and development;Architecture as code;inconsistencies;architecture drift;architectural debt},
  doi={10.1109/ICSA65012.2025.00027},
  ISSN={2835-7043},
  month={March},}@INPROCEEDINGS{8272605,
  author={Hiray, Sushant and Duppada, Venkatesh},
  booktitle={2017 Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)}, 
  title={Agree to disagree: Improving disagreement detection with dual GRUs}, 
  year={2017},
  volume={},
  number={},
  pages={147-152},
  abstract={This paper presents models for detecting agreement/disagreement in online discussions. In this work we show that by using a Siamese inspired architecture to encode the discussions, we no longer need to rely on hand-crafted features to exploit the meta thread structure. We evaluate our model on existing online discussion corpora ABCD, IAC and AWTP. Experimental results on ABCD dataset show that by fusing lexical and word embedding features, our model achieves the state of the art performance of 0.804 average F1 score. We also show that the model trained on ABCD dataset performs competitively on relatively smaller annotated datasets (IAC and AWTP).},
  keywords={Feature extraction;Task analysis;Internet;Computational modeling;Computer architecture;Tagging;Twitter},
  doi={10.1109/ACIIW.2017.8272605},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10326683,
  author={Du, Xiangyu and Qin, Tong and Tang, Yunqing and Liu, Lei and Wang, Bo and Fan, Huijin},
  booktitle={2023 35th Chinese Control and Decision Conference (CCDC)}, 
  title={Robust adaptive dynamic programming based attitude tracking control for hypersonic vehicle}, 
  year={2023},
  volume={},
  number={},
  pages={5162-5167},
  abstract={In this paper, a robust adaptive dynamic programming (RADP) control approach based on a novel identifier-actor-critic (IAC) framework for the hypersonic vehicle (HSV) attitude tracking system with actuator saturation and disturbances is proposed. The control law is generated by the combination of the desired control law and the optimal feedback control law to track the attitude reference command. To achieve the optimal feedback control, an iterative scheme based on the IAC framework is implemented. An identifier network is constructed for approximating the attitude dynamics. The actor-critic networks are designed to approximate control policy and performance function. In addition, a nonquadratic performance function effectively solves the input-constrained problem, and the online learning controller effectively suppresses parametric uncertainties and external disturbances. Finally, the comparative simulations verify the effectiveness of the proposed controller for the HSV attitude tracking system with parametric uncertainties and external disturbances.},
  keywords={Uncertainty;Attitude control;Heuristic algorithms;Simulation;Stability analysis;Feedback control;Steady-state;Hypersonic vehicle;Attitude tracking;Robust adaptive dynamic programming;Identifier-actor-critic framework},
  doi={10.1109/CCDC58219.2023.10326683},
  ISSN={1948-9447},
  month={May},}@INPROCEEDINGS{8806677,
  author={Vidal, Allan and Gomes, Pedro Henrique and Santos, Mateus},
  booktitle={2019 IEEE Conference on Network Softwarization (NetSoft)}, 
  title={Reorchestration: a Reactive Orchestration Architecture}, 
  year={2019},
  volume={},
  number={},
  pages={498-505},
  abstract={Orchestration is crucial to address the growing complexity of IT, cloud and telecom services. Orchestrators enable service deployment, but continuous operation is given second-class status. Most orchestrators use static workflows, which may fail, misbehave or be insufficient, leaving services in an undesirable state. We propose the Reorchestration architecture for orchestration without workflows, which marries functional-inspired state management with an infrastructure-as-code approach. It enables changes to be applied to existing services, while providing a high-level framework for expressing how these changes should happen. We also share our first prototype, in the hope that it can foster discussions on new software architectures for orchestrators and closed-loop automation.},
  keywords={Tools;Cloud computing;Automation;Complexity theory;Computer architecture;Maintenance engineering;Task analysis;Orchestration;day-2 operations;workflows;closed-loop automation},
  doi={10.1109/NETSOFT.2019.8806677},
  ISSN={},
  month={June},}@ARTICLE{10876008,
  author={Raji, Ayoub and Caporale, Danilo and Gatti, Francesco and Giove, Andrea and Verucchi, Micaela and Malatesta, Davide and Musiu, Nicola and Toschi, Alessandro and Popitanu, Silviu Roberto and Bagni, Fabio and Bosi, Massimiliano and Liniger, Alexander and Bertogna, Marko and Morra, Daniele and Amerotti, Francesco and Bartoli, Luca and Martello, Federico and Porta, Riccardo},
  journal={Field Robotics}, 
  title={er.autopilot 1.0: The Full Autonomous Stack for Oval Racing at High Speeds}, 
  year={2024},
  volume={4},
  number={},
  pages={99-137},
  abstract={The Indy Autonomous Challenge (IAC) brought together for the first time in history nine autonomous racing teams competing at an unprecedented speed and in a head-to-head scenario, using independently developed software on open-wheel race cars. This paper presents the complete software architecture used by the team TII EuroRacing (TII-ER), covering all the modules needed to avoid static obstacles, perform active overtakes, and reach speeds above 75m/s (270km/h). In addition to the most common modules related to perception, planning, and control, we discuss the approaches used for vehicle dynamics modeling, simulation, telemetry, and safety. Overall results and the performance of each module are described, as well as the lessons learned during the first two events of the competition on oval tracks, where the team placed second and third, respectively.},
  keywords={Automobiles;Cameras;Laser radar;Autonomous vehicles;Location awareness;Safety;Planning;Vehicle dynamics;Testing;Sports;Motion planning;Environmental monitoring;autonomous racing;control;motion planning;perception;extreme environments},
  doi={10.55417/fr.2024004},
  ISSN={2771-3989},
  month={Jan},}@INPROCEEDINGS{6669116,
  author={Pendharkar, I.},
  booktitle={2013 European Control Conference (ECC)}, 
  title={Resonance stability in electrical railway systems - A dissipativity approach}, 
  year={2013},
  volume={},
  number={},
  pages={4574-4579},
  abstract={We propose a theory for stability analysis of railway systems based on energy exchange principles between the infrastructure and rolling stock. We show that if the rolling stock and infrastructure is dissipative with respect to specially constructed power functions (more general than voltage× current) stability is guaranteed. We thereby provide a proof of the Input Admittance Criterion (IAC) - a widely used empirical criterion in the railway industry - as special case of our results. Application of the theory is demonstrated with an example from a metro train system.},
  keywords={Vehicles;Stability criteria;Harmonic analysis;Limiting;Rail transportation;Asymptotic stability},
  doi={10.23919/ECC.2013.6669116},
  ISSN={},
  month={July},}@INPROCEEDINGS{270450,
  author={Watson, G.A. and Blair, W.D.},
  booktitle={The Record of the 1993 IEEE National Radar Conference}, 
  title={Interacting acceleration compensation algorithm for tracking maneuvering targets}, 
  year={1993},
  volume={},
  number={},
  pages={281-285},
  abstract={By testing the bias vector as a target acceleration, the two-stage Kalman estimator can be used for tracking maneuvering targets. The first stage contains a constant velocity motion model and produces the target position and velocity estimates, while the second stage provides estimates of the target acceleration. When a maneuver is detected, the acceleration estimate of the second stage is used to correct the estimates of the first stage. In order to overcome the requirement for explicit maneuver detection in the two-stage estimator, the interacting acceleration compensation (IAC) algorithm is proposed. In the IAC algorithm, the two-stage estimator is viewed as having two acceleration models. The first model corresponds to the zero acceleration of the constant velocity model, while the second model is a constant acceleration model. Simulation results indicate that the tracking performance of the IAC algorithm approaches that of an interacting multiple model (IMM) algorithm with a constant velocity model and constant acceleration model, while requiring approximately 50% of the computations of the IMM algorithm.<>},
  keywords={Acceleration;Target tracking;Motion estimation;Computational modeling;Delay;Surface treatment;Kalman filters;State estimation;Real time systems;Stochastic processes},
  doi={10.1109/NRC.1993.270450},
  ISSN={},
  month={April},}@INPROCEEDINGS{8120315,
  author={Fujii, Norihiro and Koike, Nobuhiko},
  booktitle={2017 International Conference on Cyberworlds (CW)}, 
  title={IoT Remote Group Experiments in the Cyber Laboratory: A FPGA-based Remote Laboratory in the Hybrid Cloud}, 
  year={2017},
  volume={},
  number={},
  pages={162-165},
  abstract={In accordance with the resent advancement in Internet of Things (IoT), the needs for IoT experiment platform have been ever increasing. IoT system consists of various technologies such as networking, sensor controller, edge-side computing, server-side big data collections, analysis and their visualizations. An experimental environment that can handle the development and experiments of such an IoT system become important. In the IoT system, a highly flexible system structure for applications using Field Programmable Gate Array (FPGA) is required. The authors propose the Remote Laboratory System for handling IoT experiments in the Cyber Laboratory, which is an educational FPGA-based remote laboratory for under-graduate university students. It enables not only to use available board-level small computers but also to use FPGA boards for prototyping IoT edges. It can also organize the IoT cloud-server side programs in the hybrid cloud. The FPGA based edge-side computing approach can have much more freedom and flexibility to implement various sensor controls those can be customized for specific IoT applications. The use of free micro-processor IP-core and re-organizing the available FPGA CAD design platform allow us to reduce the burden of design and implementation efforts for the construction of new Cyber Laboratory to accommodate IoT designs and experiments. It also contributed to reduce the students' amount of efforts to conduct their own IoT design and experiments, where students are required to have various skills in Information Technologies (IT): hardware design, edge-side computing, server-side computing, networking and infrastructure construction. The use of the Docker container/Swarm and the Docker File contributed to construct their own IoT experiment platforms for every student automatically, in the form of "Infrastructure as Code". Furthermore, these separately designed IoT experiment platforms can be combined to conduct a group of group experiment simultaneously. The paper showed the Cyber Laboratory's usefulness and applicability for IoT kinds of Remote experiments.},
  keywords={Field programmable gate arrays;Cloud computing;Servers;Containers;Remote laboratories;Computers;Hardware;Remote laboratory;FPGA hardware design laboratory;IoT System design laboratory;Group-Group experiment;Hybrid cloud;Docker container},
  doi={10.1109/CW.2017.29},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10645405,
  author={Ni, Hao and Lai, Ping and Li, Yuke and Zeng, Pengpeng and Zhang, Haonan and Song, Jingkuan},
  booktitle={2024 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)}, 
  title={Pedestrian Attributes Recognition for UAV-Human}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Pedestrian Attributes Recognition (PAR) aims to predict a set of attributes from a predefined list to describe the characteristics of a pedestrian. This paper addresses the challenge of attribute recognition in the UAV-Human dataset. In this dataset, there are two key factors constraining attribute recognition performance. Firstly, there is class imbalance in each attribute, and the distribution of classes differs significantly between the testing and training sets. Secondly, some attributes cannot be observed from the current perspective of the images. For example, we cannot observe the attribute of the backpack from a frontal image. To tackle these issues, this paper proposes Class Imbalance Correction Strategy (CIC) and ID-based Attribute Correction Strategy (IAC) to enhance attribute recognition performance. CIC balances training classes using undersampling and oversampling to match the class distribution in the testing set. IAC corrects misidentified attributes by leveraging person re-identification (ReID) techniques to obtain images of the same pedestrian from different viewpoints. Our approach significantly improves the accuracy of attribute recognition over the baseline method. The code is publicly available at https://github.com/laiping-lp/MMVRAC-Attribute-Recognition.},
  keywords={Training;Visualization;Pedestrians;Accuracy;Conferences;Clothing;Transformers;Attribute-recognition;class imbalance;UAV-Human},
  doi={10.1109/ICMEW63481.2024.10645405},
  ISSN={2995-1429},
  month={July},}@INPROCEEDINGS{6596260,
  author={Kowsar, Y. and Afgan, E.},
  booktitle={2013 36th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)}, 
  title={Support for data-intensive computing with CloudMan}, 
  year={2013},
  volume={},
  number={},
  pages={243-248},
  abstract={Infrastructure-as-a-Service (IaaS) compute infrastructure model has showcased its ability to transform how access to compute resources is realized; it delivered on the notion of Infrastructure-as-Code and enabled a new wave of compute adaptability. In previous work we have been developing CloudMan (usecloudman.org) as a versatile solution for enabling and managing compute clusters in cloud environments via a simple web interface or an API. However, CloudMan only supported batch processing workloads. As the magnitude of the data produced and processed in digital form grows, the need to support big data applications in clusters in the cloud becomes more evident. In this paper, we have extended the batch processing capability of CloudMan and presenteda novel architecture for supporting big data analysis workloads in cluster-in-the-cloud environment. We also implemented the details through CloudMan using established big data platforms.},
  keywords={Cloud computing;Information management;Data handling;Data storage systems;Computer architecture;Bioinformatics;Engines},
  doi={},
  ISSN={},
  month={May},}@ARTICLE{10464367,
  author={Zhang, Jiaqing and Lei, Jie and Xie, Weiying and Yang, Geng and Li, Daixun and Li, Yunsong},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Multimodal Informative ViT: Information Aggregation and Distribution for Hyperspectral and LiDAR Classification}, 
  year={2024},
  volume={34},
  number={8},
  pages={7643-7656},
  abstract={In multimodal land cover classification (MLCC), a common challenge is the redundancy in data distribution, where task-irrelevant information from multiple modalities can hinder the effective integration of their unique features. To tackle this, we introduce the Multimodal Informative Vit (MIVit), a system with an innovative information aggregate-distributing mechanism. This approach redefines redundancy levels and integrates performance-aware elements into the fused representation, facilitating the learning of semantics in both forward and backward directions. MIVit stands out by significantly reducing redundancy in the empirical distribution of each modality’s separate and fused features. It employs oriented attention fusion (OAF) for extracting shallow local shape features across modalities in horizontal and vertical dimensions, and a Transformer feature extractor for extracting deep global features through long-range attention. We also propose an information aggregation constraint (IAC) based on mutual information, designed to remove redundant information and preserve complementary information within embedded features. Additionally, the information distribution flow (IDF) in MIVit enhances performance-awareness by distributing global classification information across different modalities’ feature maps. This architecture also addresses missing modality challenges with lightweight independent modality classifiers, reducing the computational load typically associated with Transformers. Our results show that MIVit’s bidirectional aggregate-distributing mechanism between modalities is highly effective, achieving an average overall accuracy of 95.56% across three multimodal datasets. This performance surpasses current state-of-the-art methods in MLCC. The code for MIVit is accessible at https://github.com/icey-zhang/MIViT.},
  keywords={Feature extraction;Task analysis;Transformers;Mutual information;Laser radar;Redundancy;Data mining;Hyperspectral image;multimodal fusion;land cover classification;mutual information;self-distillation},
  doi={10.1109/TCSVT.2024.3375511},
  ISSN={1558-2205},
  month={Aug},}@INPROCEEDINGS{9605035,
  author={Uthayakumar, Thakshanth and Mei, Jie and Wang, Xianbin},
  booktitle={2021 IEEE 4th 5G World Forum (5GWF)}, 
  title={Multi-Dimensional Modulation for Data Rate Maximization in Non-Orthogonal Spatial-Time-Frequency Domains}, 
  year={2021},
  volume={},
  number={},
  pages={76-81},
  abstract={Loss of orthogonality among radio resource blocks in different domains introduces additional interference such as inter carrier interference (ICI) in frequency domain, and inter symbol interference (ISI) in time domain, and inter antenna correlation (IAC) in spatial domain. Such interference due to imperfect time/frequency synchronization and spatial separation are usually tolerated in LTE, and 5G communication systems. However, with the ongoing wireless evolution towards beyond 5G and 6G networks that operate in mmWave bands with significantly higher data rates, these interference will become more severe, and deteriorate the system performance significantly. Based on these observations, this paper is motivated to maximize the communication data rate under non-orthogonality conditions that occur in spatial, time and frequency domains. We propose a novel multi-dimensional modulation (MDM) scheme to achieve our objective. The simulation results demonstrated that our proposed MDM scheme achieves maximized data rate in spatial-time-frequency domains and it outperforms the state-of-art spatially multiplexed MIMO-OFDM system. We also show that the proposed MDM scheme is highly advantageous for mmWave and massive MIMO applications.},
  keywords={Wireless communication;5G mobile communication;Frequency-domain analysis;Simulation;System performance;Modulation;Interference;5G;data rate;multi-dimensional modulation;non-orthogonality},
  doi={10.1109/5GWF52925.2021.00021},
  ISSN={},
  month={Oct},}@ARTICLE{8733800,
  author={Pang, Bin and Tang, Guiji and Tian, Tian},
  journal={IEEE Access}, 
  title={Rolling Bearing Fault Diagnosis Based on SVDP-Based Kurtogram and Iterative Autocorrelation of Teager Energy Operator}, 
  year={2019},
  volume={7},
  number={},
  pages={77222-77237},
  abstract={The emergence of periodic impacts in the vibration signal is considered as an essential sign of rolling bearing faults. Therefore, how to distinguish the periodic impact component from the interference components (e.g., the harmonics and noise) in the raw vibration signal is critical for detecting bearing faults. The kurtogram technique plays an essential role in the automatic selection of sub-component signals containing fault information. However, two significant shortcomings reduce its ability to detect early weak transients: 1) the decomposition accuracy of the filters used in kurtogram, i.e., short-time Fourier transform (STFT) and binary filter banks, is deficiency and 2) the detection ability of kurtosis to cyclic impact is insufficient. A singular value decomposition packet (SVDP)-based kurtogram is proposed to improve the kurtogram technique. More specifically, a novel parameter-less signal decomposition algorithm, termed SVDP, is employed as the filter for sub-components extraction. The L-kurtosis indicator is then introduced to replace the kurtosis indicator to select the optimal sub-component from the SVDP processing results. Moreover, a fault signature highlighting technique named iterative autocorrelation of Teager energy operator (TEO-IAC) is presented, and the TEO-IAC spectrum is adopted to replace the Hilbert envelope spectrum to detect the fault characteristic frequencies of the optimal sub-component to determine the fault types of bearings. Finally, the presented fault diagnosis framework based on the SVDP-based kurtogram and TEO-IAC is compared with the original kurtogram, improved kurtogram and autogram in simulated and experimental signals analysis, which demonstrates its validity and superiority for extracting weak fault features of bearings.},
  keywords={Filter banks;Fault diagnosis;Power harmonic filters;Matrix decomposition;Rolling bearings;Resonant frequency;Signal resolution;SVDP-based kurtogram;iterative autocorrelation;Teager energy operator;rolling bearing;fault diagnosis},
  doi={10.1109/ACCESS.2019.2921778},
  ISSN={2169-3536},
  month={},}@ARTICLE{10876003,
  author={Saba, Andrew and Adetunji, Aderotimi and Johnson, Adam and Kothari, Aadi and Sivaprakasam, Matthew and Spisak, Joshua and Bharatia, Prem and Chauhan, Arjun and Duff, Brendan and Gasparro, Noah and King, Charles and Larkin, Ryan and Mao, Brian and Nye, Micah and Parashar, Anjali and Attias, Joseph and Balciunas, Aurimas and Brown, Austin and Chang, Chris and Gao, Ming and Heredia, Cindy and Keats, Andrew and Lavariega, Jose and Muckelroy, William and Slavescu, Andre and Stathas, Nickolas and Suvarna, Nayana and Zhang, Chuan Tian and Scherer, Sebastian and Ramanan, Deva},
  journal={Field Robotics}, 
  title={Fast and Modular Autonomy Software for Autonomous Racing Vehicles}, 
  year={2024},
  volume={4},
  number={},
  pages={1-45},
  abstract={Autonomous motorsports aim to replicate the human race-car driver with software and sensors. As in traditional motorsports, Autonomous Racing Vehicles (ARVs) are pushed to their handling limits in multiagent scenarios at extremely high (≥150mph) speeds. This Operational Design Domain (ODD) presents unique challenges across the autonomy stack. The Indy Autonomous Challenge (IAC) is an international competition aiming to advance autonomous vehicle development through ARV competitions. While far from challenging what a human race-car driver can do, the IAC is pushing the state of the art by facilitating full-sized ARV competitions. This paper details the MIT-Pitt-RW Team's approach to autonomous racing in the IAC. In this work, we present our modular and fast approach to agent detection, motion planning and controls to create an autonomy stack. We also provide analysis of the performance of the software stack in single and multiagent scenarios for rapid deployment in a fast-paced competition environment. We also cover what did and did not work when deployed on a physical system (the Dallara AV-21 platform) and potential improvements to address these shortcomings. Finally, we convey lessons learned and discuss limitations and future directions for improvement.},
  keywords={Sensors;Vehicle dynamics;Software packages;Navigation;Roads;Autonomous vehicles;Aerodynamics;Uncertainty;Trajectory;Computer vision;Sports;computer vision;navigation;perception;autonomous racing;control},
  doi={10.55417/fr.2024001},
  ISSN={2771-3989},
  month={Jan},}@ARTICLE{11134430,
  author={Fatemimoghadam, A. and Amezyane, I. and Viana, C. and Iyer, L.V. and Kar, N. C.},
  journal={IEEE Journal of Emerging and Selected Topics in Power Electronics}, 
  title={Decoupled Current Control of Grid-Tied VSIs Using Real-Time Impedance Angle Compensation}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={This paper proposes an impedance angle compensation (IAC)-based current control strategy for voltage source inverters (VSIs), to improve dynamic performance and mitigate cross-axis coupling under varying interface impedance, a common challenge in grid-tied renewable energy systems. Unlike traditional methods that rely on explicitly tuned feed-forward, feed-back, or complex compensators, the proposed approach introduces a real-time transformation based on the interface impedance angle. This transformation normalizes the plant transfer function, enabling conventional PI controllers to maintain high current regulation accuracy with minimal tuning. Experimental results demonstrate that the IAC method reduces overshoot to less than 0.1% and achieves consistent settling times of approximately 17-19 ms, even under ±40% impedance variation. Comparative analysis confirms superior transient response and decoupling performance over existing techniques. Additionally, by leveraging the predictability of the terminal voltage angle, the method ensures direct control trajectories and strong adaptability to real-world operating conditions. With low computational complexity and operational consistency, the IAC strategy presents a practical and scalable solution for grid-tied inverters and high-speed motor drives. This method is designed for single-phase grid-tied inverters and verified through simulation and experimental implementation.},
  keywords={Impedance;PI control;Vectors;Voltage control;Current control;Current measurement;Couplings;Voltage measurement;Renewable energy sources;Real-time systems;Current controller;decoupled controller;impedance angle compensation;voltage source inverter},
  doi={10.1109/JESTPE.2025.3601822},
  ISSN={2168-6785},
  month={},}@ARTICLE{8176790,
  author={Harrison, D. L. and Rubiño-Martin, J. A. and Melhuish, S. J. and Watson, R. A. and Davies, R. D. and Rebolo, R. and Davis, R. J. and Gutiérrez, C. M. and Macias-Perez, J. F.},
  journal={Monthly Notices of the Royal Astronomical Society}, 
  title={A measurement at the first acoustic peak of the cosmic microwave background with the 33-GHz interferometer}, 
  year={2000},
  volume={316},
  number={2},
  pages={L24-L28},
  abstract={This paper presents the results from the Jodrell Bank-Instituto de Astrofisicia de Canarias (IAC) two-element 33-GHz interferometer operated with an element separation of 32.9 wavelengths and hence sensitive to 1°-scale structure on the sky. The level of cosmic microwave background (CMB) fluctuations, assuming a flat CMB spatial power spectrum over the range of multipoles ℓ=208±18, was found using a likelihood analysis to be $\Delta T_{\ell}=63^{+7}_{-6}\ \mu{\mathrm K}$ at the 68 per cent confidence level, after the subtraction of the contribution of monitored point sources. Other possible foreground contributions have been assessed and are expected to have negligible impact on this result.},
  keywords={instrumentation: interferometers;cosmic microwave background;cosmology: observations;large-scale structure of Universe},
  doi={10.1046/j.1365-8711.2000.03762.x},
  ISSN={1365-2966},
  month={Aug},}@INPROCEEDINGS{656757,
  author={Woodruff, M.G. and Jones, T.W. and Dowd, J. and Roop, J.M. and Muller, M.R.},
  booktitle={IECEC-97 Proceedings of the Thirty-Second Intersociety Energy Conversion Engineering Conference (Cat. No.97CH6203)}, 
  title={Evidence from the industrial assessment program on energy investment decisions by small and medium-sized manufacturers}, 
  year={1997},
  volume={3},
  number={},
  pages={2138-2142 vol.3},
  abstract={This paper highlights the results of a detailed analysis of investment decisions regarding energy efficiency measures at small and medium-sized manufacturing plants participating in the US Department of Energy's Industrial Assessment Center (IAC) program. This paper is drawn from a larger study that found that most small and medium-sized plants participating in the IAC program will invest in an energy efficiency measure only if the investment's capital cost can be paid back in operational savings within two years. The most frequently recommended and implemented measures have payback periods of one year or less. Implementation rates appear to drop off only slightly with increasing payback periods. Moreover, the average payback period associated with implemented measures does not appear to increase with plant size or annual energy cost. First cost appears to be more important than payback period in determining whether a recommended measure will be implemented. For most recommended energy efficiency measures, a payback period of up to two years implies an implicit (real) discount rate of about 50 percent, which is higher than the values typically used to characterize industrial investment decisions in energy-economic models.},
  keywords={Investments;Energy measurement;Manufacturing industries;Energy efficiency;Costs;Pulp manufacturing;Particle measurements;Energy consumption;Laboratories;Size measurement},
  doi={10.1109/IECEC.1997.656757},
  ISSN={},
  month={July},}@INPROCEEDINGS{6666169,
  author={Shen, Biao and Li, Zhao},
  booktitle={2013 IEEE 24th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)}, 
  title={Coexistent transmission and user scheduling for CR-MIMO system based on interference alignment and cancellation}, 
  year={2013},
  volume={},
  number={},
  pages={403-407},
  abstract={In this paper an interference alignment and cancellation (IAC) based coexistent transmission and user scheduling strategy is proposed for infrastructured cognitive radio (CR) multiple-input multiple-output (MIMO) system with multiple secondary users (SUs). By exploiting cooperative capability at primary base station (PBS) and secondary base station (SBS), spatial signal processing procedure is designed. With the scheme, interference alignment (IA) is firstly employed to adjust multiple cognitive transmissions to lie in the subspace orthogonal to the one spanned by the primary signal. Then primary information is recovered at PBS without interference and fed to SBS via inter-BS collaboration. Finally, SBS subtracts the primary part from the received mixed signal and extracts the secondary information separately. With regard to SU scheduling transmission difference of various channel realizations is exploited to achieve multiuser diversity gain. According to the IAC based mechanism the priority of primary is guaranteed, and interference-free coexistence of both primary and secondary transmission is achieved. Moreover, effective utilization of spatial channel resource is realized compared with traditional IA based scheme. Theoretical analysis and simulation results show that the achievable data rate of secondary transmission is significantly enhanced.},
  keywords={Interference;MIMO;Scattering;Cognitive radio;Signal to noise ratio;Hip;cognitive radio;multiple-input multiple output;uplink;interference alignment and cancellation;scheduling},
  doi={10.1109/PIMRC.2013.6666169},
  ISSN={2166-9589},
  month={Sep.},}@INPROCEEDINGS{8548478,
  author={Konishi, Hiroo and Suzuki, Masaichi and Sugahara, Shuichi and Hashimoto, Taha Selim Ustun Jun and Otani, Kenji},
  booktitle={2018 IEEE 7th World Conference on Photovoltaic Energy Conversion (WCPEC) (A Joint Conference of 45th IEEE PVSC, 28th PVSEC & 34th EU PVSEC)}, 
  title={HILS test facilities for PV-PCS and PCS for storage battery at AIST}, 
  year={2018},
  volume={},
  number={},
  pages={1431-1435},
  abstract={In order to make effective use of PV-PCSs and battery storage PCSs, it is important to develop and evaluate behaviors in power system, grid interconnection, their control and protection equipment, etc. A HILS (Hardware in the Loop Simulation) test facility was developed for these purposes which was consisted in combination with real-time simulator and actual hardware of their PCSs. RTDS of RTDS Technologies Inc. for real-time simulator, MX 30 of AMETEK Inc. as a signal amplifier of RTDS analysis results and the SMA 20 kW PCS for actual hardware were used for the HILS test facility. In the simulation, power system included PV-PCS is simulated by the RSCAD which is an exclusive software of RTDS. A dynamic PQ source model provided in the RSCAD library was used instead of the actual PCS model. AC voltages Vac and AC currents Iac are detected from the actual PCS and feedback to the RTDS. In the simulation program, we calculate instantanious real power P and reactive power Q in real time using Vac and Iac in order to set as a command of the dynamic PQ source model. For the HILS test, we analyzed behaviors of the PV-PCS during grid faults. And the results were compared with off-line simulation using a PV model provided in the RSCAD library.},
  keywords={Hardware;Power system dynamics;Power transmission lines;Software;Analytical models;Real-time systems;power conditioning system;photovoltaic systems;real–time simulator;battery storage;grid simulation},
  doi={10.1109/PVSC.2018.8548478},
  ISSN={0160-8371},
  month={June},}@INPROCEEDINGS{5456836,
  author={Xiaotao Wang and Jitao Wu},
  booktitle={2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics (CAR 2010)}, 
  title={Remote sensing image segmentation based on statistical region merging and nonlinear diffusion}, 
  year={2010},
  volume={1},
  number={},
  pages={32-35},
  abstract={As remote sensing images are multi-sensor, multi-spectral, multi-temporal phase and multi-resolution, general image segmentation methods always can not obtain satisfactory results. In this paper, we introduce the statistical region merging (SRM) model to segment remote sensing images. And according to the characteristics and defects of SRM, the model is improved as follows: Firstly, image gradient information is added in the sort function, which can increase the differences between regions; Secondly, we combine SRM with the nonlinear diffusion which can protect borders, then the requirements of regional homogeneity are better meted, and the model's anti-noise ability is also strengthened; Thirdly, for the issue of SRM has over merging defect, we give a predicate, by which the over merging regions are chosen and then segmented by IAC. Experiments on two color remote sensing images display the quality of the novel method.},
  keywords={Remote sensing;Image segmentation;Merging;Machine learning;Robotics and automation;Mathematics;Protection;Pixel;Asia;Informatics;statistical region merging;nonlinear diffusion},
  doi={10.1109/CAR.2010.5456836},
  ISSN={1948-3422},
  month={March},}@ARTICLE{9580826,
  author={Sarker, Subrata K. and Fahim, Shahriar Rahman and Sarker, Niloy and Tayef, Kazi Zakaria and Siddique, Abu Bakar and Datta, Dristi and Mahmud, M. A. Parvez and Ishraque, Md. Fatin and Das, Sajal K. and Sarker, Md Rabiul Islam and Shezan, Sk. A. and Rahman, Ziaur},
  journal={IEEE Access}, 
  title={Ancillary Voltage Control Design for Adaptive Tracking Performance of Microgrid Coupled With Industrial Loads}, 
  year={2021},
  volume={9},
  number={},
  pages={143690-143706},
  abstract={Although the utilizing of renewable energy sources (RESs) in microgrid (MG) offers a recognized solution to meet the increasing demand, it’s performance depend on various meteorological factors of RESs. Again, the functioning of MGs is often affected with certain industrial load dynamics which allowing them to alter the operating region and tracking function of the MGs. The above-mentioned challenges motivate us to design the ancillary voltage control design for enabling the MGs to provide adaptive transient and tracking voltage responses over the changes of various factors like weather, consumer demand, and industrial loads. Firstly, we design an intelligent adaptive control (IAC) framework made by merging with proportional-integral (PI) regulator and artificial neural network (ANN) to sustain the regulated common bus voltage over the mentioned changes. The regulated bus voltage is forwarded to operate the industrial loads via the regulation of inverter-based secondary network (SN). A study on the variation of weather condition and consumer demand is done to show the efficacy of the IAC framework. Secondly, we propose a novel fixed control structure named model reference modified fractional-order PID (MR-F0PID) regulator to maintain the high tracking response of the MG via the control of inverter associated with the SNs. The tracking competency of this fixed control framework is analyzed over the running of a few industrial loads dynamics associated with single-phase inverter based SN and results are compared with the other related existing controllers. Moreover, a mathematical analysis for mapping the stable region is completed here to track down the closed-loop stability area. As a further study, the three-phase inverter based SN associated with several three-phase industrial load is also considered with the same DC bus and analyzed to observe the competency of the proposed fixed MR-FOPID control framework.},
  keywords={Voltage control;Regulators;Inverters;Microgrids;Load modeling;Regulation;Integrated circuit modeling;Adaptive controller;DC bus voltage stabilizer;fractional-order regulator;microgrid control and PV source},
  doi={10.1109/ACCESS.2021.3121548},
  ISSN={2169-3536},
  month={},}@ARTICLE{10909132,
  author={Mar, Manuel and Chellapandi, Vishnu Pandi and Yuan, Liangqi and Wang, Ziran and Dietz, Eric},
  journal={IEEE Journal of Selected Areas in Sensors}, 
  title={Advanced Sensor Configurations for High-Speed Autonomous Racing Vehicles}, 
  year={2025},
  volume={2},
  number={},
  pages={136-149},
  abstract={Autonomous racing is a dynamic and challenging domain that not only pushes the limits of technology but also plays a crucial role in the advancement and fostering of greater acceptance of autonomous systems. This article thoroughly analyzes challenges and advances in the design and performance of autonomous racing vehicles, focusing on Roborace and the Indy Autonomous Challenge (IAC). This review compares sensor configurations, artificial intelligence techniques, architectural nuances, and performance metrics on these cutting-edge platforms. In Roborace, the evolution from Devbot 1.0 to Robocar and Devbot 2.0 is detailed, revealing insights into sensor configurations and performance outcomes. The examination extends to the IAC, which is dedicated to high-speed self-driving vehicles and emphasizes development trajectories and sensor adaptations. By reviewing these platforms, the analysis provides a valuable comparison of autonomous driving racing systems and sensor suites, contributing to a broader understanding of sensor architectures and the challenges faced.},
  keywords={Sensors;Sensor systems;Sensor phenomena and characterization;Radar;Measurement;Temperature sensors;Intelligent sensors;Artificial intelligence;Reliability;Real-time systems;Advanced sensor configurations;autonomous racing vehicles;dynamic path planning;high-performance autonomous systems;high-speed autonomous driving;real-time sensor fusion;sensor performance},
  doi={10.1109/JSAS.2025.3547283},
  ISSN={2836-2071},
  month={},}@INPROCEEDINGS{6485396,
  author={Guo, Yang},
  booktitle={2012 12th International Conference on Control Automation Robotics & Vision (ICARCV)}, 
  title={A note on the number of solutions of the coplanar P4P problem}, 
  year={2012},
  volume={},
  number={},
  pages={1413-1418},
  abstract={We present a novel constrained system for the coplanar P4P problem. By converting perspective transformation to affine transformation and using invariance to 3D affine transformation, we explore the relationship between the image of the absolute conic (IAC) and the world coordinate of camera optical center from four coplanar correspondences and show how the coplanar P4P problem is cast into the problems of solving the common intersection points of a system of five spheres. In particular, we claim that, if the four control points are coplanar, the upper bound of the coplanar P4P problem under distance-based definition or orthogonal-transformation-based definition is 2 and also attainable. From the point of view of efficient numerical solution, we also propose a solving technique based on singular value decomposition (SVD) in order to estimating the camera pose under the effects of image noise. Finally, The advantages of our method are demonstrated by testing on synthetic data.},
  keywords={Cameras;Transmission line matrix methods;Noise;Equations;Upper bound;Optical imaging;Vectors},
  doi={10.1109/ICARCV.2012.6485396},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{5753442,
  author={Khoshnaw, Abdulqadir and Zein-Sabatto, Saleh and Shetty, Sachin and Malkani, Mohan},
  booktitle={2011 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)}, 
  title={Development of information fusion model for layered sensing systems using computing with words}, 
  year={2011},
  volume={},
  number={},
  pages={183-188},
  abstract={A layered sensing system involves different layers of sensors with different capabilities in one integrated system. This research focuses on the development of a model for information fusion level of a layered sensing system using computing with words. In this research effort, we have proposed the addition of a new processing level to the Joint Directors of Laboratories (JDL) Fusion Model. The new processing level was called “Information Assessment and Control (IAC)”. In this level, the different layers of a layered sensing system evaluates information about an evolving situation in terms of threat level. The information assessment and control level can exchange processed information among the layers of a layered sensing system in order to determine the overall situation threat level. The situation threat level assessment was carried out by using Computing With Words (CWW) methodology. Using this methodology, we have added a human-like cognitive element to the process of information assessment to accomplish better situation awareness. The developed system was implemented on a layer sensing system using ATR-TSU test-bed, which consists of an UAV, several cameras mounted on a building, and UGVs. Matlab and Software Development Kit were used for image processing and control of the sensors. The software development for the camera layer has been completed and tested on a security situation scenario. The testing results are reported in this paper.},
  keywords={Sensors;Cameras;Surveillance;Software;Security;Buildings;Computer architecture;Computing With Words;Layered Sensing;Situation Awareness},
  doi={10.1109/COGSIMA.2011.5753442},
  ISSN={2379-1675},
  month={Feb},}@INPROCEEDINGS{9843235,
  author={Pyrzak, Guy and Puncel, Robert and Vona, Marsette A and Lopez-Roig, Reynaldo},
  booktitle={2022 IEEE Aerospace Conference (AERO)}, 
  title={The Mars 2020 Ground Data System Architecture}, 
  year={2022},
  volume={},
  number={},
  pages={1-20},
  abstract={The Mars 2020 Mission's primary objective is to collect 20 geographically unique samples during its prime mission of one and a quarter Martian year, or just over 2 Earth years. Mission planners determined the project needed to develop a system that would enable the operations team to analyze engineering and science data, make science decisions, select viable rover targets at a millimeter resolution and validate an uplink bundle for a car sized rover with more complex science instruments than any previous Mars surface mission. All this had to be done within a five-hour time frame. Doing this with a small team would be a challenge, but this had to be accomplished by a large team of engineers and scientists located across North America and Europe. Achieving this level of operational efficiency was unheard of in the prime mission. In addition, the mission had another set of requirements that had nothing to do with surface operations; the Mars 2020 Ground Data System (GDS) was also expected to comply with a new set of security requirements to keep up with the ever-changing cybersecurity landscape. The Mars 2020 Ground Data System (GDS) is a re-architected version of the Mars Science Laboratory GDS. The primary goal was to integrate the lessons learned from previous Mars surface missions, accommodate a set of new requirements and capabilities required to ensure mission success, and comply with a new set of cybersecurity controls. The new architecture includes several unique qualities including a data lake, language-agnostic system-wide event-based operations, containerization, automated deployment, network segmentation, infrastructure-as-code, API-driven interfaces, and the first Mars surface GDS to operate primarily in the cloud. The new architecture enabled greater access to the system's data, tighter integration with the operations team, and a higher level of traceability. The availability of the data also enabled a new set of capabilities previously not possible on surface missions. These new capabilities include an autonomous data to information, pipeline for downlink analysis, horizontal scaling of science data processing capabilities, autonomous round trip data tracking of science and engineering data, integration of flight system state into the tactical planning cycle, high fidelity targeting utilizing kinematic data, and hierarchical image and 3d meshes data representations. This paper will introduce the requirements for the Mars 2020 Mission, the heritage architecture, and the rationale for the changes to achieve the new architecture. The paper will continue to describe the fundamental changes made to the GDS architecture, how these changes enabled a more tightly integrated GDS, and the new capabilities that were enabled by the new architecture. The paper will conclude with the lessons learned from the process of rearchitecting a heritage GDS system and from the first 200 days of operations supporting over 800 users from around the world.},
  keywords={Space vehicles;Mars;Three-dimensional displays;Target tracking;Pipelines;Planning;Computer security},
  doi={10.1109/AERO53065.2022.9843235},
  ISSN={1095-323X},
  month={March},}@INPROCEEDINGS{8999923,
  author={Chaipunyathat, Ajchareeya and Porrawatpreyakorn, Nalinpat and Nuchitprasitchai, Siranee and Viriyapant, Kanchana},
  booktitle={2019 Research, Invention, and Innovation Congress (RI2C)}, 
  title={A Conceptual Model of Requirement Engineering in Cloud Project Delivery for Thai Government Organizations}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  abstract={The shift to cloud computing has affected the future of software engineering in several ways i.e., multilateral software development, scalability, and new technology stack such as an open-source software, plus infrastructure as code such as container, serverless architecture and software defined network (SDN). In order to support the cloud project delivery for government organizations, requirements engineering (RE) is a crucial step in software engineering that determines whether a project will be successful or result in a failure. RE steps include requirement elicitation, requirement analysis, requirement specification and requirement validation. Data is collected by semi-structured interview from the providers and the users of cloud services in 11 Thai government organizations, and from cloud service provider for meeting enterprise requirements and user requirements. The results reveal nine key issues that affect cloud project delivery: (1) lack of trust with external cloud service provider by generation X and baby boomer (2) lack of transparency as regards the legal agreement about the cloud user's personal data protection responsibility by cloud service provider, (3) the issues of reliability, security and service level agreements (4) lack of knowledge and lack of understanding of cloud technology (5) required training and a learning by doing (6) the policy to use government cloud services instead of developing their own cloud, (7) older people at top-level tend to resist cloud technology, (8) people in general lack of knowledge and understanding of cloud technology (9) problems about pricing model, it's impact on 23 cloud requirements (functional and non-functional) as well as factors that involved in RE phases. Based on these results this paper presents a Conceptual Model of Requirement Engineering for Cloud Project Delivery in Thai Government Organizations.},
  keywords={Training;Cloud computing;Technological innovation;Government;Requirements engineering;Software defined networking;Software engineering;Requirements Engineering;Cloud Project;Software Engineering;Thai Government Organization},
  doi={10.1109/RI2C48728.2019.8999923},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{1368173,
  author={Grabill, P. and Seale, J. and Brotherton, T.},
  booktitle={2004 IEEE Aerospace Conference Proceedings (IEEE Cat. No.04TH8720)}, 
  title={aTEDS: airborne turbine engine diagnostic system}, 
  year={2004},
  volume={6},
  number={},
  pages={3563-3570 Vol.6},
  abstract={There is a significant need for technologies that improve flight safety and reduce maintenance and support costs for aircraft turbine engines. The C17 aircraft is being used extensively in the fight against terror in Iraq and other parts of the world. Engines are being stressed with both high operation temperatures and a severe short take off and landing environment. The current C17/F117 engines do not have an engine vibration monitoring system. If high vibration conditions occur the flight crew cannot easily identify the problem engine. IAC is developing an airborne turbine engine diagnostics system (aTEDS) for the C17/F117 engine. aTEDS is designed to automatically collect, process, and monitor vibration data collected from the F117 engine. In addition to the on-board system aTEDS includes a laptop PC ground based diagnostic system to aid in data collection, visualization, analysis and fault isolation. The description of the aTEDS system and preliminary results from collection and processing of T1 C17 flight data is presented in this paper.},
  keywords={Turbines;Engines;Aircraft propulsion;Air safety;Aerospace safety;Costs;Temperature;Computerized monitoring;Portable computers;Data visualization},
  doi={10.1109/AERO.2004.1368173},
  ISSN={1095-323X},
  month={March},}@INPROCEEDINGS{11181353,
  author={Huang, Bo-Jun and Kuan, Pei-Hsun and Hung, Hsiang-Ming and Tsai, Meng-Hsun},
  booktitle={2025 25th Asia-Pacific Network Operations and Management Symposium (APNOMS)}, 
  title={Managing Computing Resources with Slurm for Multiple Courses Usage}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={In this work, we present a scalable and fair resource management solution to support multiple courses. We replace the previous direct-access system with Slurm, a widely used workload manager, to improve fairness, utilization, and manageability. The deployment is automated using IaC tools, including PXE and Ansible, enabling us to provision a fully functional Slurm cluster from operating system in minutes. To support diverse software requirements across courses, we integrate package managers such as Guix and Conda, ensuring consistent and reproducible runtime environments. We further employ Slurm’s QOS features to enforce per-user resource limits and multifactor scheduling policy. Our system has been deployed in the Spring 2025 semester to support the Parallel Programming course, with 49 active users and approximately 92,000 job submissions. Despite the high demand, our analysis shows that fewer than $\mathbf{1 0}$ nodes were sufficient to handle the workload, demonstrating the effectiveness of proposed architecture.},
  keywords={Runtime environment;Parallel programming;Operating systems;Computer architecture;Quality of service;Software;Resource management;Springs;Slurm;Scheduling;Resource management},
  doi={10.23919/APNOMS67058.2025.11181353},
  ISSN={2576-8565},
  month={Sep.},}@INPROCEEDINGS{10977883,
  author={Volkov, Egor and Linich, Anastasia and Averkin, Alexey},
  booktitle={2025 27th International Conference on Digital Signal Processing and its Applications (DSPA)}, 
  title={Active Contour Method Modification for Diabetic Macular Edema Area Quantification in OCT Images}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={A new method for automated quantification of diabetic macular edema on optical coherence tomograms based on modification of the active contour model is proposed. Traditional active contour models require manual initialization of the contour and are computationally expensive. This paper presents a modification of the IAC that uses a fast Fourier transform to accelerate the iterative segmentation process and automatic loop initialization. The model is reformulated using a threshold function that defines the contour as a region boundary, and includes a Fourier function of the pressure force with sign to account for global image features and a gradient force for local adaptation. A spectral residual approach based on the analysis of the frequency spectrum of the image is applied for automatic initialization. The proposed method combines the advantages of the frequency approach and regional segmentation, providing automatic initialization, robustness to background inhomogeneities, and high-speed performance comparable to traditional active contour models despite processing the entire image. This modification of the active contour model allows efficient and automatic extraction of diabetic macular edema boundaries on optical coherence tomograms, eliminating the need for manual initialization and ensuring the practical applicability of the method for quantitative assessment of the diabetic macular edema area.},
  keywords={Image segmentation;Accuracy;Computational modeling;Force;Manuals;Coherence;Optical imaging;Diabetes;Active contours;High-speed optical techniques;active contour;diabetic macular edema;oct;fft},
  doi={10.1109/DSPA64310.2025.10977883},
  ISSN={},
  month={March},}@INPROCEEDINGS{9077623,
  author={Alonge, Christianah Yetunde and Arogundade, Oluwasefunmi Tale and Adesemowo, Kayode and Ibrahalu, Friday Thomas and Adeniran, Olusola John and Mustapha, Abiodun Muyideen},
  booktitle={2020 International Conference in Mathematics, Computer Engineering and Computer Science (ICMCECS)}, 
  title={Information Asset Classification and Labelling Model Using Fuzzy Approach for Effective Security Risk Assessment}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  abstract={Many information assets have been exposed to threats as a result of business owners not having access to an efficient model for classifying their information assets into appropriate security risk levels, required level of protection and priority. Manual and machine learning among several approaches have been employed in classifying information; these were not effective in considering users’ preferences and are also not based on security standard. This study proposed a Fuzzy-based Information Asset Classification and Labeling framework based on ISO/IEC 27001 security standard. The framework comprises of six major phases: expert based information asset security assessment and classification (IAC), fuzzy based information assets security assessment and classification (FIACL), information asset labeling, information security risk assessment, and information asset handling and information asset storage. The implementation of the model will be done by developing an automated system with an enhanced classification using fuzzy logic and Delphi method for the security risk assessment. The comparative analysis revealed that FIACL was more efficient and accurate in classifying information assets for proper security risks assessment and control. This model will foster effective classification of information assets in any organization.},
  keywords={Fuzzy logic;Standards organizations;Information security;Organizations;Mathematical models;Security;Risk management;Labeling;Usability;Protection;Information Asset;Asset Management;Information Classification;Information Security;Risk assessment},
  doi={10.1109/ICMCECS47690.2020.240911},
  ISSN={},
  month={March},}@ARTICLE{10988907,
  author={He, Wen-Jue and Zhang, Zheng and Zhu, Xiaofeng},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Dual-Correlation-Guided Anchor Learning for Scalable Incomplete Multi-View Clustering}, 
  year={2025},
  volume={36},
  number={9},
  pages={17336-17349},
  abstract={Efficiently learning informative yet compact representations from heterogeneous data remains challenging in incomplete multi-view clustering (IMC). The prevalent resource-efficient IMC models excel in constructing small-size anchors for fast similarity learning and data partition. However, existing anchor-based methods still suffer from shared deficiencies: 1) unstable and less informative anchor generation by random anchor selection or clueless learning and 2) imbalanced coherence and versatility capabilities of the learned anchors among different views. To mitigate these issues, we propose a novel dual-correlation-guided anchor learning (DCGA) method for scalable IMC, which learns informative anchor spaces to simultaneously incorporate both intra-view and inter-view correlations. Specifically, the intra-view anchor space is constructed and stabilized by compressing the view-specific data under the guidance of the conceived anchors as a bottleneck (A3B) strategy, with a strict theoretic analysis. Importantly, we, for the first time, build an unsupervised anchor learning scheme for incomplete multi-view data under the guidance of the bottleneck of information flow with the well-defined IB principle. As such, our model can simultaneously eliminate information redundancy and preserve the versatile knowledge derived from each view. Moreover, to endow the coherence of the learned anchors, an informative anchor constraint (IAC) is imposed to align the anchor spaces across different views. Extensive experiments on seven datasets against 11 state-of-the-art IMC methods validate the effectiveness and efficiency of our method. Code is available at https://github.com/DarrenZZhang/TNNLS25-DCGA},
  keywords={Kernel;Coherence;Correlation;Bipartite graph;Training;Optimization;Similarity learning;Object recognition;Magnetic resonance imaging;Indexes;Anchor learning;incomplete multi-view clustering (IMC);unsupervised learning},
  doi={10.1109/TNNLS.2025.3562297},
  ISSN={2162-2388},
  month={Sep.},}@INPROCEEDINGS{10835435,
  author={Tummala, Pragathi and Choi, Hannah and Gupta, Anuridhi and Lapnas, Tomas A and Chung, Yoo Sun and Peterson, Matthew and Walther, Geraldine and Purohit, Hemant},
  booktitle={2024 IEEE 6th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA)}, 
  title={Design Challenges for Scam Prevention Tools to Protect Neurodiverse and Older Adult Populations}, 
  year={2024},
  volume={},
  number={},
  pages={437-441},
  abstract={Scams through various communication mediums whether online social media, emails, search ads, or offline via phone calls and short messages (SMS) have dramatically increased after the pandemic. Prior technical research has leveraged artificial intelligence (AI) algorithms for scam detection tasks, such as spam and phishing detection, to design systems for preventing users from scams. However, due to the heavy data- dependence on AI techniques, in particular machine learning, the training datasets for classification models could be non-representative in capturing different nuances and evolution of social engineering attacks that aim to target vulnerable populations like the elderly or neuro-diverse individuals. For such populations, biases in the resulting models, in turn, lead to vulnerabilities in associated cybersecurity tools. Further, a one-size-fits-all approach to create interaction mechanisms in such tools reduces their value to protect individuals with neurodiverse profiles and older adults with varying cognitive abilities. In this paper, we synthesize the existing literature with the goal of identifying the sources of inclusive design challenges for scam filtering and prevention tools through a critical analysis of literature on both current solutions explored in cybersecurity research and the needs of individuals with diverse disability profiles. We present an Inclusive AI-driven Cybersecurity (IAC) Framework for designing effective and accessible tools to protect all populations. The findings of this research can inform effective designs of scam prevention tools across different communication media with the inclusive goal of ultimately protecting all populations.},
  keywords={Training;Privacy;Machine learning algorithms;Social networking (online);Pandemics;Prevention and mitigation;Phishing;Media;Message services;Older adults;Online Scams;Spam;Phishing;Inclusive Cybersecurity},
  doi={10.1109/TPS-ISA62245.2024.00058},
  ISSN={},
  month={Oct},}@ARTICLE{7819402,
  author={Johann, Sven},
  journal={IEEE Software}, 
  title={Kief Morris on Infrastructure as Code}, 
  year={2017},
  volume={34},
  number={1},
  pages={117-120},
  abstract={Cloud specialist Kief Morris joins Software Engineering Radio host Sven Johann to discuss the benefits of infrastructure as code, including security, auditability, testing, documentation, and traceability.},
  keywords={Servers;Software engineering;Automation;Software testing;Computer security;Kief Morris;infrastructure as code;infrastructure automation;Software Engineering Radio;software engineering;software development},
  doi={10.1109/MS.2017.13},
  ISSN={1937-4194},
  month={Jan},}